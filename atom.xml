<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Martin Hwang</title>
  
  
  <link href="http://ssaru.github.io/atom.xml" rel="self"/>
  
  <link href="http://ssaru.github.io/"/>
  <updated>2023-01-04T17:36:20.664Z</updated>
  <id>http://ssaru.github.io/</id>
  
  <author>
    <name>Martin Hwang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>가능도 - Likelihood</title>
    <link href="http://ssaru.github.io/2023/01/05/20230105-likelihood/"/>
    <id>http://ssaru.github.io/2023/01/05/20230105-likelihood/</id>
    <published>2023-01-04T17:18:00.000Z</published>
    <updated>2023-01-04T17:36:20.664Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><p>Machine Learning을 시작한 지는 오래되었는데, 자주 나오던 likelihood 개념은 통 익숙하지 않았던 것 같다. 지금 와서 “아하” 하고 있으니 부끄러운 마음도 든다. 한번 이렇게 이해하고 지나가기보다는 부족하더라도 글로 남겨보고자 한다. 내용 자체는 “<strong>공돌이의 수학정리노트 - 최대우도법(MLE)</strong>”의 내용을 참고했다.</p><h2 id="Likelihood의-정의"><a href="#Likelihood의-정의" class="headerlink" title="Likelihood의 정의"></a>Likelihood의 정의</h2><p>한국어로는 가능도 혹은 우도라고 불리는 likelihood는 likelihood function이라고도 부른다. <a href="https://en.wikipedia.org/wiki/Likelihood_function">위키피디아의 likelihood function</a>을 보면, likelihood function은 주어진 데이터가 어느 확률 분포와 추출되었는지에 대한 indicate function이라고 이야기한다. 즉, 추출된 데이터는 고정되어있는 상태에서 이 데이터가 어느 확률분포에서 왔는지 계산했을 때, 어느 확률분포에서 왔는지에 대한 유사도가 수치로 나타나는게 likelihood function이라고 이해하면 되겠다.</p><p>likelihood function을 수식으로 나타내면 아래와 같다. </p><script type="math/tex; mode=display">\mathcal{L}(\theta | x) = Pr(X=x|\theta)</script><h2 id="Likelihood의-직관"><a href="#Likelihood의-직관" class="headerlink" title="Likelihood의 직관"></a>Likelihood의 직관</h2><p>다음과 같이 5개의 데이터를 얻었다고 가정하자.</p><script type="math/tex; mode=display">x = \{1,4,5,6,9\}</script><p>이때, 아래의 그림을 봤을 때 데이터 <script type="math/tex">x</script>는 주황색 확률분포와 파란색 확률분포 중 어떤 곡선으로부터 추출되었을 확률이 더 높을까?</p><p><img src="likelihood.png" alt="2개의 확률분포"></p><p>눈으로 보기에도 파란색 확률분포보다는 주황색 확률분포에서 이 데이터들을 얻었을 가능성이 더 커 보인다. 왜냐면 획득한 데이터들의 분포가 주황색 확률분포의 중심에 더 일치하는 것처럼 보이기 때문이다. 이러한 해석은 우리의 직관적인 해석이고, 이를 수학적으로 표기한 것이 likelihood function이라고 보면 된다. 파란색의 확률분포와 주황색의 확률분포에서 데이터 <script type="math/tex">x</script>에 대한 likelihood function의 값은 주황색 확률분포가 더 크게 나올 것이다. </p><h2 id="Likelihood의-계산"><a href="#Likelihood의-계산" class="headerlink" title="Likelihood의 계산"></a>Likelihood의 계산</h2><p>수치적으로 이 가능도를 계산하기 위해서는 <strong>각 데이터 샘플에서 후보 분포에 대한 높이(즉, likelihood 기여도)를 계산해서 다 곱한 것</strong>을 이용할 수 있다. 계산된 높이를 더해주지 않고 곱해주는 것은 모든 데이터의 추출이 독립적으로 연달아 일어나는 사건이기 때문이다. 그렇게 해서 계산된 가능도를 생각해볼 수 있는 모든 후보군에 대해 계산하고 이것을 비교하면 우리는 지금 얻은 데이터를 가장 잘 설명할 수 있는 확률분포를 얻어낼 수 있게 된다.</p><p>이를 수학적으로 표기하면 아래와 같다.</p><script type="math/tex; mode=display">P(x|\theta) = \prod^{n}_{k=1}P(x_{k}|\theta)</script><h2 id="이어지는-토픽"><a href="#이어지는-토픽" class="headerlink" title="이어지는 토픽"></a>이어지는 토픽</h2><ul><li>MLE(Maximum Likelihood Estimation)</li><li>MLE와 뉴럴넷 Loss function의 의미</li><li>Bayesian Theory</li></ul><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://angeloyeo.github.io/2020/07/17/MLE.html">최대우도법(MLE)</a></li><li><a href="https://jinseob2kim.github.io/probability_likelihood.html">확률(Probability) vs 가능도(Likelihood)</a></li><li><a href="https://jjangjjong.tistory.com/41">확률과 가능도 그리고 최대우도추정</a></li><li><a href="https://ko.wikipedia.org/wiki/%EA%B0%80%EB%8A%A5%EB%8F%84">가능도</a></li><li><a href="https://www.kaggle.com/code/waybackwhale/likelihood-function">Likelihood function이란 무엇인가?</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;Likelihood function에 대해서 설명한다.&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://ssaru.github.io/categories/AI/"/>
    
    <category term="ML" scheme="http://ssaru.github.io/categories/AI/ML/"/>
    
    
    <category term="AI" scheme="http://ssaru.github.io/tags/AI/"/>
    
    <category term="ML" scheme="http://ssaru.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>마르코프 체인 - Markov Chain</title>
    <link href="http://ssaru.github.io/2023/01/03/20230103-markov_chain/"/>
    <id>http://ssaru.github.io/2023/01/03/20230103-markov_chain/</id>
    <published>2023-01-02T15:47:00.000Z</published>
    <updated>2023-01-02T16:43:47.101Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><p>Stable Diffusion에 대해서 공부하다보니 마르코프 체인이 나와서 살펴봐야할 것 같아 정리한 글이다.<br>마르코프 체인 관련된 블로그 포스팅 등 여러 글들을 참고하여 정리하였다.</p><h2 id="시작"><a href="#시작" class="headerlink" title="시작"></a>시작</h2><p>마르코프 체인은 ‘<strong>현재 몇 가지의 선택지가 있고, 과거 비율을 충분한 회수로 확인할 수 있다면 미래에 특정한 선택지를 고를 확률에 대해서도 표현할 수 있지 않을까</strong>’라는 고민에서 출발했다.</p><p>쇼핑몰을 운영하는 기업은 특정 조건의 고객군이 로그인 후 어떤 검색을 거쳐 장바구니에 넣고 최종 결재를 하게 되었는지, 그리고 해당 조건의 고객군이 미래에 어떠한 선택을 하게 될 것인지 궁금해할 것이고, 이는 마르코프 체인을 활용하여 풀 수 있을 것이다.</p><h2 id="마르코프-체인-Markov-Chain-Markov-Process"><a href="#마르코프-체인-Markov-Chain-Markov-Process" class="headerlink" title="마르코프 체인(Markov Chain; Markov Process)"></a>마르코프 체인(Markov Chain; Markov Process)</h2><p>마르코프 체인이란 마르코프 특성(Markov Property)를 지니는 이산시간(discrete time) 확률과정(stochastic process)이라고 정의한다.</p><ul><li>확률과정: 시간에 따라 “어떤 사건이 발생할 확률”이 변화하는 과정</li><li>마르코프 특성: 과거 상태들( $$s_1, s_2, …, s_{t-1}$$ )과 현재 상태($$s_t$$)가 주어졌을 때, 미래 상태($$s_{t+1}$$)는 과거 상태와는 독립적으로 현재 상태에 의해서만 결정되는 것을 의미한다. (혹은 일정 기간의 상태에만 영향을 받는 것)</li></ul><p>즉, 과거와 현재 상태 모두를 고려했을 때, 미래 상태가 나타날 확률과 현재 상태만을 고려했을 때, 미래 상태가 발생할 확률이 동일하다. 이를 수식으로 표현하면 아래와 같다.</p><p>$$<br>P[s_{t+1}|s_{t}] = P[s_{t+1} | s_1, \cdots, s_t]<br>$$</p><p>마르코프 프로세스는 과거 상태를 기억하지 않기 때문에 메모리 리스(memoryless)프로세스라고 불리며, 마르코프 체인(Markov chain)이라 불리기도 한다.</p><p>어떤 상태에서 다음 단계의 상태로 변화하는 것을 변이(transition)라고 하고, 그 확률을 상태 변이확률(state transition probability)라고 한다. 시간 $t$에서의 상태를 $s$라고 하고, 시간 $t+1$에서의 상태를 $s^{‘}$이라고 할 때, 상태 변이확률은 아래 식과 같이 표현할 수 있다.</p><p>마르코프 체인 중 $$N$$차 마르코프 체인이 있는 듯하다. 이 경우를 “<strong>메모리 k 마르코프 체인</strong>”이라고도 부른다.</p><p>$$<br>    r=0,\ P(o_t|o_{t-1}o_{t-1}\cdots o_{1}) = P(o_t) \<br>    r=1,\ P(o_t|o_{t-1}o_{t-1}\cdots o_{1}) = P(o_t|o_{t-1}) \<br>    r=2,\ P(o_t|o_{t-1}o_{t-1}\cdots o_{1}) = P(o_t|o_{t-1}, o_{t-1}) \<br>$$</p><p><img src="markov_chain.png" alt="N차 마르코프 체인"></p><p>$$<br>P_{ss^{‘}} = P[s_{t+1}=s^{‘}| s_{t}=s]<br>$$</p><h2 id="마르코프-체인-계산-방법"><a href="#마르코프-체인-계산-방법" class="headerlink" title="마르코프 체인 계산 방법"></a>마르코프 체인 계산 방법</h2><p>마르코프 체인을 활용해 오늘 날씨를 통해 내일의 날씨를 확률적으로 예측하고, 다시 내일의 날씨 정보에 기반해서 모레의 날씨를 예측하는 행위를 충분히 반복했다고 가정하자. 날씨에 관한 확률의 묶음이 특정 성질을 반복할 때, 반복 계산의 어느 지점에서 날씨가 흐릴지, 비가 올지, 맑을지에 대한 확률이 특정하게 수렴하게 될 수 있다. 따라서 마르코프 체인은 오늘 흐림이라서 내일은 무조건 비가 아니라 내일도 흐릴 확률은 어느 정도인지, 혹은 맑거나 눈이 내릴 확률은 어느 정도인지 확률적으로 표현하게 된다.</p><p>문제를 간소화하여 맑음, 흐림 2가지의 조건만 활용해서 마르코프 체인을 계산해보자.</p><p><img src="weather_probability.png" alt="날씨 전이 확률"></p><p>위 확률값을 상태 전이도(State Transition Diagram)로 표현하면 아래와 같다.</p><p><img src="state_transition_diagram.png" alt="상태 전이 확률"></p><p>이는 아래와 같이 전이확률 행렬로 표현할 수 있다.</p><p><img src="state_transition_matrix.png" alt="상태 전이 행렬"><br><img src="state_transition_flow.png" alt="상태 전이 흐름도"></p><p>위의 전이 흐름도는 아래와 같이 행렬 곱을 통하여 계산할 수 있다. 모레의 확률 변화는 오늘과 내일의 전이가 연속되어 일어나는 경우이기 때문에 전이행렬을 곱하여 계산한다.</p><p><img src="calculate_markov_chain.png" alt="마르코프 체인 게산"><br>만약 지난 3년간 특정 일의 날씨 중 80%가 맑았다면 특정일 기준 모레가 맑을 확률은 0.8 x 0.565 + 0.2 x 0.362 = 0.524이기 때문에 52.4% 확률로 예측할 수 있게 된다.</p><p>이러한 상태에서 충분히 많은 횟수를 반복한다면 어느 순간에는 전이행렬이 변하지 않는 상태가 오는데 이를 두고 **안정상태(steady state)**라 부르고, 확률이 직전 상태와 동일하게 수렴하게 된다. 이러한 확률 분포를 **정적 분포(Stationary Distribution)**라고 부른다.</p><h2 id="안정상태-Steady-state-와-정적분포-Stationary-distribution"><a href="#안정상태-Steady-state-와-정적분포-Stationary-distribution" class="headerlink" title="안정상태(Steady state)와 정적분포(Stationary distribution)"></a>안정상태(Steady state)와 정적분포(Stationary distribution)</h2><p>현재 상태를 알고 있고 전이 확률행렬을 알고 있다면, 다음 단계의 상태도 알 수 있을 것이다. 마찬가지로 다음 단계의 상태를 구했고 전이 확률행렬을 이미 알고 있으니 그다음 단계의 상태도 알 수 있을 것이다. 이를 식으로 나타내면 아래와 같다.</p><p>$$<br>P^{n}<em>{ij} = [P</em>{ij}]^{n}<br>$$</p><p>$P_{ij}$는 상태 $i$에서 $j$로 가는 상태전이 확률이고, $n$의 의미는 $n$번째 상태이다. 만약 $n\rightarrow \infty$라면 아래와 같은 수식이 성립한다.</p><p>$$<br>\pi = \pi P<br>$$</p><p>이때, $\pi$는 각 상태의 확률분포이고 $P$는 전이행렬이다. 이 상태에서 다음 상태를 알기 위해 전이행렬을 더 곱한다 해도 같은 값을 유지하는데, 이를 **안정상태(Steady state)**라고 하고 이때의 확률분포를 **정적분포(Stationary distribution)**라고 한다.</p><h2 id="생각"><a href="#생각" class="headerlink" title="생각"></a>생각</h2><ul><li><a href="https://www.youtube.com/watch?v=tcrr2QiXt9M&t=474s">토스 PO 세션에서 Carrying Capacity</a>를 언급했는데, 마르코프 체인으로 Carrying Capacity를 측정해볼 수 있지 않을까?<ul><li>그런데, A라는 App을 쓴 사람이 다시 해당 App을 쓸 확률(Retension Probability)은 알 수 있지만 다른 App들을 쓰다가, A라는 App을 쓸 확률(New, Resurrection Probability)은 알 수 없는 것이 문제이다.</li><li>Inflow / Outflow / Retention 확률이 다른 변수에 의해 결정된다라고 했을 때, 마르코프 체인이 성립될 수 있나? 그 가정이 틀렸어도 마르코프 체인으로 어느정도 풀어낼 수 있나?</li></ul></li></ul><h2 id="이어지는-토픽"><a href="#이어지는-토픽" class="headerlink" title="이어지는 토픽"></a>이어지는 토픽</h2><ol><li>마르코프 보상 프로세스 (Markov Reward Process) → 강화학습과 이어짐</li><li>마르코프 디시전 프로세스(Markov Desision Process) → 강화학습과 이어짐</li><li><a href="https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=sigmagil&logNo=221482425278">마르코프 체인 분석(Markov Chain Analysis)</a></li><li>전이행렬을 고유값(Eigenvalue), 고유벡터(Eigenvector)로 제곱하는 방식으로 구할 수 있다. $$<br> P^{k} = QD^{k}Q^{-1}<br> $$</li><li>Carrying Capacity와 Markov Chain을 연결지어 생각해보기</li><li><a href="https://angeloyeo.github.io/2020/09/17/MCMC.html">마르코프 체인 몬테 카를로</a></li><li>몬테카를로 시뮬레이션</li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://www.puzzledata.com/blog190423/">마르코프 체인에 관하여</a></li><li><a href="https://bskyvision.com/entry/%EB%A7%88%EC%BD%94%ED%94%84-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EB%A7%88%EC%BD%94%ED%94%84-%EC%B2%B4%EC%9D%B8%EB%9E%80">[강화학습] 마코프 프로세스(=마코프 체인) 제대로 이해하기</a></li><li><a href="https://sites.google.com/site/machlearnwiki/RBM/markov-chain">Markov Chain</a></li><li><a href="https://www.rpubs.com/skkong/markov_chain">마코프 체인 응용</a></li><li><a href="https://www.youtube.com/watch?v=Yh62wN2kMkA">마르코프 체인 | 고급수학2 | 행렬 세특</a></li><li><a href="https://ko.wikipedia.org/wiki/%EB%A7%88%EB%A5%B4%EC%BD%94%ED%94%84_%EC%97%B0%EC%87%84">마르코프 연쇄</a></li><li><a href="https://velog.io/@qkrdbwls191/Markov-chain">Markov chain</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;Markov Chain에 대해서 설명한다.&lt;/p&gt;</summary>
    
    
    
    <category term="AI" scheme="http://ssaru.github.io/categories/AI/"/>
    
    <category term="ML" scheme="http://ssaru.github.io/categories/AI/ML/"/>
    
    
    <category term="AI" scheme="http://ssaru.github.io/tags/AI/"/>
    
    <category term="ML" scheme="http://ssaru.github.io/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>7가지 코드 - Code 1</title>
    <link href="http://ssaru.github.io/2022/12/26/20221226-product_management_sacred_seven/"/>
    <id>http://ssaru.github.io/2022/12/26/20221226-product_management_sacred_seven/</id>
    <published>2022-12-26T01:49:00.000Z</published>
    <updated>2022-12-26T17:56:24.057Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><h2 id="제품-단계별-전략"><a href="#제품-단계별-전략" class="headerlink" title="제품 단계별 전략"></a>제품 단계별 전략</h2><p>제품은 크게 2가지 유형이 있다.</p><h3 id="0-to-1"><a href="#0-to-1" class="headerlink" title="0 to 1"></a>0 to 1</h3><ul><li>“0 to 1”은 충족되지 않은 수요 혹은 현재는 사용할 수 없는 공급을 만들어내야한다.  </li><li>기존 제품과 유사 제품을 만들어낸다면 기존 제품보다는 10배 이상 뛰어난 제품을 만들어야한다.</li><li>이 과정에서 시장 적합성(Product Market Fit)을 찾아내야한다.</li></ul><h3 id="1-to-N"><a href="#1-to-N" class="headerlink" title="1 to N"></a>1 to N</h3><p>“1 to N”은 “1 to 0”에서 시장 적합성을 찾은 제품을 확장하는 단계이다.<br>“1 to N” 전략은 다른 회사들이 모방하기 어렵게하는데 초점이 맞춰져있다.</p><ul><li>브랜딩</li><li>네트워크 효과: 메신저를 사용하게되면, 친구가 많은 메신저 앱(카카오톡, 페이스북)에 들어가게된다.</li><li>규모의 경제: 쿠팡을 따라하려면 물류창고나 배송 시스템을 만들어야하는데, 비용이 크기에 따라하기 어렵다.</li><li>카운터 포지셔닝: 쿠팡의 로켓배송은 쿠팡 자체의 차별점이고, 이는 따라하는 것만 해도 어려울 수 있다.</li><li>고유의 기술: OpenAI의 chatGPT같이 공개되어이지 않으나, 독보적인 기술들이 차별점이 될 수 있다.</li><li>전환 비용: 구독 서비스를 이미 사용하고있는 경우, 다른 경쟁 제품으로 넘어가야하는 허들이 생긴다.</li><li>프로세스에 대한 지식: 쿠팡의 물류 프로세스는 모방하기 어렵다.</li><li>획득 자원: 특허와 대규모 인력구성은 따라하기 어렵다.</li></ul><h3 id="0-to-1-vs-1-to-N"><a href="#0-to-1-vs-1-to-N" class="headerlink" title="0 to 1 vs 1 to N"></a>0 to 1 vs 1 to N</h3><ul><li>“0 to 1”과 “1 to N”은 서로 균형을 이루어야한다.</li><li>“1 to N”은 캐시카우로써 지속적인 자금 조달을 한다.</li><li>제품은 영원히 존속하지 않으므로, 변화에 대응하기 위하여 지속적으로 신사업을 찾아내기 위하여 “0 to 1”활동을 지속한다.</li></ul><h2 id="0-to-1-1"><a href="#0-to-1-1" class="headerlink" title="0 to 1"></a>0 to 1</h2><ul><li>“0 to 1”단계에서는 고객이 무엇을 원하는지 알기 어렵기 때문에 불확실성이 큰 영역이다.</li><li>불확실성이 큰 영역에서 Top Down식의 접근보다는 Bottom Up식의 접근이 유리할 수 있다.</li><li>니치마켓은 비즈니스 규모가 작다. 하지만 자원이 부족한 스타트업은 니치마켓을 노려야한다.</li><li>니치마켓에서 플라이휠을 굴려서 더 큰 사업으로 확장해나가야한다.</li><li>대기업에서는 더 큰 비즈니스 영역에서 사업하므로, 니치마켓은 성가셔할 수 있다.</li><li>1,000명의 열성 팬을 모으기 위하여 투자를 아낌없이 해야한다.</li><li>기술이 제일 중요한 요소가 아니고, 기술혁신에만 집중하다가 잘못될 사례가 있다.(팬암항공)<ul><li>오히려 기존 기술을 어떻게 엮어낼지가 더 중요할 수 있다.</li></ul></li><li>(개인생각) 결국은 1). 미래에 대한 예측을 얼마나 자주 상상하고 아이데이션 하는지, 2). 작은 비용으로 얼마나 빠르고 자주 실패하는지가 “0 to 1”을 찾아내는 여정이 아닐까 싶다.</li><li>(개인생각) 아이디어 발굴이 어렵다면 사람들 생각을 자주 볼 수 있는 커뮤니티 활동이 좋을 수 있겠다.</li></ul><h3 id="가설검증"><a href="#가설검증" class="headerlink" title="가설검증"></a>가설검증</h3><ul><li>제품을 만들 때에는 간단한 가설에 대한 정리를 해보면 좋다.</li><li>가설을 검증하기 위한 방법은 아래와 같은데 위에 있을 수록 비용이 싸고 실제 제품과는 괴리가 있고 순번이 클 수록 비용이 비싸고 실제 제품과 유사한 모양을 띈다.</li></ul><ol><li>사용자 관찰</li><li>구글 설문</li><li>유저 인터뷰</li><li>프로토 타입<ol><li>포스트잇 프로토타입</li><li>와이어 프레임</li><li>MVP -&gt; ETP: MVP에 대한 오해가 있는데, MVP는 제품이 아니다. 따라서 용어를 ETP(Earliest Testable Product)으로 바꾸는게 더 좋을 수 있다.<ol><li>컨시어지 MVP: 프론트 화면만 만들고, 복잡한 뒷단은 모두 사람이 수동으로 처리</li><li>페이크 도어 테스트: 실제 제품은 없지만 제품이 있는 듯 광고하거나 메인 페이지만 만들어놓고 유저들 반응을 살피는 것</li></ol></li></ol></li></ol><h3 id="제품화"><a href="#제품화" class="headerlink" title="제품화"></a>제품화</h3><ul><li>가설검증이 충분히 되었다면, 제품을 만들어야하는데 이때의 제품을 MLP(Minimum Lovable Product)라고 한다. MLP단계가 진짜 제품런칭 단계라고 보면 된다.</li><li>MLP는 단순하지만 좋은 제품이어야하고 경험설계가 중요하다.<ul><li>아래 사례들은 MLP의 대표사례이다.</li><li>애플 워치 vs 핏비트: 헬스케어시장에서 워치형태의 제품은 핏비트가 먼저 시작했지만 시장점유율은 애플 워치가 더 높았다. 이는 애플 워치로 아이폰을 제어하거나 스타일을 바꿀 수 있게 할 수 있었던 것이 주요 요인으로 보인다.</li><li>닌텐도 스위치: 하드웨어 사양은 좋지 않았지만 이동성(TV로 게임하다가, 덱에서 디바이스를 분리하면 휴대용 게임기), 확장성(혼자서 게임하다가 컨트롤러 분리해서 친구와 같이 게임)이 유저 경험 측면에서 좋았기 때문에 좋지 않은 하드웨어 사양은 큰 문제가 되지 않았다.</li></ul></li><li>OOBE 경험 중요: 언박싱의 경험, 첫 인상이 중요하다. 그런 관점에서 첫 페이지에서 보게되는 텅 빈 화면은 좋지 않다. 이 경우 온보딩에 도움이 되는 더미 데이터를 넣는게 유리하다.<ul><li>앱을 사용하고 며칠 이내에 제품 가치가 유저에게 유용하다고 인식되어야한다. 이는 리텐션 플레토로 확인할 수 있다.<ul><li> 상위 1~10위앱은 리텐션 플레토가 50%</li><li> 상위 11~60위 앱은 42%</li><li> 상위 61~160위 앱은 20%</li><li> 평균 리텐션 플레토는 4%</li></ul></li></ul></li></ul><h3 id="개인적인-생각"><a href="#개인적인-생각" class="headerlink" title="개인적인 생각"></a>개인적인 생각</h3><p>사이드 프로젝트에서 프론트 페이지만 만들고 백단은 모두 수동으로 진행해서 실제로 유저들이 사용하는지 테스트를 해봤었는데(컨시어지 MVP), 개인적으로 제일 어렵게 느껴졌던 것은 시장 적합성(PMF)를 찾았는지 어떻게 알지? 였던 것 같다. 예를들어 돈을 태워 마케팅을 진행했는데, N명에게 노출되고 0.1% 정도의 극소수 유저만 전환(실 구매)가 일어났는데 이게 적합한지 아닌지 알기 어렵다는 것이었다. 아마 유저획득 비용관점이 너무 크고, 전환율도 좋지 않아서 PMF는 못찾았다고 볼 수도 있을 것 같다. 관련해서 <a href="https://steady-study.super.site/superhuman-pmf?fbclid=IwAR1aVFkx8o_y3WylS6XhT_r7viSCiPCe9f5o2gYHKRPLkFFj-RpxW9M0ULI">Superhuman이 PMF를 찾는 엔진을 구축한 방법</a>이라는 아티클을 참고해봐도 좋을 것 같다.  </p><p>해당 아티클을 보면 일단 꽤나 많은 유저들을 확보한 상황에서 해당 제품이 가치가 있는지를 판단한 것이라, 어느정도 초기부터 전환유저가 있었던 것으로 보인다. 즉, 제품관점에서 유저들의 반응성은 어느정도 이끌어냈고, 지속적으로 PMF를 맞춰가는 여정처럼 보여서 내가 원하는 대답은 아니었던 것 같다. 아티클에서 언급하는 지표도 후행지표이기 때문에 제품을 런칭하기 전에 PMF를 찾고 들어가야한다고 이야기하신 분도 계셨다.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;7가지 코드 Code 1파트 정리&lt;/p&gt;</summary>
    
    
    
    <category term="Product" scheme="http://ssaru.github.io/categories/Product/"/>
    
    
    <category term="Product" scheme="http://ssaru.github.io/tags/Product/"/>
    
  </entry>
  
  <entry>
    <title>2022 OKR</title>
    <link href="http://ssaru.github.io/2022/02/06/20220206_2022okr/"/>
    <id>http://ssaru.github.io/2022/02/06/20220206_2022okr/</id>
    <published>2022-02-06T11:03:00.000Z</published>
    <updated>2022-02-06T15:01:07.043Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><p>AC2 그룹 내에서 홍영기님의 Personal OKR 세션이 있어, 냉큼 신청해서 듣고왔습니다.<br><img src="trigger.png" alt="Personal OKR 세선 시작"><br><img src="review.png" alt="Personal OKR 세선 후기"></p><p>그 이후에, AC2 그룹 내에서 서로 Personal OKR을 리뷰해주고 하는 활동들이 있었는데, 당시에는 정신이 없던 시기라 부담이되어 참여하지는 않았는데요.  </p><p>이후에 흘러가는 삶의 패턴을 지켜보다보니, 의식해서 사는 삶이 아니라 흘러가는 삶을 살 것 같다는 두려움이 들었습니다. 그래서 어설프겠지만, 저만의 지표를 세워볼겸 Personal OKR을 작성해봤습니다.</p><p>OKR을 작성할 때, 김창준님의 <a href="http://m.egloos.zum.com/agile/v/5304902">영리하나 열정이 없다</a> 라는 글을 참고했습니다. 그 외에 창준님의 조언도 참고했습니다.</p><blockquote><p>예를 들어 OO님의 “내 블로그 글 중 5개가 조회수 1000회, SNS 리액션 150회, 인용 50회를 달성한다”(A)를 갖고 생각할 때, 이렇게 상상해 보는 겁니다.  </p><ol><li>A를 완벽히 달성했지만 불만족하는 경우를 상상해 본다. 적어도 3가지.  </li><li>A를 거의 달성하지 못했지만 만족하는 경우를 상상해 본다. 적어도 3가지.  </li></ol><p>그 후에 A를 수정한다. 만약 A에 큰 수정이 일어난다면 내가 처음 만든 A는 초점이 잘못된 것일 확률이 높다(특히 측정하기 쉬운 걸 측정하게 되는 경향면에서).</p></blockquote><h2 id="2022년-OKR"><a href="#2022년-OKR" class="headerlink" title="2022년 OKR"></a>2022년 OKR</h2><h3 id="2022년-이루고-싶은-목표-한가지-Objective"><a href="#2022년-이루고-싶은-목표-한가지-Objective" class="headerlink" title="2022년 이루고 싶은 목표 한가지(Objective)"></a>2022년 이루고 싶은 목표 한가지(Objective)</h3><p><strong>[목표]</strong></p><ul><li>나를 찾아보자(feat. 윌리를 찾아서)</li></ul><p><strong>[이 목표가 중요한 이유]</strong></p><ul><li>본격적으로 일을 시작한 이후, 일 중심적으로 살아왔다. 이를 통해 이룬 성과들이 없진 않았지만 가족, 친구들과의 관계, 건강, 나만의 서브 컬쳐가 없는 것 등 잃는 것도 많았다.</li><li>특히 최근에 “나는 왜 일을 하고있는가?”에 대한 의문이 생겼다.<ul><li>의문이 생긴 이유: 사회 초년생 때 개인적으로 가지고있던 사회적 지위, 실력의 증명들과 같은 결핍들이 어느정도 해소되었다고 느끼면서 앞으로는 내가 쫓아야하는 대상이 사라졌다.</li><li>들었던 감정: 무기력감, 회의감, 공허함을 느꼈다. 지금까지 살아왔던 내 발자취들이 “나”라는 사람의 고유한 색이 아닌 사회의 압력이 만들어낸 평범한 발자취로 보였다.</li><li>원하는 것: 겉으로 보이기에는 평범한 발자취처럼 보이더라도, 나만의 의미가 있었으면 좋겠다. 그게 일종의 탐색이어도 좋고, 깊게 파고드는 것이어도 크게 상관없는 것 같다.</li></ul></li></ul><p><strong>[목표를 이루기 위해 필요한 결과(Key Result)]</strong></p><ol><li>안 해본 활동을 탐색하고 내가 어떤 기분이 드는지 확인했다. 이를 통해 내가 무엇을 좋아하고 무엇을 싫어하는지에 대해서 알고있다. (탐색)</li></ol><ul><li><strong>AS IS</strong> : 지금은 주어진 삶에서 쳇바퀴를 돌리고있다. 회사-집-회사-집?</li><li><strong>TO BE</strong>: 의식적으로 새로운 것이 무엇이 있는지 학습하고 시도하고있다. 그리고 그 시도에서 내가 무엇을 느끼는지 확인하고있다.</li><li>6개 이상의 접하지 않았던 경험들을 의식적으로 했다.</li><li>CS / ML 분야에서 하나 이상의 이론이나 실무적인 프로젝트를 깊게 탐구하고있다.</li></ul><hr><ul><li>완벽히 달성했지만 불만족하는 경우를 상상해 본다. 적어도 3가지.<ol><li>새로운 활동들로부터 새로운 감정들을 느끼지 못할 때,</li><li>새로운 이론이나 실무적인 프로젝트가 내 커리어 혹은 미래에 도움이 되지 못하다고 느낄 때</li><li>새로운 경험들을 했음에도 공허하거나 무기력한 감각이 사라지지 않을 경우</li></ol></li><li>A를 거의 달성하지 못했지만 만족하는 경우를 상상해 본다. 적어도 3가지.<ol><li>환경의 변화로 지금 하고있는 것으로만 충분히 동기부여를 느낄 때</li><li>기존의 환경에서 새로운 경험들을 하게 되어서 내 감정들이 더 다양해질 때</li><li>기존에 가지고있는 지식으로도 충분히 성과를 낼 수 있다는 자신감이 들 때</li></ol></li></ul><ol start="2"><li>건강하기</li></ol><ul><li><strong>AS IS</strong>: 건강관기를 위한 운동을 안 함, 춤을 추었으나 디스크 판정 이후에는 쉬고있고, 다시 생각해보는 중(허리 건강에 좋을까?…)</li><li><strong>TO BE</strong>: 춤보다는 조금 더 신체적인 관리 측면에서 식단과 운동을 하고있음</li><li>체형이 마른 근육질로 변화했다. 혹은 내 스스로가 충분히 건강하다고 느끼고있다.</li><li>평소에 먹는 식단이 건강식 위주이고, 3개월 마다 치아 관리 및 치실 습관이 있다.</li><li><del>수면시간이 평균 8시간이고, 아침에 일어나면 피로감을 덜 느껴 에너지 레벨이 높다.</del><ul><li>변경: 잠자기 전, 아침에 일어났을 때 이전과 다르게 에너지 레벨이 꽤 높다.</li></ul></li></ul><hr><ul><li>완벽히 달성했지만 불만족하는 경우를 상상해 본다. 적어도 3가지.<ol><li>건강에 너무 집중해서 다른 중요한 것을 못하는 경우. 커리어, 관계 등</li><li>먹고싶은 것들을 편하게 먹지 못하는 경우, 여자친구, 가족, 친구들과 편하게 술약속 못하는 경우?</li><li>수면, 건강에 너무 엄격해서 이를 어겨야하는 경우가 필수임에도 융통성 없을 때</li></ol></li><li>A를 거의 달성하지 못했지만 만족하는 경우를 상상해 본다. 적어도 3가지.<ol><li>좋은 몸매를 굳이 만들 필요는 없을 듯. 그게 나에게 중요한 것은 아닌 것 같다.</li><li>수면시간이 꼭 8시간일 필요는 없다. 내가 활기찬 느낌이 들고, 에너지 레벨이 좋으면 상관 없을 것 같다.</li><li>명상같은 것을 꾸준히 해서 에너지 레벨 관리가 잘 되면 그것도 크게 상관 없을 것 같다.</li></ol></li></ul><ol start="3"><li>새로운 사람 혹은 기존의 관계에서 관계를 시작하고 잘 만들어가는 방법에 대한 한가지 이상의 노하우를 가지고있고, 그 사람들에게 영감을 줄 수 있게 도울 수 있다.</li></ol><ul><li><strong>AS IS</strong>: AC2에서 배웠던 것 외에는 무의식적으로 하고있음</li><li><strong>TO BE</strong>: 조금 더 의식적으로 목표를 새우고 측정하고있음, 그리고 관련된 공부도 하고있음</li><li>NOTE: 지금 작성하는 순간에는 크게 와닿지는 않은데, 가끔 대화를 하던 도중 상대방이 스스로 고민하던 것들에 대한 해결책을 얻는 모습(유레카 모먼트)을 보면 즐거울 때가 있어서 그 이후에는 어떨지 모르겠음</li></ul><hr><ul><li><p>완벽히 달성했지만 불만족하는 경우를 상상해 본다. 적어도 3가지.</p><ol><li>내 에너지가 너무 타인에게 집중되어서 고갈되었다고 느꼈을 때</li><li>대화 스타일이나 관점이 코칭이나 상담쪽에 고정되어버렸을 때</li><li>업무와 연관짓지 못할 때</li></ol></li><li><p>A를 거의 달성하지 못했지만 만족하는 경우를 상상해 본다. 적어도 3가지.</p><ol><li>별도의 액션을 하지 않았음에도 관계에서 오는 에너지가 충만하다고 느낄 때</li><li>지금 관성으로도 관계에서 충분한 성과를 낼 수 있을 때</li><li>새로운 통찰이나 지식들을 얻었을 때</li></ol><p>경제나 돈에 대해서 더 이상 노동자의 관점이(돈 많은게 짱이야. 집있는게 짱이야?) 아니라 새로운 관점을 갖고있다.</p></li><li><p>AS IS: 그냥 무지성 투자. 부동산도 그냥 하자고하는데로.. 내가 전문가는 아니니까..</p></li><li><p>TO BE: 기업에 대해서, 투자에 대해서, 현금 흐름에 대해서 대략적으로 거시적인 나만의 관점을 가지고있다.</p></li></ul><hr><ul><li>완벽히 달성했지만 불만족하는 경우를 상상해 본다. 적어도 3가지.<ol><li>너무 많은 것들을 하다가 본업에 소홀히 했다.</li><li>현금흐름을 만들기 어렵거나 수익을 내기 어렵다는 판단이 들었을 때</li></ol></li><li>A를 거의 달성하지 못했지만 만족하는 경우를 상상해 본다. 적어도 3가지.<ol><li>공부 없이도 현금 흐름 및 수익이 생겼을 때? (몰론 운이겠지만..)</li><li>다른 KR에서 성과를 냈을 때? </li></ol></li></ul><h2 id="분기별-OKR"><a href="#분기별-OKR" class="headerlink" title="분기별 OKR"></a>분기별 OKR</h2><p>2~4 Quarter는 아직 먼 미래라서 별도의 OKR을 적어두진 않았다. 어차피 2022년 OKR이 있으니…<br>4월에 1 Quarter가 끝나고 회고를하면서 2, 3 Quarter를 작성할까 한다.</p><h3 id="1-Quarter-OKR"><a href="#1-Quarter-OKR" class="headerlink" title="1 Quarter OKR"></a>1 Quarter OKR</h3><p><strong>[목표]</strong></p><ul><li>건강을 찾고 새로운 탐험을 시작한다.</li></ul><p><strong>[목표가 중요한 이유]</strong></p><ul><li>지금까지 건강관리에 매우 소홀했다. 몸에 자잘자잘한 이상신호가 오고있고, 장기적인 관점에게 나에게 좋지 않다고 생각했다. 건강관리가 정신건강에도 영향을 주니까. 기초체력을 만드는게 중요하다고 생각한다.</li><li>집돌이가 되어서 주말에는 하루종일 침대에 누워서 생활한다. 집돌이가 되었다는게 부정적인 것은 아니나 공허함, 무기력감이 찾아왔다는게 중요한 것 같다. 새로운 변화를 만들어주면 이런 공허함, 무기력감이 사라지지 않을까?</li></ul><p><strong>[목표를 이루기 위해 필요한 결과(Key Result)]</strong></p><ol><li>DL쪽 이론 공부를 열심히 하고있고, 관련된 블로그 포스팅을 어설프더라도 5편 이상 작성한다.</li></ol><ul><li>아마 DL 쪽의 Transformer나 시계열쪽에 대한 이론 공부이지 않을까 싶다. 딥러닝 기초 공부이기도 하고?</li><li>이전까지는 주로 엔지니어링 위주로해서 이론적으로는 손을 많이 놓고 살았다. 최근 새로 공부하는게 짜릿한 기분이 들었다. 옛날과 비슷한 희열감도 느꼈던 것 같고..</li></ul><hr><ul><li>완벽히 달성했지만 불만족하는 경우를 상상해 본다. 적어도 3가지.<ol><li>주객이 전도된 상황. 블로그를 쓰기 위해서 공부하는 경우.</li><li>시간을 너무 뺏겨서 중요한 일을 하지 못한 경우</li><li>마음의 여유가 많이 없어지는 상황</li></ol></li><li>A를 거의 달성하지 못했지만 만족하는 경우를 상상해 본다. 적어도 3가지.<ol><li>블로그는 작성하지 못했지만, 스스로 이론이나 실무적인 지식을 깊게 탐구한 경우</li><li>건강, 관계에 있어서 충분히 에너지를 쏟으면서(균형을 지키면서) 실행한 경우</li></ol></li></ul><ol start="2"><li>허리와 관련된 코어 운동을 일주일에 3번 정도 하고있다. 또한 허리에 좋지 않은 습관들 10개정도는 숙지하고있고, 신경쓰고있다.</li></ol><ul><li>완벽히 달성했지만 불만족하는 경우를 상상해 본다. 적어도 3가지.<ol><li>운동이 너무 재미없고, 건강해진다는 느낌이 없다.</li><li>운동에 시간을 너무 뺐겨서 다른 일을 못하는 경우</li></ol></li><li>A를 거의 달성하지 못했지만 만족하는 경우를 상상해 본다. 적어도 3가지.<ol><li>건강과 업무의 균형을 잘 지키면서 했을 때</li><li>몇개의 습관이라도 완벽히 익혔을 때,</li></ol></li></ul><ol start="3"><li>커리어와 관련되지 않은 새로운 탐색을 2개 이상하고있다.</li></ol><ul><li>완벽히 달성했지만 불만족하는 경우를 상상해 본다. 적어도 3가지.<ol><li>너무 많은 일을 펼쳐서 정작 중요한 일을 못할 때</li><li>탐색한 결과들이 나에게 별 감흥이 없을 때, 시간낭비라는 생각이 들 때</li><li>에너지를 너무 많이 뺏길 때</li></ol></li><li>A를 거의 달성하지 못했지만 만족하는 경우를 상상해 본다. 적어도 3가지.<ol><li>그냥 새로운 탐색을 안하고 자신만의 시간(집에서 쉬는 것 등) 너무 좋고 편할 때</li><li>모종의 이유로 무기력감과 공허함이 사라졌을 때</li></ol></li></ul><ol start="4"><li>잠자기 전, 아침에 일어났을 때 이전과 다르게 에너지 레벨이 꽤 높다.</li></ol><ul><li>전체 OKR의 수면시간 변경사항에 적혀있어 생략한다.</li></ul><h3 id="2-Quarter-OKR"><a href="#2-Quarter-OKR" class="headerlink" title="2 Quarter OKR"></a>2 Quarter OKR</h3><p><strong>[목표]</strong></p><ul><li>관계에 있어서 새로운 시도를 해본다. 대화법 변경 등</li></ul><h3 id="3-Quarter-OKR"><a href="#3-Quarter-OKR" class="headerlink" title="3 Quarter OKR"></a>3 Quarter OKR</h3><p><strong>[목표]</strong></p><ul><li>경제적인 관점에서 새로운 시각을 얻는다.</li></ul><h3 id="4-Quarter-OKR"><a href="#4-Quarter-OKR" class="headerlink" title="4 Quarter OKR"></a>4 Quarter OKR</h3><p><strong>[목표]</strong></p><ul><li>커리어를 제외하고 새로운 탐험을 더 해본다.</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;2022년 Personal OKR을 작성해보았습니다.&lt;/p&gt;</summary>
    
    
    
    <category term="OKR" scheme="http://ssaru.github.io/categories/OKR/"/>
    
    
    <category term="OKR" scheme="http://ssaru.github.io/tags/OKR/"/>
    
  </entry>
  
  <entry>
    <title>Wide &amp; Deep Learning for Recommender Systems 리뷰</title>
    <link href="http://ssaru.github.io/2022/01/30/20220130_wide_and_deep_learning_for_recommender_systems/"/>
    <id>http://ssaru.github.io/2022/01/30/20220130_wide_and_deep_learning_for_recommender_systems/</id>
    <published>2022-01-30T10:44:00.000Z</published>
    <updated>2022-01-30T17:19:15.151Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><p>오늘 리뷰할 논문은 Google Play Store에 적용된 논문 “Wide &amp; Deep Learning for Recommender Systems”입니다.</p><p>리뷰 내용에는 제 나름대로 해석하고 의역한 내용이 많습니다.</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="추천시스템"><a href="#추천시스템" class="headerlink" title="추천시스템"></a>추천시스템</h3><p>논문에서는 추천 시스템을 search ranking system이라는 관점에서 보고있습니다.<br>즉, 입력은 사용자 정보와 맥락(contextual) 정보이고, 출력은 랭킹화된 아이템들의 리스트라는거죠.</p><p>추천 시스템을 search ranking system이라는 관점으로 해석한다면, 당연하게도 일반적인 search ranking system이 해결하고자하는 문제도 따라오게됩니다. 논문에서는 이를 “memorization”과 “generalization”이라고 주장합니다.</p><p>“memorization”은 과거 데이터에서 나타나는 특징(feature)와 아이템(items)의 상관관계를 학습하는 것을 의미하고, “generalization”은 과거 데이터들의 상관관계를 기반으로 한번도 본적이 없던 데이터 패턴에서 특징과 연관될 수 있는 아이템들을 추천해주는 것을 말합니다. 논문에서는 이를 “transitivity of correlation”이라고 이야기합니다.</p><p>논문에서는 “generalization”은 “memorization”과 비교했을 때, 추천 시스템의 다양성을 증가시켜주는 경향이 있다고 주장하는데요. 논문의 저자들은 “generalization”이 추천 시스템에서 매우 중요하다라고 주장하는 것으로 이해했습니다.</p><h3 id="“linear-model”-vs-“nonlinear-model”"><a href="#“linear-model”-vs-“nonlinear-model”" class="headerlink" title="“linear model” vs “nonlinear model”"></a>“linear model” vs “nonlinear model”</h3><p>산업계에서 대규모 온라인 추천 시스템, ranking system은 간단하면서 해석이 가능하고, 확장성이 좋은 linear model을 폭넓게 쓰고있습니다.</p><p>“memorization”은 sparse feature들을 cross-product transformation해서 효율적으로 달성이 가능하다고합니다.</p><p>예를들어 “<em>user_installed_app=netflix AND impression_app=pandora</em>“일 경우에 값을 “<em>1</em>“로 맵핑하는 것이죠. 이는 사용자가 이미 Netflix를 설치했고 그 이후에 “<em>pandora</em>“라는 앱을 본 것을 의미합니다. </p><p>즉, “<em>user_installed_app=netflix</em>“, “<em>impression_app=pandora</em>“라는 두 가지 feature를 가지고 하나의 feature를 새로 만드는 것이죠. 이렇게 cross-product transformation로 새로 만들어진 feature는 “<em>user_installed_app</em>“, “<em>impression_app</em>“라는 feature pair가 target label과 얼마나 상관관계가 있는지 직접적으로 설명할 수 있습니다.</p><p>“memorization”에서 “generalization”은 덜 세분화된 feature를 사용하여 추가할 수 있습니다. 예를들어 “<em>user_installed_category=video AND impression_category=music</em>“ 형태로 사용할 수 있죠. 다만, 이 경우에는 직접 raw data에서 이러한 cross-product transformation을 해서 새로운 feature table을 만드는 것 과 같은 feature engineering을 해줘야할 수 있습니다. 하지만 cross-product transformation은 학습 데이터에서 나타나지 않았던 query item - feature pair에 대해서는 generalization을 할 수 없다는 단점이 있습니다.</p><p>deep neural network나 factorization machine과 같은 embedding-based model은 낮은 차원의 query - item feature에 대한 dense embedding vector를 학습하여 이전에 보지 못했던 query-item feature pair를 일반화할 수 있습니다. embedding-based model은 상대적으로 feature engineering에 대한 부담이 적다는 장점이 있습니다. </p><p>아마 이는 상대적으로 cross-product transformation에 대한 부담이 크게 줄어서 그렇게 주장하지 않았을까 싶습니다.</p><p>하지만 embedding-based model은 query-item matrix가 고차원이고(rank가 높고) sparse한 경우 저차원에 대한 표현을 효과적으로 학습하기 어렵다는 단점이 있습니다. 예를들어 특정 선호도를 가진 사용자인데, 여러 사용자 그룹에서는 그 비율이 매우 작은 경우가 고차원이면서 sparse한 query-item matrix를 가지는 예가 될 수 있습니다. 이런 경우에는 대부분의 query pair들과 상호작용을 없게해줘야하지만, 그렇게 했을 경우에 모든 query pair에 대해서 0이 아닌 예측값을 출력하기 때문에 과하게 일반화가 되어 관련이 없는 추천 아이템을 추천해줄 수 있습니다. 반대로 linear model에서는 이러한 예외적인 문제를 더 작은 parameter로 기억할 수 있습니다.</p><p>저는 특정 분야에 선호도가 강한 매니악한 유저그룹의 경우 대부분의 유저 세그먼트에 비해서 비율이 낮지만 비지니스적으로는 유효할 수 있어서 잘 챙겨줘야한다는 이슈가 있다고 생각했습니다.</p><p>이런 경우에는 데이터 자체가 imbalance해서 함께 학습되면 학습이 안되어 따로 떼어내서 학습하거나 다른 lable에 영향을 덜 받는 방향으로 학습되도록 해야한다고 생각했습니다. 하지만 그럼에도 저차원에서 표현 학습이 잘 안되게되면 추천하는 item자체가 실제 사용자가 원하는 추천 아이템이 아닌 무작위의 item들을 추천해줄 확률이 높다고 생각했고, 논문에서는 이를 over-generalization이라고 표현했다고 생각합니다.</p><h2 id="Wide-amp-Deep-learning"><a href="#Wide-amp-Deep-learning" class="headerlink" title="Wide &amp; Deep learning"></a>Wide &amp; Deep learning</h2><p>딥러닝 아키텍쳐 자체는 매우 간단한 구조라서 아래 그림으로 설명이 충분한 것 같습니다.</p><p><img src="1.architecture_overview.png" alt="architecture overview"><br><img src="2.model_architecture.png" alt="model architecture"><br><img src="3.model_pipeline.png" alt="model pipeline"></p><p>모델 예측값은 아래 수식에 의해 결정됩니다.</p><p>$$P(Y=1|x)=\alpha(w^{T}_{wide}[x, \phi(x)] + w^{T}_{deep} a^{l_{f}}+b)$$</p><ul><li>$Y$: binary class label</li><li>$\alpha(\cdot)$: sigmoid function</li><li>$\phi(x)$: cross product transformation of the original features $x$</li><li>$b$: bias</li><li>$w_{wide}$: vector of all wide model weights</li><li>$w_{deep}$: weights applied on the final activations $a^{l_{f}}$</li></ul><h3 id="The-Wide-Component"><a href="#The-Wide-Component" class="headerlink" title="The Wide Component"></a>The Wide Component</h3><p>wide component는 $y=w^{T}x+b$ 형태의 일반화된 모델입니다.</p><ul><li>$y$: prediction</li><li>$x$: $x=[x_{1}, x_{2}, …, x_{d}]$와 같은 $d$ feature의 vector</li><li>$w$: $w=[w_{1}, w_{2}, …, w_{d}]$와 같은 model parameter</li><li>$b$: bias</li></ul><p>이 때, feature는 raw input과 transformed를 포함합니다. 여기서 가장 중요한 transformation은 cross-product transformation입니다.<br>$$\phi_{k}(x) = \prod^{d}_{i=1}x^{c_{ki}}_{i} \ \ \ \ c_{ki} \in {0, 1}$$</p><ul><li>$c_{ki}$: $i$번째 feature가 $k$번째의 변환인 $\phi_{k}$의 일부이면 1이고 그렇지 않으면 0인 boolean variable<ul><li>그냥 cross-product transformation을 수식화하기 위한 term이라고 보면 좋을 것 같습니다.</li><li>논문에서는 여러 변수들 간의 상호작용을 의미하고, 선형모델에 비선형성을 추가하는 역활을 한다고 이야기합니다. 문제는 binary 혹은 카테고리컬한 feature가 많으면 많을 수록 cross-product transformation이 경우의 수 만큼 증가하게될거라… 이를 어떻게 처리하면 좋을지 고민이 됩니다.</li></ul></li></ul><h3 id="The-Deep-Component"><a href="#The-Deep-Component" class="headerlink" title="The Deep Component"></a>The Deep Component</h3><p>deep component에서는 카테고리 feature를 다룰 때, embedding vector를 사용하면 되겠다는 생각이 들었습니다.<br>나머지 부분들은 아래 수식을 보고는 그냥 MLP라고 생각하면서 봤습니다.</p><p>$$a^{(l+1)} = f(W^{(l)}a^{(l)} + b^{(l)})$$</p><ul><li>$l$: layer number </li><li>$f$: activation function</li><li>$a$: activations</li><li>$W$: model weights</li><li>$b$: bias</li></ul><h2 id="System-Implementation"><a href="#System-Implementation" class="headerlink" title="System Implementation"></a>System Implementation</h2><h3 id="Data-Generation"><a href="#Data-Generation" class="headerlink" title="Data Generation"></a>Data Generation</h3><p>label은 app acquisition으로 impressed app이면 1이고 그렇지 않으면 0입니다. 아마 구글에서는 app을 설치했을 경우 “<em>impressed_app=1</em>“이라고 표기했나봅니다.<br>카테고리 feature는 정수로 구성된 id 공간을 mapping해서 사용했다고하는데, 저는 “<em>male=0</em>“, “<em>female=1</em>“ 이런 형태로 맵핑했다고 이해했습니다. 지금 이 논문을 구현한다면 저는 아마 NLP쪽의 embedding layer를 쓰면 되지 않을까 생각해봅니다. </p><p>continuous real-valued feature는 누적분포함수에 맵핑해서 $[0,1]$로 정규화했다고 합니다. </p><p>정확히 어떤 방식으로 했는지는 아직 감이 잘 안오네요.. min-max normalization을 하더라도 누적분포함수를 보존할 것 같은데… 그냥 이를 말로 길게 풀어놓은 것 같습니다. 만약에 min-max normalization이라면, unseen continous real-valued feature가 max값 보다 높아질 수 있는 가능성이 있는데, 이는 어떻게 처리했는지 궁금하네요.</p><h3 id="Model-Training"><a href="#Model-Training" class="headerlink" title="Model Training"></a>Model Training</h3><p>모델 학습 부분은 크게 눈에 띄는 부분이 없어서 생략했습니다.<br>궁금하신 분들은 논문을 보시면 좋을 것 같습니다.</p><h2 id="Experiment-Result"><a href="#Experiment-Result" class="headerlink" title="Experiment Result"></a>Experiment Result</h2><p>저는 실험결과에서 아래 테이블에서 보여주듯이 AUC에서는 Wide, Deep, Wide &amp; Deep 모두가 비슷하지만, 실제 Online에서는 Acquisition Gain이 높았던게 재밌었습니다.<br>서빙쪽은 크게 개선되었다고 써놓았는데, 단순 쓰레딩처리로 큰 novelty는 없어보여 사진이나 설명을 별도로 첨부하진 않았습니다.</p><p><img src="4.result.png" alt="result"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;구글의 2016년 Wide &amp;amp; Deep Learning for Recommender Systems 논문 리뷰입니다.&lt;/p&gt;</summary>
    
    
    
    <category term="Ai" scheme="http://ssaru.github.io/categories/Ai/"/>
    
    <category term="Paper review" scheme="http://ssaru.github.io/categories/Ai/Paper-review/"/>
    
    
    <category term="Recommender Systems" scheme="http://ssaru.github.io/tags/Recommender-Systems/"/>
    
    <category term="Neural Network" scheme="http://ssaru.github.io/tags/Neural-Network/"/>
    
  </entry>
  
  <entry>
    <title>Ray Datasets 사용하기</title>
    <link href="http://ssaru.github.io/2021/11/26/20211126-ray_datasets/"/>
    <id>http://ssaru.github.io/2021/11/26/20211126-ray_datasets/</id>
    <published>2021-11-26T12:18:00.000Z</published>
    <updated>2021-12-01T15:55:35.201Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><p>글쓰기에 앞서 본 포스팅은 제가 Ray Datasets를 이해하고자 쓰는 글입니다.<br>글의 구성은 1). Ray Datasets에 대한 공식문서 번역, 2). parquet 파일을 Ray Dataset으로 활용하는 방법에 대해서 소개하려고 합니다.</p><h2 id="Ray-Datasets"><a href="#Ray-Datasets" class="headerlink" title="Ray Datasets"></a>Ray Datasets</h2><p><a href="https://docs.ray.io/en/latest/data/dataset.html">Ray Dataset</a>은 Ray 라이브러리와 애플리케이션에서 데이터를 불러오고 교환하는데 사용하는 기본적인 방법입니다. Datasets는 <code>map.filter</code>, <code>repartition</code>과 같은 분산 데이터 변환을 기본적으로 제공하고, 다양한 데이터 포맷, 데이터 소스, 분산 프레임워크와 호환됩니다.</p><p><img src="1.dataset.svg" alt="datasets"></p><h3 id="개념"><a href="#개념" class="headerlink" title="개념"></a>개념</h3><p>Ray Datasets는 <a href="https://arrow.apache.org/">Distributed Arrow</a>의 구현체입니다. Dataset은 <code>block</code>을 참조하고있는 Ray object의 list로 구성되어있습니다. 각 block은 Python list나 <a href="https://arrow.apache.org/docs/python/data.html#tables">Arrow Table</a>을 가지고있습니다. Dataset에 다수의 block이 있다면, 데이터 병렬 변환 및 수집이 가능합니다.</p><p>다음은 3개의 Arrow table block를 갖는 Dataset을 시각화한 그림입니다. 여기서 각 block은 1,000개의 row를 가지고있다고 가정했습니다.</p><p><img src="2.dataset-arch.svg" alt="dataset-arch"></p><p>Ray Dataset은 Ray object reference들을 모아놓은 list일 뿐이므로, Ray tasks, actor, 라이브러리 간에 자유롭게 전달할 수 있습니다. 이러한 유연성은 Ray Dataset의 고유한 특징입니다.</p><p>Spark RDDs나 Dask Bags과 비교했을 때, Datasets은 조금 더 기본적인 feature의 집합을 제공하고 단순함을 위해 작업(operation)을 즉시 실행(eagerly)합니다. 이는 사용자가 Datasets를 다른 dataframe type(<code>ds.to_dask()</code>)으로 casting할 수 있도록 의도한 것입니다. 다른 dataframe type으로 cating하게되면, 특정 dataframe type에서만 사용할 수 있는 고급 operation을 사용할 수 있게됩니다.</p><p>호환되는 Datasource 리스트는 <a href="https://docs.ray.io/en/latest/data/dataset.html#datasource-compatibility-matrices">링크</a>에서 확인할 수 있습니다.</p><h3 id="Datasets-만들기"><a href="#Datasets-만들기" class="headerlink" title="Datasets 만들기"></a>Datasets 만들기</h3><p><code>ray.data.range()</code>와 <code>ray.data.from_items()</code>를 이용해서 생성된 데이터로 Ray Datasets를 만들어볼 수 있습니다. 이 때, Datasets는 Plain Python object나 Arrow records를 갖게됩니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ray</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a Dataset of Python objects.</span></span><br><span class="line">ds = ray.data.<span class="built_in">range</span>(<span class="number">10000</span>)</span><br><span class="line"><span class="comment"># -&gt; Dataset(num_blocks=200, num_rows=10000, schema=&lt;class &#x27;int&#x27;&gt;)</span></span><br><span class="line"></span><br><span class="line">ds.take(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># -&gt; [0, 1, 2, 3, 4]</span></span><br><span class="line"></span><br><span class="line">ds.count()</span><br><span class="line"><span class="comment"># -&gt; 10000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a Dataset of Arrow records.</span></span><br><span class="line">ds = ray.data.from_items([&#123;<span class="string">&quot;col1&quot;</span>: i, <span class="string">&quot;col2&quot;</span>: <span class="built_in">str</span>(i)&#125; <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>)])</span><br><span class="line"><span class="comment"># -&gt; Dataset(num_blocks=200, num_rows=10000, schema=&#123;col1: int64, col2: string&#125;)</span></span><br><span class="line"></span><br><span class="line">ds.show(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># -&gt; ArrowRow(&#123;&#x27;col1&#x27;: 0, &#x27;col2&#x27;: &#x27;0&#x27;&#125;)</span></span><br><span class="line"><span class="comment"># -&gt; ArrowRow(&#123;&#x27;col1&#x27;: 1, &#x27;col2&#x27;: &#x27;1&#x27;&#125;)</span></span><br><span class="line"><span class="comment"># -&gt; ArrowRow(&#123;&#x27;col1&#x27;: 2, &#x27;col2&#x27;: &#x27;2&#x27;&#125;)</span></span><br><span class="line"><span class="comment"># -&gt; ArrowRow(&#123;&#x27;col1&#x27;: 3, &#x27;col2&#x27;: &#x27;3&#x27;&#125;)</span></span><br><span class="line"><span class="comment"># -&gt; ArrowRow(&#123;&#x27;col1&#x27;: 4, &#x27;col2&#x27;: &#x27;4&#x27;&#125;)</span></span><br><span class="line"></span><br><span class="line">ds.schema()</span><br><span class="line"><span class="comment"># -&gt; col1: int64</span></span><br><span class="line"><span class="comment"># -&gt; col2: string</span></span><br></pre></td></tr></table></figure><p>Datasets는 local disk의 파일이나 S3와 같이 원격 datasource로부터 만들 수도 있습니다. pyarrow가 지원하는 filesystem이라면 특정한 파일 위치를 사용하면 됩니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Read a directory of files in remote storage.</span></span><br><span class="line">ds = ray.data.read_csv(<span class="string">&quot;s3://bucket/path&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read multiple local files.</span></span><br><span class="line">ds = ray.data.read_csv([<span class="string">&quot;/path/to/file1&quot;</span>, <span class="string">&quot;/path/to/file2&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Read multiple directories.</span></span><br><span class="line">ds = ray.data.read_csv([<span class="string">&quot;s3://bucket/path1&quot;</span>, <span class="string">&quot;s3://bucket/path2&quot;</span>])</span><br></pre></td></tr></table></figure><p>마지막으로, Ray object store에 있거나 Ray와 호환되는 Distributed DataFrame에 있는 데이터로부터 Dataset을 만들 수 있습니다. 아래 예제는 <code>pandas</code>의 <code>DataFrame</code>과 <code>dask</code>의 <code>dataframe</code>을 Ray Dataset으로 변환하는 예제입니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> dask.dataframe <span class="keyword">as</span> dd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a Dataset from a list of Pandas DataFrame objects.</span></span><br><span class="line">pdf = pd.DataFrame(&#123;<span class="string">&quot;one&quot;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&quot;two&quot;</span>: [<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>]&#125;)</span><br><span class="line">ds = ray.data.from_pandas([pdf])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a Dataset from a Dask-on-Ray DataFrame.</span></span><br><span class="line">dask_df = dd.from_pandas(pdf, npartitions=<span class="number">10</span>)</span><br><span class="line">ds = ray.data.from_dask(dask_df)</span><br></pre></td></tr></table></figure><h3 id="Datasets-저장하기"><a href="#Datasets-저장하기" class="headerlink" title="Datasets 저장하기"></a>Datasets 저장하기</h3><p>Datasets는 <code>.write_csv()</code>, <code>.write_json()</code>, <code>.write_parquet()</code> API를 통해 local이나 remote storage에 저장할 수 있습니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Write to csv files in /tmp/output.</span></span><br><span class="line">ray.data.<span class="built_in">range</span>(<span class="number">10000</span>).write_csv(<span class="string">&quot;/tmp/output&quot;</span>)</span><br><span class="line"><span class="comment"># -&gt; /tmp/output/data0.csv, /tmp/output/data1.csv, ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use repartition to control the number of output files:</span></span><br><span class="line">ray.data.<span class="built_in">range</span>(<span class="number">10000</span>).repartition(<span class="number">1</span>).write_csv(<span class="string">&quot;/tmp/output2&quot;</span>)</span><br><span class="line"><span class="comment"># -&gt; /tmp/output2/data0.csv</span></span><br></pre></td></tr></table></figure><p>또한 Dataset을 Ray와 호환되는 Distributed DataFrames로 변환할 수 있습니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Convert a Ray Dataset into a Dask-on-Ray DataFrame.</span></span><br><span class="line">dask_df = ds.to_dask()</span><br></pre></td></tr></table></figure><h3 id="Dataset-변환"><a href="#Dataset-변환" class="headerlink" title="Dataset 변환"></a>Dataset 변환</h3><p>Datasets는 <code>.map()</code>을 사용하면 병렬적으로 변환작업을 수행할 수 있습니다. 변환(Transformation)은 즉시(eagerly) 실행되며 작업(operation)이 끝날 때까지 blocking됩니다. Datasets는 <code>.filter()</code>, <code>.flat_map()</code>을 지원합니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ds = ray.data.<span class="built_in">range</span>(<span class="number">10000</span>)</span><br><span class="line">ds = ds.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x * <span class="number">2</span>)</span><br><span class="line"><span class="comment"># -&gt; Map Progress: 100%|████████████████████| 200/200 [00:00&lt;00:00, 1123.54it/s]</span></span><br><span class="line"><span class="comment"># -&gt; Dataset(num_blocks=200, num_rows=10000, schema=&lt;class &#x27;int&#x27;&gt;)</span></span><br><span class="line">ds.take(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># -&gt; [0, 2, 4, 6, 8]</span></span><br><span class="line"></span><br><span class="line">ds.<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x &gt; <span class="number">5</span>).take(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># -&gt; Map Progress: 100%|████████████████████| 200/200 [00:00&lt;00:00, 1859.63it/s]</span></span><br><span class="line"><span class="comment"># -&gt; [6, 8, 10, 12, 14]</span></span><br><span class="line"></span><br><span class="line">ds.flat_map(<span class="keyword">lambda</span> x: [x, -x]).take(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># -&gt; Map Progress: 100%|████████████████████| 200/200 [00:00&lt;00:00, 1568.10it/s]</span></span><br><span class="line"><span class="comment"># -&gt; [0, 0, 2, -2, 4]</span></span><br></pre></td></tr></table></figure><p>벡터화 함수(vectorized function)의 장점을 취하고 싶을 때에는 <code>.map_batches()</code>를 사용할 수 있습니다.</p><blockquote><p><code>filter</code>, <code>flat_map</code>을 <code>.map_batches()</code>를 통해 구현할 수 있습니다. 이 때, map function은 특정 크기를 갖는 batch 출력을 반환해야합니다.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ds = ray.data.range_arrow(<span class="number">10000</span>)</span><br><span class="line">ds = ds.map_batches(<span class="keyword">lambda</span> df: df.applymap(<span class="keyword">lambda</span> x: x * <span class="number">2</span>), batch_format=<span class="string">&quot;pandas&quot;</span>)</span><br><span class="line"><span class="comment"># -&gt; Map Progress: 100%|████████████████████| 200/200 [00:00&lt;00:00, 1927.62it/s]</span></span><br><span class="line">ds.take(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># -&gt; [ArrowRow(&#123;&#x27;value&#x27;: 0&#125;), ArrowRow(&#123;&#x27;value&#x27;: 2&#125;), ...]</span></span><br></pre></td></tr></table></figure><p>변환은 기본적으로 Ray tasks를 사용해서 실행됩니다. 설정이 필요한 변환의 경우 <code>compute=&quot;actors&quot;</code>를 지정합니다. <code>compute=&quot;actors&quot;</code>를 설정하면, Ray는 autoscaling actor pool을 사용하여 변환작업을 실행합니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example of GPU batch inference on an ImageNet model.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span>(<span class="params">image: <span class="built_in">bytes</span></span>) -&gt; <span class="built_in">bytes</span>:</span></span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BatchInferModel</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.model = ImageNetModel()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, batch: pd.DataFrame</span>) -&gt; pd.DataFrame:</span></span><br><span class="line">        <span class="keyword">return</span> self.model(batch)</span><br><span class="line"></span><br><span class="line">ds = ray.data.read_binary_files(<span class="string">&quot;s3://bucket/image-dir&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Preprocess the data.</span></span><br><span class="line">ds = ds.<span class="built_in">map</span>(preprocess)</span><br><span class="line"><span class="comment"># -&gt; Map Progress: 100%|████████████████████| 200/200 [00:00&lt;00:00, 1123.54it/s]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Apply GPU batch inference with actors, and assign each actor a GPU using</span></span><br><span class="line"><span class="comment"># ``num_gpus=1`` (any Ray remote decorator argument can be used here).</span></span><br><span class="line">ds = ds.map_batches(BatchInferModel, compute=<span class="string">&quot;actors&quot;</span>, batch_size=<span class="number">256</span>, num_gpus=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># -&gt; Map Progress (16 actors 4 pending): 100%|██████| 200/200 [00:07, 27.60it/s]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the results.</span></span><br><span class="line">ds.repartition(<span class="number">1</span>).write_json(<span class="string">&quot;s3://bucket/inference-results&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="Datasets의-교환"><a href="#Datasets의-교환" class="headerlink" title="Datasets의 교환"></a>Datasets의 교환</h3><p>Datasets는 Ray tasks나 actor에 전달할 수 있고 <code>.iter_batches()</code>나 <code>.iter_rows()</code>를 통해 읽어들일 수 있습니다. 이 때, 읽기 작업은 복사를 수행하는 것이 아니라 block들의 reference가 담긴 Ray objects로 전달합니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">consume</span>(<span class="params">data: Dataset[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">    num_batches = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> data.iter_batches():</span><br><span class="line">        num_batches += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> num_batches</span><br><span class="line"></span><br><span class="line">ds = ray.data.<span class="built_in">range</span>(<span class="number">10000</span>)</span><br><span class="line">ray.get(consume.remote(ds))</span><br><span class="line"><span class="comment"># -&gt; 200</span></span><br></pre></td></tr></table></figure><p>Datasets는 sub-datasets로 분리할 수 있습니다. 원하는 분할 개수와 actor의 handle을 <code>split()</code>함수에 전달하면 Locality-aware 분리를 수행할 수 있습니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ray.remote(<span class="params">num_gpus=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Worker</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, rank: <span class="built_in">int</span></span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">self, shard: ray.data.Dataset[<span class="built_in">int</span>]</span>) -&gt; <span class="built_in">int</span>:</span></span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> shard.iter_batches(batch_size=<span class="number">256</span>):</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">return</span> shard.count()</span><br><span class="line"></span><br><span class="line">workers = [Worker.remote(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>)]</span><br><span class="line"><span class="comment"># -&gt; [Actor(Worker, ...), Actor(Worker, ...), ...]</span></span><br><span class="line"></span><br><span class="line">ds = ray.data.<span class="built_in">range</span>(<span class="number">10000</span>)</span><br><span class="line"><span class="comment"># -&gt; Dataset(num_blocks=200, num_rows=10000, schema=&lt;class &#x27;int&#x27;&gt;)</span></span><br><span class="line"></span><br><span class="line">shards = ds.split(n=<span class="number">16</span>, locality_hints=workers)</span><br><span class="line"><span class="comment"># -&gt; [Dataset(num_blocks=13, num_rows=650, schema=&lt;class &#x27;int&#x27;&gt;),</span></span><br><span class="line"><span class="comment">#     Dataset(num_blocks=13, num_rows=650, schema=&lt;class &#x27;int&#x27;&gt;), ...]</span></span><br><span class="line"></span><br><span class="line">ray.get([w.train.remote(s) <span class="keyword">for</span> s <span class="keyword">in</span> shards])</span><br><span class="line"><span class="comment"># -&gt; [650, 650, ...]</span></span><br></pre></td></tr></table></figure><h3 id="Custom-Datasources"><a href="#Custom-Datasources" class="headerlink" title="Custom Datasources"></a>Custom Datasources</h3><p>Datasets는 python에서 정의된 <a href="https://docs.ray.io/en/latest/data/package-ref.html#custom-datasource-api">custom datasource</a>을 사용해서 병렬적으로 read/write작업을 수행할 수 있습니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Read from a custom datasource.</span></span><br><span class="line">ds = ray.data.read_datasource(YourCustomDatasource(), **read_args)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Write to a custom datasource.</span></span><br><span class="line">ds.write_datasource(YourCustomDatasource(), **write_args)</span><br></pre></td></tr></table></figure><h2 id="문제상황"><a href="#문제상황" class="headerlink" title="문제상황"></a>문제상황</h2><p>용량이 매우 큰 parquet 파일들을 읽어들여 Ray tasks에 전달하여 작업해야한다고 했을 때, 이를 Datasets로 처리할 수 있습니다.</p><h3 id="예제-데이터를-parquet-파일로-변환하기"><a href="#예제-데이터를-parquet-파일로-변환하기" class="headerlink" title="예제 데이터를 parquet 파일로 변환하기"></a>예제 데이터를 parquet 파일로 변환하기</h3><p>json data를 pandas의 DataFrame으로 읽어들이고 이를 <code>sample.parq</code> 이름으로 저장합니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">json_data = &#123;<span class="string">&quot;col1&quot;</span>:&#123;<span class="string">&quot;row1&quot;</span>:<span class="number">1</span>,<span class="string">&quot;row2&quot;</span>:<span class="number">2</span>,<span class="string">&quot;row3&quot;</span>:<span class="number">3</span>&#125;,<span class="string">&quot;col2&quot;</span>:&#123;<span class="string">&quot;row1&quot;</span>:<span class="string">&quot;x&quot;</span>,<span class="string">&quot;row2&quot;</span>:<span class="string">&quot;y&quot;</span>,<span class="string">&quot;row3&quot;</span>:<span class="string">&quot;z&quot;</span>&#125;&#125;</span><br><span class="line">df = pd.DataFrame(json_data)</span><br><span class="line"></span><br><span class="line">df.to_parquet(<span class="string">&quot;./sample/sample.parq&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="Ray-Dataset을-사용하는-actor를-정의하기"><a href="#Ray-Dataset을-사용하는-actor를-정의하기" class="headerlink" title="Ray Dataset을 사용하는 actor를 정의하기"></a>Ray Dataset을 사용하는 actor를 정의하기</h3><p>Ray의 Dataset을 batch로 처리하는 actor class를 정의합니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ray</span><br><span class="line"></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Worker</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, rank: <span class="built_in">int</span></span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_df_from_ds</span>(<span class="params">self, shard: ray.data.Dataset</span>):</span></span><br><span class="line">        l = []</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> shard.iter_batches():</span><br><span class="line">            df = batch.to_pandas()</span><br><span class="line">            l.append(df)</span><br><span class="line">            <span class="comment"># ... pandas processing</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> l</span><br></pre></td></tr></table></figure><h3 id="Ray-Datasets를-생성하기"><a href="#Ray-Datasets를-생성하기" class="headerlink" title="Ray Datasets를 생성하기"></a>Ray Datasets를 생성하기</h3><p>이전에 저장했던 <code>sample.parq</code>을 Ray Dataset으로 만듭니다. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> ray</span><br><span class="line"></span><br><span class="line"><span class="comment"># 절대경로 필수</span></span><br><span class="line">data_path = Path(<span class="string">&quot;./sample&quot;</span>).absolute()</span><br><span class="line"></span><br><span class="line">parq_list = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">str</span>, data_path.glob(<span class="string">&quot;*.parq&quot;</span>)))</span><br><span class="line">ds = ray.data.read_parquet(parq_list)</span><br></pre></td></tr></table></figure><h3 id="Ray-Datasets-Split하기"><a href="#Ray-Datasets-Split하기" class="headerlink" title="Ray Datasets Split하기"></a>Ray Datasets Split하기</h3><p>locality-aware을 사용해서 Datasets을 split해줍니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">workers = [Worker.remote(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">shards = ds.split(n=<span class="number">10</span>, locality_hints=workers)</span><br></pre></td></tr></table></figure><h3 id="Split한-데이터를-처리하기"><a href="#Split한-데이터를-처리하기" class="headerlink" title="Split한 데이터를 처리하기"></a>Split한 데이터를 처리하기</h3><p>아래 코드를 실행하여 split한 데이터를 처리합니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ray.init()</span><br><span class="line"><span class="built_in">print</span>(ray.get([workers[rank].load_df_from_ds.remote(s) <span class="keyword">for</span> rank, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(shards)]))</span><br><span class="line">ray.shutdown()</span><br></pre></td></tr></table></figure><h3 id="전체코드"><a href="#전체코드" class="headerlink" title="전체코드"></a>전체코드</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> ray</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ray 실행</span></span><br><span class="line">ray.init()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ray actor class 정의</span></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Worker</span>():</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, rank: <span class="built_in">int</span></span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_df_from_ds</span>(<span class="params">self, shard: ray.data.Dataset</span>):</span></span><br><span class="line">        l = []</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> shard.iter_batches():</span><br><span class="line">            df = batch.to_pandas()</span><br><span class="line">            l.append(df)</span><br><span class="line">            <span class="comment"># ... pandas processing</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 샘플 데이터 저장</span></span><br><span class="line">json_data = &#123;<span class="string">&quot;col1&quot;</span>:&#123;<span class="string">&quot;row1&quot;</span>:<span class="number">1</span>,<span class="string">&quot;row2&quot;</span>:<span class="number">2</span>,<span class="string">&quot;row3&quot;</span>:<span class="number">3</span>&#125;,<span class="string">&quot;col2&quot;</span>:&#123;<span class="string">&quot;row1&quot;</span>:<span class="string">&quot;x&quot;</span>,<span class="string">&quot;row2&quot;</span>:<span class="string">&quot;y&quot;</span>,<span class="string">&quot;row3&quot;</span>:<span class="string">&quot;z&quot;</span>&#125;&#125;</span><br><span class="line">df = pd.DataFrame(json_data)</span><br><span class="line"></span><br><span class="line">df.to_parquet(<span class="string">&quot;./sample/sample.parq&quot;</span>)</span><br><span class="line"></span><br><span class="line">data_path = Path(<span class="string">&quot;./sample&quot;</span>).absolute()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터셋 로드</span></span><br><span class="line">parq_list = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">str</span>, data_path.glob(<span class="string">&quot;*.parq&quot;</span>)))</span><br><span class="line">ds = ray.data.read_parquet(parq_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ray actor 생성 및 Ray Datasets을 split</span></span><br><span class="line">workers = [Worker.remote(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">shards = ds.split(n=<span class="number">10</span>, locality_hints=workers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ray 코드 실행</span></span><br><span class="line"><span class="built_in">print</span>(ray.get([workers[rank].load_df_from_ds.remote(s) <span class="keyword">for</span> rank, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(shards)]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Ray 중지</span></span><br><span class="line">ray.shutdown()</span><br></pre></td></tr></table></figure><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://docs.ray.io/en/latest/data/dataset.html">Datasets: Flexible Distributed Data Loading</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;이번 포스팅은 Ray에서 제공하는 Dataset에 대해서 알아봅니다.&lt;/p&gt;</summary>
    
    
    
    <category term="Software" scheme="http://ssaru.github.io/categories/Software/"/>
    
    <category term="Disbritubed Computing" scheme="http://ssaru.github.io/categories/Software/Disbritubed-Computing/"/>
    
    
    <category term="Python" scheme="http://ssaru.github.io/tags/Python/"/>
    
    <category term="Distributed" scheme="http://ssaru.github.io/tags/Distributed/"/>
    
    <category term="Parallel" scheme="http://ssaru.github.io/tags/Parallel/"/>
    
    <category term="Ray" scheme="http://ssaru.github.io/tags/Ray/"/>
    
  </entry>
  
  <entry>
    <title>3번째, 퇴사. 그리고 회고</title>
    <link href="http://ssaru.github.io/2021/09/09/20210907-quit_company/"/>
    <id>http://ssaru.github.io/2021/09/09/20210907-quit_company/</id>
    <published>2021-09-09T06:19:00.000Z</published>
    <updated>2022-01-03T09:44:12.048Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><p>먼저, 글을 풀어내기 전에 제가 쓴 글이 읽는 분들께 어떻게 읽힐지 예측이 안되기 때문에 두려운 마음이 큽니다. 마치 살얼음이 깨질까 까치발을 들고 얼어붙은 호수를 건너가는 기분이랄까요? 그럼에도 불구하고, 먼 미래의 나를 위해, 중간지점을 찍어두는게 좋을 것 같다고 생각하기에 조심스럽게 적어봅니다.</p><p>저는 2021년 8월 31일부로 퇴사하게되었습니다. 입사한지 3년 7개월만이네요.<br>퇴사를 결심했다면, 결심한 저 나름의 이유가 있었던 것 같습니다. 그래서 그 이야기들을 해볼까 합니다.</p><ol><li>지금 회사로 오게 된 이유</li><li>지금 회사에서 이루고 싶었던 것</li><li>회사에서 일하면서 성장한 것들</li><li>회사에서 일하면서 아쉬웠던 것들</li><li>이직을 한다면 시도해보고 싶은 것들</li></ol><h2 id="지금-회사로-오게-된-이유"><a href="#지금-회사로-오게-된-이유" class="headerlink" title="지금 회사로 오게 된 이유"></a>지금 회사로 오게 된 이유</h2><p>원래 저는 AI 스타트업에서 근무 중이었습니다. 했던 역활은 사업 아이디어들을 실현하기 위한 기술을 제안하고 구현해나가는 것 이었습니다. 사업을 만들어나가는 과정이 고되긴 했지만, 과정 자체를 경험하는 것은 재미있었습니다. 아쉬움이 있다면 딥러닝 엔지니어가 저 혼자뿐이라는 것 정도….?</p><p>그러던 와중에 <a href="https://modulabs.co.kr/">모두의 연구소</a>라는 곳을 알게되었고, 자율자동차에서 사용되는 영상처리 기술에 대해서 공부하는 연구실에 들어갔습니다. 연구실 사람들과 논문을 읽고 학술적인 논의를 하면서 “함께 무언가를 한다는 것이 이렇게 재밌을 수 있구나”라는 것을 느꼈던 것 같습니다.</p><p>어느날, 함께 공부하던 연구원 분 중 한 분이 자신이 일하는 연구소에서 자율차 연구를 하고있고 차량이 준비될 예정인데, 함께하지 않겠냐는 감사한 제안을 주셨습니다.</p><p>모두의 연구소의 즐거웠던 경험이 업무로 확장되어 재밌게 일할 수 있겠다는 생각도 있었고, 연구소 환경은 어떤지, 그리고 연구소의 환경은 어떤지 호기심이 들어서 이직하게되었습니다.</p><h2 id="지금-회사에서-해보고-싶었던-것"><a href="#지금-회사에서-해보고-싶었던-것" class="headerlink" title="지금 회사에서 해보고 싶었던 것"></a>지금 회사에서 해보고 싶었던 것</h2><p>지금 회사로 이직하면서, 저는 몇가지 목표를 세웠습니다.</p><ol><li>3년 이상 근속해 보기</li><li>능력을 인정받아보기</li></ol><p>“1. 3년 이상 근속”은 잦은 이직이 제 커리어게 긍정적이지 않겠다는 생각과 3년 정도는 버틸 수 있는 사람인지 확인해보고자했고, “2. 능력을 인정받아보자”는 대체 불가능한 사람을 꿈꿨기 때문에 그랬던 것 같습니다.</p><p>하지만 입사하고 난 후, 1년 안에 팀이 공중분해되어 다른 부서로 발령이 났습니다.</p><p>발령된 부서는 클라우드 및 인프라 기술을 연구하는 팀이었고, 연구 주제는 AI 지원하는 인프라 기술이었습니다. 지금은 그걸 MLOps라고 부르죠. 특이사항으로는 옆에 있는 헬스케어팀에서 필요한 인공지능 기술을 연구하고 개발해야한다는 점이 있었습니다.</p><p>당시에는 이직을 해야하는가에 대해서 격정적인 고민 사이에 있었는데요. 인프라 기술을 경험해보고싶다는 생각이 들어서 계속 근무하게 되었습니다.</p><p>돌이켜보면 리서치 엔지니어만으로는 무언가를 이루기 어렵겠다는 생각이 지배적이었던 것 같습니다. 부족하겠지만 필요하다면 대부분의 것들을 혼자 해볼 수 있는 사람이 되고싶었습니다.</p><h2 id="회사에서-일하면서-성장한-것들"><a href="#회사에서-일하면서-성장한-것들" class="headerlink" title="회사에서 일하면서 성장한 것들"></a>회사에서 일하면서 성장한 것들</h2><p>연구소에서 3년 6개월 동안 일하면서 아래 항목들을 배운 것 같습니다.<br>항목들의 순서는 제가 생각했을 때, 저에게 도움이 많이 되었던 경험 순서대로입니다.</p><ol><li>다른 사람들의 삶을 존중하는 태도</li><li>짧은 시간에 단거리 달리기하고 성과내기</li><li>비문없이 커뮤니케이션하기</li><li>아키텍쳐 그림 잘 표현하고, PPT에 잘 녹이기</li><li>논리적인 글쓰기</li><li>동시다발적으로 들어오는 많은 일들 다뤄보기</li><li>K8S, 컨테이너 기술, OS, 네트워크 관련 지식</li></ol><p>이 중에 제일 받아들이기 어려웠던 것은 “1. 다른 사람들의 삶을 존중하는 태도” 였네요.</p><p>“1. 다른 사람들의 삶을 존중하는 태도”를 못했을 때, 치명적인 단점은 제가 동료들에게는 함께 일하기 싫은 사람이 된다는 것입니다. 저는 “무릇 개발자란 이래야한다~”라는 이상적인 모양이 있었던 터라 다른 “개발보다는 개인의 삶이 중요했던”사람들을 이해하기 어려웠었네요.</p><p>아마 대학교때부터 개발을 놀이처럼 하기도 했었고, 늦깎이 비전공자 출신이라 도태될까하는 두려움에 여유시간 대부분을 자기계발에 쏟는 삶을 살아와서 그랬을 수 있습니다.</p><p>아이러니하게도 다양한 삶에 대한 이해나 필요성이 아주 강력하게 각인되는 계기가 있었는데, 업무를 과하게하다가 병이 생기면서 제 삶의 가치관에 대해서 다시 한 번 생각해봤던 것 같습니다.</p><h2 id="회사에서-일하면서-아쉬웠던-것들"><a href="#회사에서-일하면서-아쉬웠던-것들" class="headerlink" title="회사에서 일하면서 아쉬웠던 것들"></a>회사에서 일하면서 아쉬웠던 것들</h2><p>아쉬운 점이라고하면!… 퇴사하게 된 계기와도 맞물리는 것이겠죠?.<br>퇴사를 결심하게 된 계기는 더 이상 새로운 것에 도전적이지 않은 사람이 되어가는 제 모습을 알아차렸을 때였던 것 같습니다.</p><p>도전적이지 않게 된 이유는 초기에 조직의 변화를 만들어내는 시도에서 왔던 좌절감도 있었을 것이고, 업무 부하가 강해짐에 따라서 스스로를 살필 수 있는 심적 여유가 사라졌던게 제일 큰 것 같습니다.</p><p>주변의 다양한 일들로부터 한발 떨어져서 어떤 상황이고, 이 상황에서 내가 해볼 수 있는 시도나 선택할 수 있는 선택지가 무엇이 있는지 전략적으로 살펴볼 수 있어야했는데, 심적여유가 많이 사라지다보니 새로운 일들이 들어오거나 변화가 발생하면 일단 저항하거나 방어하고있는 모습을 발견하게 되었습니다.</p><p>처음에는 시간이 지나면 나아질 것이라고 생각했던 것 같은데, 실제로는 시간이 지나면 지날 수록 스스로 부정적인 감정을 감당하기 어렵다는 생각이 들었습니다.</p><p>일정조정, 업무조정, 회사와의 대화와 같은 시도에서 타협점을 찾기가 어렵다는 생각이 들었고, 그렇게 저는 퇴사를 결심하게 되었습니다.</p><h2 id="이직을-한다면-시도해보고-싶은-것들"><a href="#이직을-한다면-시도해보고-싶은-것들" class="headerlink" title="이직을 한다면 시도해보고 싶은 것들"></a>이직을 한다면 시도해보고 싶은 것들</h2><p>지금의 저는 퇴사를 하고 천천히 지난 3년 7개월을 돌아보는 시간을 가지고있습니다. 일하느라 바쁘다는 핑계로 돌보지 못했던 제 삶의 다른 영역도 돌보고있고요.</p><p>제가 다음 회사를 가서 개인적으로 해보고싶은 것을 한 문장으로 표현하자면 “나의 감정 상태와 내가 선택할 수 있는 선택지들을 큰 시각에서 살펴보고 선택할 수 있는 힘을 기르는 것”이 될 것 같습니다.</p><p>저는 퇴사하기 직전에 AC2과정을 수강하고있었는데요. AC2에서 들었던 1). “마인크래프트로 하는 협력 시뮬레이션”, 2). “KAI 점수에 따른 의사결정 양상”, 3). “마인드 리딩”, 4). “CTA”, 5). “퍼실리테이션”과 같은 워크샵들은 잘 몰랐던 제 모습을 적나라하게 보여준다는 측면에서 굉장히 충격적이었어요. AC2에서 들었던 워크샵 덕분에 저는 특정 상황에서 트리거링되는 제 감정상태와 무의식적인 선택패턴들을 살펴볼 수 있었습니다. </p><p>이후, 남은 AC2과정에서 저는 코치님, 멘토님과 함께 저의 무의식적인 패턴을 알아차리고 의식적으로 다른 선택을 하는 변화를 시도하는 연습을 하게되었는데요. 이런 시도들이 회사에서도 충분히 작동한다는 것을 느끼게되면서 저는 이를 점점 더 발전시켜나가고 싶었습니다. AC2에서 배운 전략들은 다른 부수적인 것들을 모두 포함하고있는 상위수준의 전략이라고 느꼈기 때문에 제가 달성하기 원하는 목표들은 부수적으로 달성되지 않을까 생각했습니다.</p><p>대충 꾸준히 해볼 수 있는 것들은 아래정도이지 않을까 싶습니다.</p><ul><li>AC2에서 배웠던 1). 5FS + 2). 감정, 욕구 자가진단 도구 + 3). 지도 그리며 일하기 + 4). 마크포스터의 시간관리 기법을 혼합한 노트를 적극적으로 작성하기</li><li>사람 관계에서 마인드 리딩과 내 감정을 적극적으로 표현해보기</li><li>제일 중요한 일들에 신경쓰기 위해 나의 기본적인 대답을 “아니오” 혹은 “생각해볼게요”로 변경하기</li><li>코치님께 코칭을 요청드려서 함께 내 삶을 객관적으로 인지하고 설계해나가기</li></ul><h2 id="마무리"><a href="#마무리" class="headerlink" title="마무리"></a>마무리</h2><p>결론적으로 현재 회사를 입사하면서 세웠던 목표들은 대략적으로 달성했습니다.<br>세부적으로는 여러 포인트에서 “이 때, 이렇게 했더라면 어땠을까?”라는 아쉬움이 많은게 사실입니다.<br>(글은 뻔지르르하게 썼지만, 우아하지 않았어요…)</p><p>부정적인 감정을 잘 다스리고 회사에 더 머물렀다면, 어쩌면 정년까지도 보장이되는 안정적인 직장생활도 이룰 수 있었을 것이라고 생각합니다.</p><p>그래도 저는 아직까지는 야생에서 어떻게든 살아남아서 “생존력”이 있는 사람이 되고싶은 열망이 있습니다. 그래서 어떻게 보면 스스로를 차디찬 야생에 집어던지는 짓(?)을 하지 않았을까… 라고 생각합니다.</p><p>어렸을 때의 불꽃이 많이 사그러들긴했지만, 아직까지는 어렸을 때의 열망들을 잘 간직하고 당시에 상상하던 미래의 나의 모습이 실제로 이뤄질 수 있게 계속 노력했으면 좋겠습니다.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;3번째 퇴사를 했습니다. 퇴사를 하고 왜 내가 이 회사에 오게되었지?, 왜 회사를 퇴사하는지?, 그리고 앞으로는 어떤 시도들을 해보고싶은지를 정리해보았습니다.&lt;/p&gt;</summary>
    
    
    
    <category term="Retrospective" scheme="http://ssaru.github.io/categories/Retrospective/"/>
    
    <category term="Essay" scheme="http://ssaru.github.io/categories/Retrospective/Essay/"/>
    
    
    <category term="Retrospective" scheme="http://ssaru.github.io/tags/Retrospective/"/>
    
  </entry>
  
  <entry>
    <title>(TIL) GPU is lost. Reboot the system to recover this GPU Error잡기</title>
    <link href="http://ssaru.github.io/2021/05/21/20210521-til_gpu_is_lost_reboot_the_system_to_recover_this_gpu/"/>
    <id>http://ssaru.github.io/2021/05/21/20210521-til_gpu_is_lost_reboot_the_system_to_recover_this_gpu/</id>
    <published>2021-05-21T13:49:00.000Z</published>
    <updated>2021-11-26T12:08:49.007Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><h2 id="GPU-is-lost"><a href="#GPU-is-lost" class="headerlink" title="GPU is lost"></a>GPU is lost</h2><p>최근 셋팅한 제 회사 컴퓨터에는 RTX-3090이 장착되어있습니다. RTX-3090을 장착한 김에 딥러닝 모델의 Hyperparameter search를 제 컴퓨터에서 수행하였는데요. 매번 프로그램을 실행할 때마다 <code>GPU is lost</code>라는 에러를 출력하고 프로그램이 중단되곤했습니다. 이 에러가 나오면 더 이상 OS에서 GPU에 접근할 수 없기 때문에 매번 OS를 재부팅해야하는 번거로움이 있었습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ python3 train.py</span><br><span class="line">...</span><br><span class="line">(중략)</span><br><span class="line">...</span><br><span class="line">Unable to determine the device handle <span class="keyword">for</span> GPU 0000:05:00.0: GPU is lost. Reboot the system to recover this GPU</span><br></pre></td></tr></table></figure><h2 id="What-is-problem"><a href="#What-is-problem" class="headerlink" title="What is problem?"></a>What is problem?</h2><p>이 에러를 마주하고나서는 제가 세운 가설은 다음과 같았습니다.</p><ol><li>파워 서플라이의 용량이 컴퓨터의 전력 수요를 맞출 수 없다. 혹은 GPU의 발열이 너무 심하다.</li><li>GPU가 PCI 슬롯에 제대로 장착되지 않았다.</li><li>하드웨어 호환성 혹은 하드웨어에 문제가 있을 것이다.</li></ol><h3 id="Insufficient-power"><a href="#Insufficient-power" class="headerlink" title="Insufficient power"></a>Insufficient power</h3><p>컴퓨터에 장착된 파워 서플라이의 용량이 GPU가 장착된 컴퓨터의 전력 수요를 맞출 수 없다면, <code>nvidia-smi</code>에서 GPU가 사용하는 전력량을 제한할 수 있습니다. </p><p>GPU의 발열이 심한 경우에도 GPU가 사용하는 전력량을 제한하여 온도상승을 제한할 수 있습니다.</p><p>GPU가 사용할 수 있는 전력량을 제한하는 명령어는 아래와 같습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -pm --persistence-mode=</span></span><br><span class="line"><span class="comment"># Set persistence mode: 0/DISABLED, 1/ENABLED</span></span><br><span class="line">$ sudo nvidia-smi -pm 1</span><br><span class="line">&gt;&gt;</span><br><span class="line">Enabled persistence mode <span class="keyword">for</span> GPU 00000000:02:00.0.</span><br><span class="line">All <span class="keyword">done</span>.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -pl --power-limit</span></span><br><span class="line"><span class="comment"># Specifies maximum power management limit in watts.</span></span><br><span class="line">$ sudo nvidia-smi -pl 290</span><br><span class="line">&gt;&gt;</span><br><span class="line">Power <span class="built_in">limit</span> <span class="keyword">for</span> GPU 00000000:02:00.0 was <span class="built_in">set</span> to 290.00 W from 390.00 W.</span><br><span class="line">All <span class="keyword">done</span>.</span><br></pre></td></tr></table></figure><p>먼저 <code>nvidia-smi</code> 명령어를 통해서 nvidia 커널 모듈이 지정된 GPU에 대해서 항상 활성화 상태가 되도록 강제합니다. nvidia 커널 모듈은 그래픽 GPU가 작동하기 위해 필요한데, X윈도우 상태이거나 CUDA 애플리케이션이 작동할 때에 커널 모듈이 활성화됩니다. X윈도우가 종료되거나 CUDA 애플리케이션이 더 이상 작동하지 않는 경우에는 커널 모듈이 비활성화 상태가 됩니다.</p><p><code>nvidia-smi</code> 명령어를 통한 전력제한 옵션은 nvidia 커널 모듈이 활성화되어있을 때만 적용됩니다. 즉, nvidia 커널 모듈이 활성화된 상태에서 전력제한이 적용되지만 비활성화된 상태에서는 전력제한이 풀려서 원래의 값으로 복원되게 됩니다. 전력제한이 동적으로 적용되는 것을 방지하기 위해서 persistence mode를 적용하여 nvidia 커널 모듈을 활성합니다.</p><p>RTX-3090에 전력제한을 하고, GPU와 CPU의 온도를 모니터링하면서 같은 에러가 발생하는지 테스트하였습니다.</p><p>GPU가 허용하는 온도는 아래의 명령어를 확인할 수 있습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ nvidia-smi -q | grep -i temp</span><br><span class="line">&gt;&gt;</span><br><span class="line">    Temperature</span><br><span class="line">        GPU Current Temp                  : 67 C</span><br><span class="line">        GPU Shutdown Temp                 : 98 C</span><br><span class="line">        GPU Slowdown Temp                 : 95 C</span><br><span class="line">        GPU Max Operating Temp            : 93 C</span><br><span class="line">        GPU Target Temperature            : 83 C</span><br><span class="line">        Memory Current Temp               : N/A</span><br><span class="line">        Memory Max Operating Temp         : N/A</span><br></pre></td></tr></table></figure><p>GPU가 Shutdown되는 온도는 98도임을 확인할 수 있고, 권장 최대 온도는 83도임을 확인할 수 있습니다.</p><p>CPU 의 온도를 모니터링하기 위해서는 <a href="https://askubuntu.com/questions/15832/how-do-i-get-the-cpu-temperature">lm-sensor</a>를 이용하였습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">$ watch -n 0.1 sensor</span><br><span class="line">&gt;&gt;</span><br><span class="line">Every 0.1s: sensors                                 ketimartin3090: Fri May 21 23:39:24 2021</span><br><span class="line"></span><br><span class="line">iwlwifi_1-virtual-0</span><br><span class="line">Adapter: Virtual device</span><br><span class="line">temp1:            N/A</span><br><span class="line"></span><br><span class="line">pch_cometlake-virtual-0</span><br><span class="line">Adapter: Virtual device</span><br><span class="line">temp1:        +46.0°C</span><br><span class="line"></span><br><span class="line">acpitz-acpi-0</span><br><span class="line">Adapter: ACPI interface</span><br><span class="line">temp1:        +16.8°C  (crit = +20.8°C)</span><br><span class="line">temp2:        +27.8°C  (crit = +119.0°C)</span><br><span class="line"></span><br><span class="line">coretemp-isa-0000</span><br><span class="line">Adapter: ISA adapter</span><br><span class="line">Package id 0:  +65.0°C  (high = +100.0°C, crit = +100.0°C)</span><br><span class="line">Core 0:        +49.0°C  (high = +100.0°C, crit = +100.0°C)</span><br><span class="line">Core 1:        +47.0°C  (high = +100.0°C, crit = +100.0°C)</span><br><span class="line">Core 2:        +65.0°C  (high = +100.0°C, crit = +100.0°C)</span><br><span class="line">Core 3:        +45.0°C  (high = +100.0°C, crit = +100.0°C)</span><br><span class="line">Core 4:        +47.0°C  (high = +100.0°C, crit = +100.0°C)</span><br><span class="line">Core 5:        +47.0°C  (high = +100.0°C, crit = +100.0°C)</span><br><span class="line">Core 6:        +43.0°C  (high = +100.0°C, crit = +100.0°C)</span><br><span class="line">Core 7:        +45.0°C  (high = +100.0°C, crit = +100.0°C)</span><br><span class="line"></span><br><span class="line">nvme-pci-0400</span><br><span class="line">Adapter: PCI adapter</span><br><span class="line">Composite:    +54.9°C  (low  = -273.1°C, high = +84.8°C)</span><br><span class="line">                       (crit = +84.8°C)</span><br><span class="line">Sensor 1:     +54.9°C  (low  = -273.1°C, high = +65261.8°C)</span><br><span class="line">Sensor 2:     +78.8°C  (low  = -273.1°C, high = +65261.8°C)</span><br></pre></td></tr></table></figure><p>학습을 돌려놓고, 확인해본 결과 전력제한을 걸어 전력소모와 발열량을 줄였음에도 같은 에러가 발생하는 것을 확인하였습니다.</p><h3 id="GPU-inserted-not-properly-in-PCIE-slot"><a href="#GPU-inserted-not-properly-in-PCIE-slot" class="headerlink" title="GPU inserted not properly in PCIE slot"></a>GPU inserted not properly in PCIE slot</h3><p>RTX-3090은 지금까지 나왔던 GPU 중에 제일 크고 무게가 있는 GPU입니다. 메인보드가 세로로 세워져있는 컴퓨터 케이스에 RTX-3090을 장착하게되면 PCIE slot에 장착된 GPU가 무게 때문에 내려앉습니다. 이로 인해 GPU가 잘 장착되지 않거나 메인보드에 PCIE 슬롯이 망가질 수 있습니다. 이를 방지하기 위해서 GPU 지지대를 사용하고있습니다만, 혹시 모르는 마음에 GPU를 탈착하고 재 장착하였습니다.</p><p>GPU를 재장착하고 테스트한 결과 같은 에러가 발생하는 것을 확인할 수 있었습니다.</p><h3 id="Hardware-compatibility"><a href="#Hardware-compatibility" class="headerlink" title="Hardware compatibility"></a>Hardware compatibility</h3><p>문제에 대해서 계속 검색하다가 리눅스 부팅 메세지를 확인하는 것을 통해서 GPU의 상태를 추적할 수 있다는 사실을 알았습니다. 부팅메세지는 <code>dmesg</code>명령어를 통해서 확인할 수 있었는데, 여기서 몇가지 키워드들을 확인할 수 있었습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ dmesg</span><br><span class="line">...</span><br><span class="line">(중략)</span><br><span class="line">[ 189.427290] NVRM: Xid (PCI:0000:01:00): 79, GPU has fallen off the bus.</span><br><span class="line">...</span><br><span class="line">(중략)</span><br><span class="line">PCIE Bus Error: Severity=Corrected after booting into Ubuntu</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>저는 이 키워드들에 집중했고, 모종의 하드웨어 호환 이슈로 인해 발생하는 PCIE Bus Error의 문제는 매우 흔하고, 이를 kernel parameter를 수정하여 해결할 수 있다는 것을 확인하였습니다. </p><p>우분투는 <code>/etc/default/grub</code>에서 이를 설정할 수 있습니다. 해당 파일을 열어 아래의 내용을 추가해줍니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GRUB_CMDLINE_LINUX_DEFAULT=<span class="string">&quot;quiet splash pci=nomsi&quot;</span></span><br></pre></td></tr></table></figure><p>해당 내용을 추가하였다면, <code>sudo update-grub</code>으로 수정된 내용을 반영해주고 컴퓨터를 재부팅하면 됩니다.</p><p>저는 최종적으로 위 내용을 반영하고나서, 위의 에러가 다시 발생하지 않는다는 것을 확인하였습니다.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://forums.developer.nvidia.com/t/unable-to-determine-the-device-handle-for-gpu-gpu-is-lost/57641">Unable to determine the device handle for GPU :GPU is lost</a></li><li><a href="https://forums.developer.nvidia.com/t/xid-79-gpu-has-fallen-off-the-bus/49452">Xid 79, GPU has fallen off the bus.</a></li><li><a href="https://askubuntu.com/questions/868321/gpu-has-fallen-off-the-bus-nvidia">GPU has fallen off the bus (Nvidia)</a></li><li><a href="https://askubuntu.com/questions/15832/how-do-i-get-the-cpu-temperature">How do i get the CPU temperature</a></li><li><a href="https://kyumdoctor.co.kr/11">nvidia smi 꼭 알아야 할 TIP - temp,serial,topology matrix</a></li><li><a href="https://itsfoss.com/pcie-bus-error-severity-corrected/">Troubleshooting PCIe Bus Error severity Corrected on Ubuntu and Linux Mint</a></li><li><a href="https://www.ddengle.com/board_FAQ/2719454">NVIDIA 우분투 마이닝 FAQ</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;최근 셋팅한 제 회사 컴퓨터에는 RTX-3090이 장착되어있습니다. 제 컴퓨터에서 딥러닝 모델을 학습하다보면 매번 학습 중에  &lt;code&gt;GPU is lost. Reboot the system to recover this GPU&lt;/code&gt; 에러를 출력하면서 학습이 중단되었습니다. 이럴 때마다 매번 컴퓨터를 리부팅해야하는 상황이 반복되어 매우 불편했는데요. 이 에러에 대해서 제가 어떻게 작업했는지 공유합니다.&lt;/p&gt;</summary>
    
    
    
    <category term="TIL" scheme="http://ssaru.github.io/categories/TIL/"/>
    
    
    <category term="GPU" scheme="http://ssaru.github.io/tags/GPU/"/>
    
    <category term="RTX-3090" scheme="http://ssaru.github.io/tags/RTX-3090/"/>
    
  </entry>
  
  <entry>
    <title>(TIL) Alpine Linux에서 locale 설정하기</title>
    <link href="http://ssaru.github.io/2021/05/09/20210509-til_set_locale_in_alpine_linux/"/>
    <id>http://ssaru.github.io/2021/05/09/20210509-til_set_locale_in_alpine_linux/</id>
    <published>2021-05-09T07:14:00.000Z</published>
    <updated>2021-11-26T12:08:48.998Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><h2 id="Installing-locale-in-alpine-Linux"><a href="#Installing-locale-in-alpine-Linux" class="headerlink" title="Installing locale in alpine Linux"></a>Installing locale in alpine Linux</h2><p>애플리케이션이 다국어를 지원할 수 있도록 docker image에 다른 locale을 설치하는 것이 필요할 수 있습니다. 올바른 locale이 설치되지 않는다면 텍스트 데이터가 올바르게 표현되지 않는 문제를 겪을 수 있습니다. alpine docker image는 <code>locale</code>, <code>locale-gen</code> 명령어가 존재하지 않으며, <code>apk add locale</code>로 설치를 시도할 경우 locale이라는 패키지가 없다는 에러를 확인할 수 있습니다. alpine에서 locale을 사용하기 위해서는 alpine과 호환되는 locale 패키지를 별도로 설치해줘야합니다. </p><p>(해당 포스팅에서는 명령어는 dockerfile을 기준으로 설명합니다.)</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> alpine:<span class="number">3.6</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---not shown here---</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Install language pack</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk --no-cache add ca-certificates wget &amp;&amp; \</span></span><br><span class="line"><span class="bash">    wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://raw.githubusercontent.com/sgerrand/alpine-pkg-glibc/master/sgerrand.rsa.pub &amp;&amp; \</span></span><br><span class="line"><span class="bash">    wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-2.25-r0.apk &amp;&amp; \</span></span><br><span class="line"><span class="bash">    wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-bin-2.25-r0.apk &amp;&amp; \</span></span><br><span class="line"><span class="bash">    wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-i18n-2.25-r0.apk &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apk add glibc-bin-2.25-r0.apk glibc-i18n-2.25-r0.apk glibc-2.25-r0.apk</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># install ko_KR locale</span></span><br><span class="line"><span class="comment"># Note that locale -a is not available in alpine linux, use `/usr/glibc-compat/bin/locale -a` instead</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> /usr/glibc-compat/bin/localedef -i ko_KR -f UTF-8 ko_KR.UTF-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> /usr/glibc-compat/bin/localedef -i ko_KR -f UTF-8 ko_KR.UTF-8 &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">echo</span> <span class="string">&quot;export LC_ALL=&#x27;ko_KR.UTF-8&#x27;&quot;</span> &gt;&gt; /etc/profile &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">echo</span> <span class="string">&quot;export LANG=&#x27;ko_KR.UTF-8&#x27;&quot;</span> &gt;&gt; /etc/profile &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">echo</span> <span class="string">&quot;export LANGUAGE=&#x27;ko_KR.UTF-8&#x27;&quot;</span> &gt;&gt; /etc/profile</span></span><br><span class="line"><span class="keyword">ENV</span> LC_ALL=ko_KR.UTF-<span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- not show here---</span></span><br></pre></td></tr></table></figure><h3 id="install-locale-package"><a href="#install-locale-package" class="headerlink" title="install locale package"></a>install locale package</h3><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> apk --no-cache add ca-certificates wget &amp;&amp; \</span></span><br><span class="line"><span class="bash">    wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://raw.githubusercontent.com/sgerrand/alpine-pkg-glibc/master/sgerrand.rsa.pub &amp;&amp; \</span></span><br><span class="line"><span class="bash">    wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-2.25-r0.apk &amp;&amp; \</span></span><br><span class="line"><span class="bash">    wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-bin-2.25-r0.apk &amp;&amp; \</span></span><br><span class="line"><span class="bash">    wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.25-r0/glibc-i18n-2.25-r0.apk &amp;&amp; \</span></span><br><span class="line"><span class="bash">    apk add glibc-bin-2.25-r0.apk glibc-i18n-2.25-r0.apk glibc-2.25-r0.apk</span></span><br></pre></td></tr></table></figure><p>위 명령어는 alpine linux를 지원하는 <code>locale</code> 패키지를 설치합니다. 해당 명령어를 실행하고나면, <code>/usr/glibc-compat/bin</code> 디렉토리에서 locale관련 명령어인 <code>locale</code>과 <code>localedef</code>를 확인할 수 있습니다. </p><h3 id="compile-locale"><a href="#compile-locale" class="headerlink" title="compile locale"></a>compile locale</h3><p><code>locale</code>관련 패키지를 설치하고나면, 현재 시스템이 사용중인 locale과 사용 가능한 locale을 <code>/usr/glibc-compat/bin/locale</code> 명령어와 <code>/usr/glibc-compat/bin/locale -a</code>로 확인할 수 있습니다. 이를 확인해보면, 내가 사용하고자하는 <code>ko_KR.UTF-8</code> 이 없음을 확인할 수 있습니다. </p><p>locale을 정의한 파일들은 <code>/usr/glibc-compat/share/i18n/locales</code> 폴더 아래에 있고, charmap(캐릭터맵)에 대한 정보는 <code>/usr/glibc-compat/share/i18n/charmaps</code> 폴더 아래에 있습니다. 이 두 가지 정보가 <code>localedef</code>의 명령어로 컴파일 되며 컴파일을 하게되면 <code>/usr/glibc-compat/lib/locale</code> 폴더에 <code>locale-archive</code>라는 접두사(prefix)를 가진 파일이 생성되게 됩니다.</p><p><code>ko_KR.UTF-8</code> locale을 사용하기 위해서 아래 명령어로 locale을 컴파일 합니다.</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> /usr/glibc-compat/bin/localedef -i ko_KR -f UTF-8 ko_KR.UTF-8</span></span><br></pre></td></tr></table></figure><h3 id="Set-locale"><a href="#Set-locale" class="headerlink" title="Set locale"></a>Set locale</h3><p>이제 locale 관련 패키지도 설치하였고 필요한 locale도 컴파일 해줬으니, 환경변수에 locale을 설정해봅시다.</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> /usr/glibc-compat/bin/localedef -i ko_KR -f UTF-8 ko_KR.UTF-8 &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">echo</span> <span class="string">&quot;export LC_ALL=&#x27;ko_KR.UTF-8&#x27;&quot;</span> &gt;&gt; /etc/profile &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">echo</span> <span class="string">&quot;export LANG=&#x27;ko_KR.UTF-8&#x27;&quot;</span> &gt;&gt; /etc/profile &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">echo</span> <span class="string">&quot;export LANGUAGE=&#x27;ko_KR.UTF-8&#x27;&quot;</span> &gt;&gt; /etc/profile</span></span><br><span class="line"><span class="keyword">ENV</span> LC_ALL=ko_KR.UTF-<span class="number">8</span></span><br></pre></td></tr></table></figure><p>ubuntu는 기본적으로 bash shell을 사용하기 때문에, 환경변수를 로그인 쉘의 경우에는 <code>~/.bashrc</code>에 미 로그인 쉘에는 <code>/etc/profile</code>에 설정합니다. alpine은 bash shell이 아닌 ash를 제공하는 busybox를 기본 shell로 사용합니다. 따라서 환경변수 설정은 로그인 쉘의 경우 <code>~/.profile</code>, 미 로그인 쉘은 <code>/etc/profile</code>에 설정해야합니다.</p><p>(저의 경우는 미로그인 쉘을 사용했으므로 환경변수를 <code>/etc/profile</code>에 설정하였습니다.)</p><h2 id="Check-locale-setting"><a href="#Check-locale-setting" class="headerlink" title="Check locale setting"></a>Check locale setting</h2><p>설정을 완료하고나면, <code>/usr/glibc-compat/bin/locale</code>와 <code>/usr/glibc-compat/bin/locale -a</code>를 통해 locale이 <code>ko_KR.UTF-8</code>로 잘 설정되었음을 확인할 수 있습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ /usr/glibc-compat/bin/locale</span><br><span class="line">&gt;&gt;</span><br><span class="line">LANG=ko_KR.UTF-8</span><br><span class="line">LC_CTYPE=<span class="string">&quot;ko_KR.UTF-8&quot;</span></span><br><span class="line">LC_NUMERIC=<span class="string">&quot;ko_KR.UTF-8&quot;</span></span><br><span class="line">LC_TIME=<span class="string">&quot;ko_KR.UTF-8&quot;</span></span><br><span class="line">LC_COLLATE=<span class="string">&quot;ko_KR.UTF-8&quot;</span></span><br><span class="line">LC_MONETARY=<span class="string">&quot;ko_KR.UTF-8&quot;</span></span><br><span class="line">LC_MESSAGES=<span class="string">&quot;ko_KR.UTF-8&quot;</span></span><br><span class="line">LC_PAPER=<span class="string">&quot;ko_KR.UTF-8&quot;</span></span><br><span class="line">LC_NAME=<span class="string">&quot;ko_KR.UTF-8&quot;</span></span><br><span class="line">LC_ADDRESS=<span class="string">&quot;ko_KR.UTF-8&quot;</span></span><br><span class="line">LC_TELEPHONE=<span class="string">&quot;ko_KR.UTF-8&quot;</span></span><br><span class="line">LC_MEASUREMENT=<span class="string">&quot;ko_KR.UTF-8&quot;</span></span><br><span class="line">LC_IDENTIFICATION=<span class="string">&quot;ko_KR.UTF-8&quot;</span></span><br><span class="line">LC_ALL=ko_KR.UTF-8</span><br><span class="line"></span><br><span class="line">$ /usr/glibc-compat/bin/locale -a</span><br><span class="line">&gt;&gt;</span><br><span class="line">C</span><br><span class="line">POSIX</span><br><span class="line">ko_KR.utf8</span><br></pre></td></tr></table></figure><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://gist.github.com/alextanhongpin/aa55c082a47b9a1b0060a12d85ae7923">Setting up locale on alpine:3.6 docker image</a></li><li><a href="https://palyoung.tistory.com/12">컨테이너 접속시 locale 에러 해결</a></li><li><a href="https://stackoverflow.com/questions/35325856/where-to-set-system-default-environment-variables-in-alpine-linux">Where to set system default environment variables in Alpine linux?</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;Alpine linux는 용량이 80MB이고, 컨테이너 이미지는 5MB밖에 안되는 초경량화된 리눅스 배포판입니다. alpine linux는 용량을 줄이기 위해 시스템의 기본 C runtime을 &lt;a href=&quot;https://ko.wikipedia.org/wiki/GNU_C_라이브러리&quot;&gt;glibc&lt;/a&gt; 대신 &lt;a href=&quot;https://en.wikipedia.org/wiki/Musl&quot;&gt;musl libc&lt;/a&gt; 를 사용하는데요. 이로 인해 제가 즐겨쓰는 ubuntu기반의 작업들이 동작하지 않는 경우가 있습니다. 그 중 ubuntu에서의 locale 명령어가 대표적입니다. ubuntu의 locale은 glibc 기반으로 구현되어있기 때문에 alpine linux에서는 &lt;code&gt;apk add locale&lt;/code&gt; 명령어로는 설치할 수 없습니다. 이번 포스팅은 alpine linux에서 locale을 설정하는 방법에 대해서 다룹니다.&lt;/p&gt;</summary>
    
    
    
    <category term="TIL" scheme="http://ssaru.github.io/categories/TIL/"/>
    
    
    <category term="Alpine Linux" scheme="http://ssaru.github.io/tags/Alpine-Linux/"/>
    
    <category term="Locale" scheme="http://ssaru.github.io/tags/Locale/"/>
    
  </entry>
  
  <entry>
    <title>(TIL) RTX 3090을 지원하는 PyTorch 버전설치</title>
    <link href="http://ssaru.github.io/2021/05/05/20210505-til_install_rtx3090_supported_pytorch/"/>
    <id>http://ssaru.github.io/2021/05/05/20210505-til_install_rtx3090_supported_pytorch/</id>
    <published>2021-05-05T13:27:00.000Z</published>
    <updated>2021-11-26T12:08:48.988Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><h2 id="Installing-PyTorch-with-RTX-3090-support"><a href="#Installing-PyTorch-with-RTX-3090-support" class="headerlink" title="Installing PyTorch with RTX 3090 support"></a>Installing PyTorch with RTX 3090 support</h2><p>2021.05.05 현재 RTX3090은 CUDA11 이상을 지원하는 딥러닝 프레임워크에 버전에서만 사용할 수 있습니다. 하지만 단순하게 <code>pip install torch==1.7.1 torchvision==0.8.2</code> 형태로 설치하면 <code>CUDA error: no kernel image is available for execution on the device</code> 에러를 마주할 수 있습니다.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">$ python3 -m pip install torch==1.7.1 torchvision==0.8.2</span><br><span class="line">Collecting torch==1.7.1</span><br><span class="line">  Using cached torch-1.7.1-cp38-cp38-manylinux1_x86_64.whl (776.8 MB)</span><br><span class="line">Collecting torchvision==0.8.2</span><br><span class="line">  Using cached torchvision-0.8.2-cp38-cp38-manylinux1_x86_64.whl (12.8 MB)</span><br><span class="line">Requirement already satisfied: numpy <span class="keyword">in</span> /home/ubuntu/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from torch==1.7.1) (1.20.2)</span><br><span class="line">Requirement already satisfied: typing-extensions <span class="keyword">in</span> /home/ubuntu/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from torch==1.7.1) (3.10.0.0)</span><br><span class="line">Requirement already satisfied: pillow&gt;=4.1.1 <span class="keyword">in</span> /home/ubuntu/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from torchvision==0.8.2) (8.2.0)</span><br><span class="line">Installing collected packages: torch, torchvision</span><br><span class="line">Successfully installed torch-1.7.1 torchvision-0.8.2</span><br><span class="line"></span><br><span class="line">$ python3</span><br><span class="line">Python 3.8.10 (default, May  4 2021, 22:52:00)</span><br><span class="line">[GCC 9.3.0] on linux</span><br><span class="line">Type <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> or <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line">&gt;&gt;&gt; import torch</span><br><span class="line">&gt;&gt;&gt; torch.cuda.is_available()</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; torch.randn(3,3).to(<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">/home/ubuntu/.pyenv/versions/3.8.10/lib/python3.8/site-packages/torch/cuda/__init__.py:104: UserWarning:</span><br><span class="line">GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.</span><br><span class="line">The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70 sm_75.</span><br><span class="line">If you want to use the GeForce RTX 3090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/</span><br><span class="line"></span><br><span class="line">  warnings.warn(incompatible_device_warn.format(device_name, capability, <span class="string">&quot; &quot;</span>.join(arch_list), device_name))</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line 1, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">  File <span class="string">&quot;/home/ubuntu/.pyenv/versions/3.8.10/lib/python3.8/site-packages/torch/tensor.py&quot;</span>, line 179, <span class="keyword">in</span> __repr__</span><br><span class="line">    <span class="built_in">return</span> torch._tensor_str._str(self)</span><br><span class="line">  File <span class="string">&quot;/home/ubuntu/.pyenv/versions/3.8.10/lib/python3.8/site-packages/torch/_tensor_str.py&quot;</span>, line 372, <span class="keyword">in</span> _str</span><br><span class="line">    <span class="built_in">return</span> _str_intern(self)</span><br><span class="line">  File <span class="string">&quot;/home/ubuntu/.pyenv/versions/3.8.10/lib/python3.8/site-packages/torch/_tensor_str.py&quot;</span>, line 352, <span class="keyword">in</span> _str_intern</span><br><span class="line">    tensor_str = _tensor_str(self, indent)</span><br><span class="line">  File <span class="string">&quot;/home/ubuntu/.pyenv/versions/3.8.10/lib/python3.8/site-packages/torch/_tensor_str.py&quot;</span>, line 241, <span class="keyword">in</span> _tensor_str</span><br><span class="line">    formatter = _Formatter(get_summarized_data(self) <span class="keyword">if</span> summarize <span class="keyword">else</span> self)</span><br><span class="line">  File <span class="string">&quot;/home/ubuntu/.pyenv/versions/3.8.10/lib/python3.8/site-packages/torch/_tensor_str.py&quot;</span>, line 89, <span class="keyword">in</span> __init__</span><br><span class="line">    nonzero_finite_vals = torch.masked_select(tensor_view, torch.isfinite(tensor_view) &amp; tensor_view.ne(0))</span><br><span class="line">RuntimeError: CUDA error: no kernel image is available <span class="keyword">for</span> execution on the device</span><br></pre></td></tr></table></figure><p>이 때에는 반드시 <code>pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html</code>형태로 설치해주어야합니다.</p><p>(RTX3090을 지원하는 PyTorch는 python3.8이상을 요구한다고 하여 해당 예제는 python3.8에서 테스트하였습니다)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ python3 -m pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html </span><br><span class="line">python3 -m pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html</span><br><span class="line">Looking <span class="keyword">in</span> links: https://download.pytorch.org/whl/torch_stable.html</span><br><span class="line">Collecting torch==1.7.1+cu110</span><br><span class="line">  Using cached https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp38-cp38-linux_x86_64.whl (1156.8 MB)</span><br><span class="line">Collecting torchvision==0.8.2+cu110</span><br><span class="line">  Using cached https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp38-cp38-linux_x86_64.whl (12.9 MB)</span><br><span class="line">Requirement already satisfied: numpy <span class="keyword">in</span> /home/ubuntu/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from torch==1.7.1+cu110) (1.20.2)</span><br><span class="line">Requirement already satisfied: typing-extensions <span class="keyword">in</span> /home/ubuntu/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from torch==1.7.1+cu110) (3.10.0.0)</span><br><span class="line">Requirement already satisfied: pillow&gt;=4.1.1 <span class="keyword">in</span> /home/ubuntu/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from torchvision==0.8.2+cu110) (8.2.0)</span><br><span class="line">Installing collected packages: torch, torchvision</span><br><span class="line">Successfully installed torch-1.7.1+cu110 torchvision-0.8.2+cu110</span><br><span class="line"></span><br><span class="line">$ python3</span><br><span class="line">Python 3.8.10 (default, May  4 2021, 22:52:00)</span><br><span class="line">[GCC 9.3.0] on linux</span><br><span class="line">Type <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> or <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line">&gt;&gt;&gt; import torch</span><br><span class="line">&gt;&gt;&gt; torch.cuda.is_available()</span><br><span class="line">True</span><br><span class="line">&gt;&gt;&gt; torch.randn(3,3).to(<span class="string">&quot;cuda:0&quot;</span>)</span><br><span class="line">tensor([[-0.5210,  0.2223,  1.7470],</span><br><span class="line">        [ 0.5932,  0.3055,  0.8472],</span><br><span class="line">        [-0.1898, -1.0950,  1.6593]], device=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;p&gt;2021.05.05 현재 RTX3090은 CUDA11 이상을 지원하는 딥러닝 프레임워크에 버전에서만 사용할 수 있습니다. 하지만 단순하게 &lt;code&gt;pip install torch==1.7.1 torchvision==0.8.2&lt;/code&gt; 형태로 설치하면 &lt;code&gt;CUDA error: no kernel image is available for execution on the device&lt;/code&gt; 에러를 마주할 수 있습니다. 이 때에는 반드시 &lt;code&gt;pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html&lt;/code&gt;형태로 설치해주어야합니다.&lt;/p&gt;</summary>
    
    
    
    <category term="TIL" scheme="http://ssaru.github.io/categories/TIL/"/>
    
    
    <category term="PyTorch" scheme="http://ssaru.github.io/tags/PyTorch/"/>
    
    <category term="RTX3090" scheme="http://ssaru.github.io/tags/RTX3090/"/>
    
  </entry>
  
  <entry>
    <title>(MML Book 선형대수 Chapter 3.5) Orthonormal Basis</title>
    <link href="http://ssaru.github.io/2020/11/01/20201101-mml_book_chap3.5_orthonormal_basis/"/>
    <id>http://ssaru.github.io/2020/11/01/20201101-mml_book_chap3.5_orthonormal_basis/</id>
    <published>2020-11-01T13:10:00.000Z</published>
    <updated>2021-11-26T12:08:48.985Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><h2 id="Orthonormal-Basis"><a href="#Orthonormal-Basis" class="headerlink" title="Orthonormal Basis"></a>Orthonormal Basis</h2><p><strong>Definition 3.9</strong> (Orthonormal Basis)</p><p>$n$차원의 벡터 공간 $V$과 $V$에서의 basis <script type="math/tex">\{b_{i},...,b_{n}\}</script> 를 생각했을 때, $\forall\ i,j=1,…,n$ 에서 다음을 만족하면 이를 orthonormal basis(ONB)라고 부릅니다.</p><script type="math/tex; mode=display">\big< b_{i}, b_{j} \big> =0, \ \ for\ i \neq j\ \ \ \ (3.33)\\ \big< b_{i}, b_{j} \big> = 1\ \ \ \ (3.34)\\</script><p>만약에 (3.33)만 만족한다면 이 basis는 orthogonal basis라고 부릅니다. (3.34)는 모든 basis vector의 length나 norm이 1임을 의미합니다. 따라서 orthonormal basis라는 것은 basis가 서로 orthogonal하면서, length나 norm이 1인 basis를 말하는 것입니다.</p><p>Chapter 2.6.1의 내용을 다시 생각해보면, vector들의 집합으로부터 스팬된 vector space에서의 basis를 찾기 위해서 가우시안 소거법을 사용했었습니다. </p><p>우리에게 non-orthogonal이고 unnormalized basis vecotr의 집합인 <script type="math/tex">\{\tilde{b}_{1},...,\tilde{b}_{n} \}</script>이 주어졌다고 생각해보십니다.</p><p>이때, orthonormal basis를 얻기 위해서는 다음과 같은 과정을 반복합니다.</p><ol><li>unnormalized basis vector들의 집합들을 concatenate해서 행렬 <script type="math/tex">\tilde{B} = [\tilde{b}_{1},...,\tilde{b}_{n}]</script> 를 만듭니다.</li><li>concatenate해서 만든 행렬을 augmented matrix<script type="math/tex">(\tilde{B}\tilde{B}^{T}|\tilde{B})</script> 형태로 변경합니다.</li><li>augmented matrix form의 행렬을 가우시안 소거법을 적용합니다.</li></ol><p>위와 같이 반복적인 작업을 통해서 orthonormal basis <script type="math/tex">\{b_{1},...,b_{n}\}</script>를 구하는 방법을 Gram-Schmidt process라고 부릅니다.</p><p><img src="example3.8.png" alt="Example 3.8"></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MML book 스터디를 진행하고있습니다. 이번 포스팅은 MML book Chapter 3.5. Orthonormal Basis에 대해서 정리한 내용입니다.&lt;/p&gt;
&lt;p&gt;Chapter 2.6.1에서 basis vector의 속성을 살펴봤었습니다. 이 때, $n$-차원 벡터 공간에서 서로 선형 독립인 $n$개의 basis vector가 필요함을 배웠었습니다.&lt;/p&gt;
&lt;p&gt;또한 Chapter 3.3과 3.4에서는 inner product를 벡터의 길이, 벡터 간 각도를 구하기 위해서 사용했었습니다. 이번 Chapter에서는 basis vector가 서로 orthogonal하고 basis vector의 길이가 1인 orthonormal basis basis에 대해서 이야기할 것입니다.&lt;/p&gt;
&lt;p&gt;이 orthonormal basis의 개념은 나중에 support vector machine과 PCA를 다루는 Chapter 12, Chapter10에서 활용하게 될 것입니다.&lt;/p&gt;</summary>
    
    
    
    <category term="Math" scheme="http://ssaru.github.io/categories/Math/"/>
    
    
    <category term="Math" scheme="http://ssaru.github.io/tags/Math/"/>
    
    <category term="Linear algebra" scheme="http://ssaru.github.io/tags/Linear-algebra/"/>
    
  </entry>
  
  <entry>
    <title>(MML Book 선형대수 Chapter 3.4) Angles and Orthogonality</title>
    <link href="http://ssaru.github.io/2020/11/01/20201101-mml_book_chap3.4_angles_and_orthogonality/"/>
    <id>http://ssaru.github.io/2020/11/01/20201101-mml_book_chap3.4_angles_and_orthogonality/</id>
    <published>2020-11-01T12:34:00.000Z</published>
    <updated>2021-11-26T12:08:48.978Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><h2 id="Angle"><a href="#Angle" class="headerlink" title="Angle"></a>Angle</h2><p>inner product는 벡터의 length나, 두 벡터 간의 distance를 정의하게 하는 것 외에도 두 벡터 간의 각도 $\omega$를 정의할 수 있습니다.</p><p>이때, 두 벡터 $x, y$ 사이의 inner product space에서 각도 $\omega$를 정의하기 위해서 우리는 Cauchy-Schwarz inequality (3.17)를 사용합니다. </p><blockquote><p> Cauchy-Schwarz Inequality</p><script type="math/tex; mode=display">|\big< x,y \big>| \leqslant ||x||\ ||y||\ \ \ \ (3.17)</script></blockquote><p>​        </p><p>$x \neq 0, y \neq0$을 가정할 때, Angle은 다음과 같습니다.</p><script type="math/tex; mode=display">-1 \leqslant \frac{\big<x,y\big>}{||x||\ ||y||} \leqslant 1\ \ \ \ (3.24)</script><ol><li><p>Cauchy-Schwarz Inequality에서 좌항의 절대값을 제거</p><script type="math/tex; mode=display">-||x||\ ||y|| \leqslant \big< x,y \big> \leqslant ||x||\ ||y||</script></li><li><p>모든 항을 $||x||\ ||y||$ 로 나눔</p><script type="math/tex; mode=display">-1 \leqslant \frac{\big<x,y\big>}{||x||\ ||y||} \leqslant 1\ \ \ \ (3.24)</script></li></ol><p>​    </p><p>이때,  $\omega \in [0, \pi]$는 다음과 같이 정의되며, Figure 3.4과 같이 표현할 수 있습니다.</p><script type="math/tex; mode=display">cos \omega = \frac{\big< x,y \big>}{||x||\ ||y||}\ \ \ \ (3.25)</script><p><img src="figure3.4.png" alt="Figure3.4"></p><p>​     </p><p>이때, $\omega$는 두 벡터 $x, y$간의 각도입니다. 각도는 직관적으로 두 벡터의 방향성이 얼마나 일치하는지에 대해서 알려줍니다. 예를들어 inner product가 dot product이고 벡터 $x, y=4x$가 있을 때, $y$는 $x$가 스케일된 벡터이므로 Angle은 0입니다.  Angle이 0이라면 방향이 같다는 의미가 됩니다.</p><p><img src="example3.6.png" alt="Example3.6"></p><p>​    </p><h2 id="Orthogonality"><a href="#Orthogonality" class="headerlink" title="Orthogonality"></a>Orthogonality</h2><p>length, distance, angle을 유도하는 것 외에 inner product의 핵심 특징은 두 벡터가 orthogonal인지 아닌지에 대한  알 수 있게 해준다는 것입니다.</p><p>​    </p><p><strong>Definition 3.7</strong> (Orthogonality)</p><p>만약 $\big&lt; x, y \big&gt; =0$이라면, 두 벡터 $x,y$는 orthogonal이며 우리는 이를 $x \perp y$라고 적습니다. 추가적으로 $||x||=1=||y||$라면 벡터는 unit vector라는 속성도 추가되어 orthonormal하다라고 이야기합니다.</p><p>이러한 정의가 함축하는 것은 $0$-벡터는 벡터 공간에서 모든 벡터와 orthogonal하다는 것을 의미합니다.</p><p>​    </p><p><strong>Remark</strong></p><p>Orthogonality는 inner product에 대한(bilinear forms) 수직(perpendicularity) 개념의 일반화입니다.</p><p>기하학적인 맥락에서는 두 벡터가 orthogonal이라면 두 벡터가 서로 직각인 벡터로써 생각할 수 있습니다.</p><p><img src="example3.7_1.png" alt="Example3.7_1"></p><p><img src="example3.7_2.png" alt="Example3.7_2"></p><p>​    </p><p><strong>Definition 3.8</strong> (Orthogonal Matrix)</p><p>만약에 모든 column들 끼리 모두 orthonormal하다면 square matrix $A \in \mathbb{R}^{n \times n}$은 orthogonal matrix입니다.</p><script type="math/tex; mode=display">AA^{T} = I = A^{T}A\ \ \ \ (3.29)</script><p>그리고, 이는 아래의 식과 같은 관계를 갖습니다.</p><script type="math/tex; mode=display">A^{-1} = A^{T}\ \ \ \ (3.30)</script><p>즉, 역행렬을 transpose로 간단히 구할 수 있다는 의미가 됩니다.</p><p>​    </p><p>orthogonal transformation matrix $A$를 이용한 transformation($Ax$)은 벡터 $x$의 length가 변하지 않는다는 특성이 있습니다. inner product를 dot product라고 생각하면, $||Ax||^{2}$ 은 $||x||^{2}$ 와 같습니다.</p><script type="math/tex; mode=display">||Ax||^{2} = (Ax)^{T}(Ax) = x^{T}A^{T}Ax = x^{T}Ix = x^{T}x = ||x||^{2}\ \ \ \ (3.31)</script><p>​    </p><p>거기에 두 벡터 $x, y$사이의 각도 또한 inner product로써 측정되므로 orthogonal matrix $A$를 이용해 transformation시 각도 또한 변하지 않습니다. dot product를 inner product로 가정하고 orthogonal matrix$A$ 가 있을 때, $Ax, Ay$ 간의 각도는 두 벡터 $x, y$ 와 같음을 확인할 수 있습니다.</p><script type="math/tex; mode=display">cos \omega = \frac{(Ax)^{T}(Ay)}{||Ax||\ ||Ay||} = \frac{x^{T}A^{T}Ay}{\sqrt{x^{T}A^{T}Axy^{T}A^{T}Ay}} = \frac{x^{T}y}{||x||\ ||y||}\ \ \ \ (3.32)</script>]]></content>
    
    
    <summary type="html">&lt;p&gt;MML book 스터디를 진행하고있습니다. 이번 포스팅은 MML book Chapter 3.4. Angles and Orthogonality에 대해서 정리한 내용입니다.&lt;/p&gt;
&lt;p&gt;Angle과 Orthogonality가 무엇인지에 대해서 살펴봅니다.&lt;/p&gt;</summary>
    
    
    
    <category term="Math" scheme="http://ssaru.github.io/categories/Math/"/>
    
    
    <category term="Math" scheme="http://ssaru.github.io/tags/Math/"/>
    
    <category term="Linear algebra" scheme="http://ssaru.github.io/tags/Linear-algebra/"/>
    
  </entry>
  
  <entry>
    <title>(MML Book 선형대수 Chapter 3.3) Lengths and Distances</title>
    <link href="http://ssaru.github.io/2020/11/01/20201101-mml_book_chap3.3_lengths_and%20_distances/"/>
    <id>http://ssaru.github.io/2020/11/01/20201101-mml_book_chap3.3_lengths_and%20_distances/</id>
    <published>2020-11-01T11:53:00.000Z</published>
    <updated>2021-11-26T12:08:48.974Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><h2 id="시작하기-Norm"><a href="#시작하기-Norm" class="headerlink" title="시작하기; Norm"></a>시작하기; Norm</h2><p>앞서 norm은 vector의 vector의 lenght 혹은 magnitude의 직관이라고 이야기했었습니다.</p><p>아래 식과 같이 어떤 inner product지 간에 norm을 유도한다는 측면에서 Inner product와 norm은 매우 밀접하게 연관 되어있습니다.</p><script type="math/tex; mode=display">||x|| := \sqrt{\big< x, x \big>}\ \ \ \ (3.16)</script><p>위의 식에서 $\big&lt; \cdot, \cdot \big&gt;$는 inner product를 의미합니다.</p><p>하지만, 모든 norm이 inner product에 의해 유도되는 것은 아닙니다. Manhattan norm은 inner product로부터 유도되지 않는 대표적인 norm입니다.</p><blockquote><p>norm이 inner product에서 유도되었는지 아닌지를 확인하는 방법에 대해서 알고싶다면, “<a href="https://math.stackexchange.com/questions/159766/an-example-of-a-norm-which-cant-be-generated-by-an-inner-product">An example of a norm which can’t be generated by an inner product</a>“과 “<a href="https://en.wikipedia.org/wiki/Parallelogram_law">Parallelogram law</a>“를 참고하세요.</p></blockquote><p>​    </p><p><strong>Remark.</strong> (Cauchy-Schwarz Inequality)</p><p>inner product vector space $(V, \big&lt; \cdot, \cdot \big&gt;)$에서 유도된 norm $||\cdot||$은 Cauchy-Schwarz inequality를 만족합니다.</p><script type="math/tex; mode=display">|\big< x,y \big>| \leqslant ||x||\ ||y||\ \ \ \ (3.17)</script><p>​     </p><p>norm에 의해 계산되는 length는 어떤 inner product냐에 따라 값이 변할 수 있습니다. 아래 Example 3.5에서는 dot product가 아닌 다른 inner product를 사용해서 norm을 구하면 값이 어떻게 변할 수 있는지에 대해 나타냅니다.</p><p><img src="example3.5.png" alt="Example3.5"></p><p>​    </p><h2 id="Distance와-Metric"><a href="#Distance와-Metric" class="headerlink" title="Distance와 Metric"></a>Distance와 Metric</h2><p><strong>Definition 3.6</strong>. (Distance and Metric)</p><p>inner product space $(V, \big&lt; \cdot, \cdot \big&gt;)$을 고려했을 때, 아래의 식을 벡터 $x$와 $y$의 distance라고 부릅니다. $(x, y \in V)$</p><script type="math/tex; mode=display">d(x, y) := ||x-y|| = \sqrt{\big<x-y , x-y\big>}\ \ \ \ (3.21)</script><p>만약에 inner product로 dot product를 사용한다면, 그 distance는 Euclidean distance라고 부릅니다.</p><p>이 때, distance에 대한 mapping은 아래와 같이 표현되며, 이를 metric이라고 부릅니다.</p><script type="math/tex; mode=display">d: V\times V \rightarrow \mathbb{R}\ \ \ \ (3.22)\\ (x, y) \mapsto d(x,y)\ \ \ \ (3.23)</script><p>​    </p><p><strong>Remark</strong></p><p>벡터의 길이와 유사하게 벡터 간의 거리를 구할 때는 inner product가 필요하지 않습니다. 단지 inner product로 유도된 norm이면 됩니다. 다만 거리는 norm이 어떤 inner product로부터 유도된 norm이냐에 따라 다를 수 있습니다.</p><p>​    </p><p>지금까지 distnace와 metric의 정의에 대해서 살펴봤습니다. 두 벡터 공간 $V, V$ 에서 $\mathbb{R}$ 공간으로 mapping하는 함수 metric $d$ 는 아래와 같은 속성을 갖습니다.</p><p>​    </p><ol><li><p>positive definite</p><ul><li><p>$d(x, y) \geqslant 0, \forall x, y \in V$</p></li><li><p>$d(x, y) = 0 \Longleftrightarrow x=y.$</p></li></ul></li><li><p>symmetric</p><ul><li>$d(x, y) = d(y, x), \forall x, y \in V$</li></ul></li><li><p>Triangle inequality</p><ul><li>$d(x, z) \leqslant d(x, y) + d(y, z), \forall x,y,z \in V$</li></ul></li></ol><p>​    </p><p><strong>Remark</strong></p><p>inner product와 metric의 속성은 매우 유사해보입니다. 하지만 위에 언급한 Definition 3.6과 이전에 챕터에서 Definition 3.3을 비교해보면 $\big&lt; x, y \big&gt;, d(x,y)$ 는 서로 반대되는 방식으로 동작합니다.</p><p><strong>Definition 3.3</strong></p><p>$V$를 벡터공간, $\Omega: V \times V \rightarrow \mathbb{R}$을 두 벡터를 real number로 맵핑하는 bilinear mapping이라고 해봅시다.</p><ul><li>positive definite, symmetric bilinear mapping $\Omega: V \times V \rightarrow \mathbb{R}$은 벡터공간 $V$에서의 inner product라고 부릅니다.</li><li>$(V, \big&lt;\cdot, \cdot\big&gt;)$는 inner product space 혹은 inner product가 있는 (real) vector space라고 부릅니다. 만약 (3.5)에서 정의한 dot product를 사용한다면 우리는 $(V, \big&lt;\cdot, \cdot \big&gt;)$을 Euclidean vector space라고 부릅니다.</li></ul><p>​    </p><p><strong>즉, 벡터 $x, y$가 서로 유사할 때, inner product는 매우 큰 값을 갖으며 metric은 매우 작은 값을 갖습니다.</strong></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MML book 스터디를 진행하고있습니다. 이번 포스팅은 MML book Chapter 3.3, Length and Distances에 대해서 정리한 내용입니다.&lt;/p&gt;
&lt;p&gt;Length와 Distances가 무엇인지에 대해서 살펴봅니다.&lt;/p&gt;</summary>
    
    
    
    <category term="Math" scheme="http://ssaru.github.io/categories/Math/"/>
    
    
    <category term="Math" scheme="http://ssaru.github.io/tags/Math/"/>
    
    <category term="Linear algebra" scheme="http://ssaru.github.io/tags/Linear-algebra/"/>
    
  </entry>
  
  <entry>
    <title>(MML Book 선형대수 Chapter ~2.2) 선형대수/벡터/선형시스템/매트릭스</title>
    <link href="http://ssaru.github.io/2020/09/23/20200921-MML_Book_Chap_2.3/"/>
    <id>http://ssaru.github.io/2020/09/23/20200921-MML_Book_Chap_2.3/</id>
    <published>2020-09-23T14:31:30.000Z</published>
    <updated>2021-11-26T12:08:48.964Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><h2 id="시작하기"><a href="#시작하기" class="headerlink" title="시작하기"></a>시작하기</h2><p>직관적인 개념을 형식화할 때, 공통적인 접근법은 다음과 같습니다.</p><ol><li>객체(object, symbol)의 집합(set)을 만든다.</li><li>만든 객체들을 조작(manipulate)하기 위한 규칙을(rule) 만든다.</li></ol><p>이러한 접근법으로 만들어진 개념들의 집합은 우리에게 대수(Algebra)라고 알려져 있습니다.</p><p><img src="algebra.png" alt="algebra"></p><p>선형대수는 벡터(vector)와 벡터들을 조작하기 위한 규칙들을 연구하는 학문입니다. </p><p>벡터라고 하면 많은 사람이 고등학교에서 배운 geometric vector를 생각합니다. 하지만 책에서는 벡터의 일반화된 개념에 대해서 논의합니다.</p><p>​    </p><h3 id="벡터의-정의"><a href="#벡터의-정의" class="headerlink" title="벡터의 정의"></a>벡터의 정의</h3><p>A라는 유형을 갖는 객체가 있다고 가정해봅시다. 이때,</p><ol><li>객체끼리 더함</li><li>스칼라(scalar, 상수)를 객체에 곱함</li></ol><p>1), 2)라는 연산의 결과로 같은 유형의 객체(A라는 유형의 객체)가 나온다면 이를 벡터라고 정의합니다.</p><p>다시 말해, 수학적인 관점에서 벡터는 아래 두 성질을 충족하면 벡터로 간주합니다.</p><ol><li>벡터끼리 덧셈 연산을(add) 했을 경우 벡터가 나옴</li><li>벡터에 스칼라를 곱했을 때, 벡터가 나옴</li></ol><p>벡터에 대한 대표적인 예는 아래와 같습니다.</p><ol><li><p><strong>Geometric vectors:</strong></p><p>Figure 2.1 (a) 에서 표현하고 있는 geometric vector는  고등학교 수학이나 물리에서 많이 배워 매우 친숙한 벡터입니다.</p></li><li><p><strong>Polynomial vectors:</strong></p><p>Figure 2.1 (b) 에서 표현하고 있는 polynomial(다항식) 또한 벡터입니다.</p><p>두 다항식은 서로 더해질 수 있으며, 더해진 결과 또한 다항식입니다. 그리고 다항식은 스칼라( <script type="math/tex">\lambda \in R</script> )로 곱셈 연산을 해도 다항식입니다. 따라서 다항식 또한 벡터입니다.</p></li></ol><p>그 외에도 3. <strong>Audio signals</strong>, 4. Elements of <script type="math/tex">R^{n}</script> (tuples of <script type="math/tex">n</script> real numbers)도 벡터입니다.</p><blockquote><p>Audio signals, Elements of $R^{n}$은 내용상 크게 문제가 되지 않기 때문에 생략했습니다.</p><p>자세히 알고싶은 분들은 <a href="https://mml-book.github.io/book/mml-book.pdf">MML Book</a> 18 page를 참고하시면 됩니다.</p></blockquote><p><img src="vector.png" alt="vector"></p><p>​    </p><h3 id="책에서-초점을-두고-설명하고자-하는-것"><a href="#책에서-초점을-두고-설명하고자-하는-것" class="headerlink" title="책에서 초점을 두고 설명하고자 하는 것"></a>책에서 초점을 두고 설명하고자 하는 것</h3><p>본 책에서는 다음과 같은 내용에 초점을 두고 선형 대수를 설명합니다.</p><ol><li>선형 대수의 대부분 알고리즘은 <script type="math/tex">R^{n}</script> 공간에서 정의가 됩니다. 따라서 책에서는 주로 <script type="math/tex">R^{n}</script> 공간의 벡터에 대해서 초점을 맞춰 설명합니다. 특히 chapter 8에서 데이터를  <script type="math/tex">R^{n}</script>공간의 벡터로 간주하고 설명할 것입니다.</li><li><strong>유한 차원 벡터 공간에(finite dimensional vector space) 초점을 맞춥니다. 유한 차원 벡터 공간의 경우, 모든 종류의 벡터와  <script type="math/tex">R^{n}</script>공간 간의 1:1 대응이 존재합니다.</strong></li></ol><p>​    </p><h3 id="선형-대수와-기계학습-알고리즘-간의-상관관계"><a href="#선형-대수와-기계학습-알고리즘-간의-상관관계" class="headerlink" title="선형 대수와 기계학습 알고리즘 간의 상관관계"></a>선형 대수와 기계학습 알고리즘 간의 상관관계</h3><p>만약 내가 새로운 연산자(operator)를 만들었다고 생각해봅시다. 이때, <strong>내가 제안한 연산(operation)으로 만들어지는 것들의 집합은 무엇인가?</strong>라는 궁금증이 생길 수 있습니다.</p><p>이를 선형대수 관점에서 다시 생각해보면, <strong>작은 벡터의 집합에서 시작해서 서로 더해지고, 스케일링 되었을 때의 그 결과인 벡터들의 집합은 무엇인가?</strong>와 같습니다. 이 질문에 대한 답은 Section 2.4에서 언급할 vector space가 됩니다. vector space의 개념과 속성은 기계학습 알고리즘의 기초가 됩니다.</p><p>선형대수는 기계학습과 수학에서 중요한 역할을 합니다. 이번 장에서 소개되는 개념들은 chapter 3에서 geometry에 대한 아이디어로 확장됩니다. chapter 5에서는 벡터 미적분(vector calculus)에 대해서 논의합니다. 벡터 미적분은 매트릭스 연산에 대한 지식이 필수적으로 요구됩니다. chapter 10에서는 PCA를 활용한 차원 축소를 위해 사영(projection)을 사용할 것입니다. chapter 9에서는 선형 회귀(linear regression)에 대해서 논의합니다. 선형 회귀에서 선형대수는 least-square problems을 푸는 중요한 역할을 합니다.</p><p><img src="concept_mindmap.png" alt="concept_mindmap"></p><p>​    </p><h2 id="선형-시스템-Systems-of-Linear-Equations"><a href="#선형-시스템-Systems-of-Linear-Equations" class="headerlink" title="선형 시스템(Systems of Linear Equations)"></a>선형 시스템(Systems of Linear Equations)</h2><p>선형 시스템은 선형 대수에서 중심적인 역할을 합니다. 많은 문제는 선형 시스템으로 형식화되며, 선형대수는 이를 풀 수 있는 도구를 제공합니다.</p><p>​    </p><p><strong>Example 2.1</strong></p><p>어떤 회사가 리소스 <script type="math/tex">R_{1}, ... ,R_{N}</script> 가 들어가는 제품 <script type="math/tex">N_{1}, ... ,N_{n}</script> 을 생산합니다. 이때, <script type="math/tex">N_{j}</script>의 일부 파트를 생산하기 위해서 리소스 <script type="math/tex">R_{i}</script>의 일부인 <script type="math/tex">a_{ij}</script>가 필요합니다. (<script type="math/tex">i=1,...,m</script>, <script type="math/tex">j=1,...,n</script>).</p><p>우리의 목적은 한정된 리소스에서 얼마나 많은 제품을 만들 수 있는지에 대한 최적의 생산 계획을 찾는 것입니다. 예를 들어 “우리에게 리소스 <script type="math/tex">b_{i}</script>가 있을 때,  제품 <script type="math/tex">N_{j}</script>의 일부 파트인 <script type="math/tex">x_{j}</script>를 얼마나 많이 생산할 수 있는가?”와 같은 질문의 답을 찾는 것이지요.</p><p>만약 우리가 제품과 대응되는 파트들 <script type="math/tex">x_{i},...,x_{n}</script>을 생산할 때, 다음과 같은 리소스가 필요하게 됩니다.</p><script type="math/tex; mode=display">a_{i1}x_{1} + ... + a_{in}x_{n}\ \  (2.2)</script><p>이때, 최적의 생산계획은 실수공간에 존재하게 됩니다<script type="math/tex">(x_{1},...,x_{n}) \in R^{n}</script>. 따라서, 최적의 생산 계획은 아래의 선형 시스템을 만족하는 해를 찾으면 됩니다.</p><script type="math/tex; mode=display">\begin{matrix}  a_{11}x_{1} + ... + a_{1n}x_{n} =  b_{1}\\   ...\\  a_{m1}x_{1} + ... + a_{mn}x_{n} = b_{m} \end{matrix}, \ \ \ a_{ij} \in R, \ b_{i} \in R \ \ (2.3)</script><p>식 (2.3)은 일반적인 형태의 선형 시스템입니다.</p><script type="math/tex; mode=display">x_{1},...,x_{n},\ \ \ \ (x_{1},...,x_{n}) \in R^{n}</script><p>은 시스템에서 미지수가 되며, 식 (2.3) 을 만족하는 해가 이 선형 시스템의 해가 됩니다.</p><p>​    </p><p><strong>Example 2.2</strong></p><p>다음 선형 시스템이 있을 때,</p><script type="math/tex; mode=display">\begin{matrix}  x_{1} + x_{2} + x_{3} = 3\ \ \ \  (1)\\   x_{1} - x_{2} + 2x_{3} = 2\ \ \ (2)\\   2x_{1} + 3x_{3} = 1 \ \ \ \ \ \ \ \ \ \ (3)\\\end{matrix}</script><p>이 선형 시스템은 해가 없습니다. (1)과 (2)를 더하면 <script type="math/tex">2x_{1} + 3x_{3} = 5</script>입니다. 이 결과를 (3)과 빼게되면, 부등식은 모순이 됩니다. 이 경우에는 선형 시스템에 해는 없게 됩니다.</p><p>또 다른 선형 시스템을 살펴봅시다.</p><script type="math/tex; mode=display">\begin{matrix}  x_{1} + x_{2} + x_{3} = 3\ \ \ \  \ (1)\\   x_{1} - x_{2} + 2x_{3} = 2\ \ \ (2)\\ \ \ \ \ \ \ \ x_{2} + x_{3} = 2 \ \ \ \ \ \ \ (3)\\\end{matrix}</script><p>이를 위와 같은 방식으로 풀게 되면, <script type="math/tex">(x_{1} = 1, x_{2} = 1, x_{3}=1)</script>이 유일한 해(유일해; unique solution)가 됩니다.</p><p>마지막으로 아래 선형 시스템을 살펴봅시다.</p><script type="math/tex; mode=display">\begin{matrix}  x_{1} + x_{2} + x_{3} = 3\ \ \ \  \ (1)\\   x_{1} - x_{2} + 2x_{3} = 2\ \ \ (2)\\ 2x_{1} + 3x_{3} = 5 \ \ \ \ \ \ \ \ \ \ (3)\\\end{matrix}</script><p>이를 똑같이 풀어보면, (1)과 (2)를 더한 결과가 (3)과 같음을 확인할 수 있습니다.</p><p>이때, (1)과 (2)를 이용해서 <script type="math/tex">2x_{1} = 5 - 3x_3{}</script>, <script type="math/tex">2x_{2} = 1+x_{3}</script>을 얻을 수 있습니다.</p><p>$x_{3} = a \in R$로 자유 변수(free variable)로 정의하면, 다음과 같은 해를 찾을 수 있습니다.</p><script type="math/tex; mode=display">(\frac{5}{2} - \frac{3}{2}a, \frac{1}{2}+ \frac{1}{2}a, a),\ \  a \in R</script><p>이 해는 무수히 많은 해가 존재한다는 것을 의미하며, 기하학적으로 Figure 2.3과 같습니다.</p><p><img src="solution_of_linear_equation.png" alt="solution_of_linear_equation"></p><p>일반적으로 실수값을 갖는 선형 시스템으로 구성된 시스템에서 우리는 아래와 같은 종류의 해를 구할 수 있습니다.</p><ol><li>해가 없음</li><li>단 하나의 해</li><li>무한히 많은 해</li></ol><p>선형 회귀(linear regression)은 Example 2.1과 같은 예제에서 선형 시스템을 풀지 못했을 경우 이를 푸는 방법입니다.</p><p>​    </p><h3 id="선형-시스템에-대한-기하학적-해석-Geometric-Interpretation-of-System-of-Linear-Equation"><a href="#선형-시스템에-대한-기하학적-해석-Geometric-Interpretation-of-System-of-Linear-Equation" class="headerlink" title="선형 시스템에 대한 기하학적 해석(Geometric Interpretation of System of Linear Equation)"></a>선형 시스템에 대한 기하학적 해석(Geometric Interpretation of System of Linear Equation)</h3><p>두 개의 변수(<script type="math/tex">x_{1}, x_{2}</script>)를 갖는 선형 시스템에서 각각의 시스템은 <script type="math/tex">x_{1}</script> - <script type="math/tex">x_{2}</script>  평면에서 하나의 선이 됩니다.</p><p>만약에 각 시스템을 모두 만족하는 해가 있다면, 이 해는 각 선의 교집합이 됩니다.</p><p>이 교집합은 다음과 같은 형태로 나타납니다.</p><ol><li>점이 되거나(교차) </li><li>선이 되거나(겹침)</li><li>공집합(평행; 해가 없음).</li></ol><p>이를 확장하여 변수가 세 개가 된다면, 각 시스템은 면(plane)이 되며, 교집합은 선(line)이 됩니다.</p><p>이때의 교집합은 1)면, 2)선, 3)점, 4)공집합(해가 없음)으로 나타나게 됩니다.</p><p>​    </p><h2 id="행렬-Matrices"><a href="#행렬-Matrices" class="headerlink" title="행렬 (Matrices)"></a>행렬 (Matrices)</h2><p>행렬 또한 선형 대수에서 중요한 역할을 합니다. 행렬은 선형 시스템을 간단히 표기하는데 사용하기도 하지만, Section 2.7에서 살펴볼 선형 함수(linear mapping)를 표현하기도 합니다.</p><p>행렬의 재밌는 주제를 논의하기 전에 먼저, 1) 행렬이 무엇이고, 2) 행렬로 어떤 연산이 가능한지 살펴봅시다.</p><p>​    </p><p><strong>Definition 2.1 (Matrix)</strong></p><p> $m, n \in N,\ \ N \in R$인 $(m, n)$ 행렬 $A$는 $m$ rows와 $n$ columns으로 구성된 직사각형 구조를 갖습니다. </p><p>행렬의 원소 $a_{ij},\ i=1,…,m,\ j=1,…,n$ 는 $m\cdot n$ - tuple입니다.</p><script type="math/tex; mode=display">A = \begin{bmatrix}        a_{11} & a_{12} & ... & a_{1n}\\         a_{21} & a_{22} & ... & a_{2n}\\        \vdots & \vdots & & \vdots \\        a_{m1} & a_{m2} & ... &  a_{mn}     \end{bmatrix}, \ \ a_{ij} \in R</script><p>일반적으로 $(1, n)$-행렬은 rows라고 부르고, $(m, 1)$-행렬은 columns라고 부릅니다.</p><p>rows, colums와 같이 특별한 행렬은 row, column vectors라고 부릅니다.</p><p>$R^{m \times n}$는 실수공간에 있는 $(m, n)$-행렬입니다.</p><p> $A \in R^{m \times n}$는 모든 $n$ columns의 행렬이 길게 붙여진 $a \in R^{mn}$과 같은 표현입니다.</p><blockquote><p>행렬의 표현이 달라질 뿐이지, 벡터 개념에서는 벗어나지 않는다는 것에 주목합시다.</p><p>표현이 변경된 행렬은 다른 행렬을 더해도 같은 형태를 유지하는 행렬이며, 스칼라와 곱해도 같은 형태를 유지하는 행렬입니다. </p><p>추가적으로, 우리가 알고 있는 행렬곱의 연산자(opration)를 일부 변경하면 <script type="math/tex">R^{nm}</script> 행렬 또한 행렬곱 정의가 가능합니다.</p></blockquote><p><img src="matrix.png" alt="matrix"></p><p>​    </p><h3 id="행렬의-덧셈과-곱셈"><a href="#행렬의-덧셈과-곱셈" class="headerlink" title="행렬의 덧셈과 곱셈"></a>행렬의 덧셈과 곱셈</h3><p>두 행렬 $A \in R^{m \times n}$, $B \in R^{m \times n}$의 합은 element-wise sum으로 정의됩니다</p><script type="math/tex; mode=display">A + B := \begin{bmatrix}        a_{11} + b_{11} & ... & a_{1n} + b_{1n} \\         \vdots &  & \vdots \\        a_{m1} + b_{m1} & ... & a_{mn} + b_{mn}        \end{bmatrix} \in R^{m \times n}</script><p>두 행렬 $A \in R^{m \times n}$, $B \in R^{n \times k}$가 있을 때, 행렬곱( $C = AB \in R^{m \times k}$)의 결과인 행렬 <script type="math/tex">C</script> 원소 $c_{ij}$는 다음과 같이 계산합니다</p><script type="math/tex; mode=display">c_{ij} = \Sigma_{l=1}^{n} a_{il}b_{lj},\ \ \ \ i = 1,...,m,\ \ \ \ \ j = 1,...,k.</script><p>위와 같이 $A$의 $i$th row의 원소와 $B$의 $j$th columns의 원소끼리 곱하는 연산을 Section 3.2에서는 <strong>dot product</strong>라고 부르며, $A \cdot B$로 표기합니다.</p><p>​    </p><p><strong>Remark</strong></p><blockquote><p>행렬의 곱은 인접 차원이 같아야합니다. 예를 들어 $n \times k$ 행렬 $A$는 $k \times m$ 행렬 $B$와 곱셈 연산을 수행할 수 있습니다. 이때, 행렬 $B$는 행렬 $A$ 우측에 있어야만 합니다.</p><script type="math/tex; mode=display">\underbrace{A}_{n \times k} \underbrace{B}_{k \times m} =\underbrace{C}_{n \times m}</script><p>프로덕트(product) $BA$는 이웃 차원이 맞지 않기 때문에 정의되지 않습니다.</p></blockquote><p>​    </p><p><strong>Remark</strong></p><blockquote><p>행렬 곱은 element-wise 연산으로 정의되지 않습니다. 프로그래밍 언어에서 종종 나타나는 array 간 element-wise 곱은 <strong><em>Hadamard product</em></strong>라고 부릅니다.</p></blockquote><p>​    </p><p><strong>Definition 2.2 (Identity Matrix)</strong> </p><p>$R^{n \times n}$에서 단위행렬(identity matrix)은 대각방향으로는 1, 그 외에는 0을 갖는 $n \times n$- 행렬로 정의됩니다.</p><script type="math/tex; mode=display">I_{n} := \begin{bmatrix}    1&0&...&0&...&0 \\     0&1&...&0&...&0 \\    \vdots&\vdots&\ddots&\vdots&\ddots&\vdots \\    0&0&...&1&...&0 \\    \vdots&\vdots&\ddots&\vdots&\ddots&\vdots \\    0&0&...&0&...&1 \\    \end{bmatrix} \in R^{m \times n}</script><p>지금까지 우리는 행렬의 1) 합, 2) 곱, 3) 단위행렬에 대해서 정의했습니다. 이를 이용하여 매트릭스의 속성을 살펴보면 아래와 같습니다.</p><ul><li><p>Associativity (결합법칙)</p><script type="math/tex; mode=display">\forall A \in R^{m \times n},\ B \in R^{n \times p},\ C \in R^{p \times q}\ :\ (AB)C = A(BC) \ \ (2.18)</script></li><li><p>Distributivity (분배법칙)</p><script type="math/tex; mode=display">\forall A, B \in R^{m \times n},\ C, D \in R^{n \times p}\ : (A+B)C = AC+BC \ \ (2.19a)\\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ A(C+D) = AC + AD \ \ (2.19b)</script></li><li><p>Multiplication with the identity matrix (단위행렬과의 곱셈)</p><script type="math/tex; mode=display">\forall A \in R^{m \times n} : I_{m}A = AI_{n} = A, \ \ \ \ I_{m} \neq I_{n}\ for\ \  m \neq n.</script></li></ul><p>​    </p><h3 id="역행렬과-전치행렬"><a href="#역행렬과-전치행렬" class="headerlink" title="역행렬과 전치행렬"></a>역행렬과 전치행렬</h3><p>​    </p><p><strong>Definition 2.3 (Inverse)</strong><br>정방행렬 $A \in R^{n \times n}$이 있을 때, 매트릭스 $B \in R^{n \times n}$와의 관계가 $AB = I_{n} = BA$라는 속성을 만족할 때, $B$는 $A$의 역행렬이라고 부르며 $A^{-1}$로 표기합니다.</p><p>모든 행렬 $A$가 역행렬 $A^{-1}$를 갖진 않습니다. $A$가 역행렬을 가지려면 $A$는 regular / invertible / nonsigular(정칙행렬) 이어야 합니다. 다른 경우는 singular / noninvertible (특이 행렬)이라고 부릅니다.</p><p>역행렬이 존재한다면, 이는 유일합니다. Section 2.3에서는 선형 시스템을 풀어 역행렬을 계산하는 일반적인 방법을 논의합니다.</p><p>​    </p><p><strong>Remark</strong> (Existence of the Inverse of a $2 \times 2$-matrix)</p><blockquote><script type="math/tex; mode=display">A := \begin{bmatrix}a_{11} & a_{12} \\a_{21} & a_{22}\end{bmatrix}\in R^{2 \times 2}.\ \ \ \ (2.21)</script><script type="math/tex; mode=display">A^{'} := \begin{bmatrix}a_{22} & -a_{12} \\-a_{21} & a_{11}\end{bmatrix}\in R^{2 \times 2}.\ \ \ \ (2.22)</script><p> 위와 같은 행렬이 있을 때, 두 행렬을 곱하게 되면 다음과 같은 행렬을 얻을 수 있습니다.</p><script type="math/tex; mode=display">AA^{'} =\begin{bmatrix}a_{11}a_{22} - a_{12}a_{21} & 0 \\0 & a_{11}a_{22} - a_{12}a_{21} \\\end{bmatrix} = (a_{11}a_{22} - a_{12}a_{21})I\ \ \ \ (2.23)</script><p> 따라서 역행렬 $A^{-1}$은 아래와 같습니다.</p><script type="math/tex; mode=display">A^{'} := \frac{1}{a_{11}a_{22} - a_{12}a_{21}}\begin{bmatrix}a_{22} & -a_{12} \\-a_{21} & a_{11}\end{bmatrix}</script><p>이때, <script type="math/tex">a_{11}a_{22} - a_{12}a_{21} \neq 0</script> 이어야 합니다. Section 4.1에서는 <script type="math/tex">a_{11}a_{22} - a_{12}a_{21}</script>가 <script type="math/tex">2 \times 2</script>-matrix의 행렬식(determinant)임을 살펴봅니다. 우리는 행렬식을 통해 행렬이 역행렬을 갖는지 확인할 수 있습니다.</p></blockquote><p>​    </p><p><strong>Definition 2.4</strong> (Transpose)</p><p>행렬 <script type="math/tex">A, B</script>가 다음과 같을 때 <script type="math/tex">A \in R^{m \times n}</script>, <script type="math/tex">B \in R^{n \times m}</script>, <script type="math/tex">b_{ij} = a_{ji}</script>면 <script type="math/tex">B</script>를 <script type="math/tex">A</script>의 전치행렬(transpose)이라고 부릅니다. 전치행렬은 <script type="math/tex">B = A^{T}</script>로 표기합니다.</p><p>역행렬과 전치행렬의 중요한 속성은 다음과 같습니다.</p><p>$AA^{-1} = I = A^{-1}A \<br>(AB)^{-1} = B^{-1}A^{-1} \<br>(A + B)^{-1} \neq A^{-1} + B^{-1} \<br>(A^{T})^{T} = A \<br>(A+B)^{T} = A^{T} + B^{T} \<br>(AB)^{T} = B^{T}A^{T}$$</p><p>​    </p><p><strong>Definition 2.5</strong> (Symmetric Matrix, 대칭행렬)</p><p>$A \in R^{n \times n}$인 행렬이 대칭행렬이라면 $A = A^{T}$입니다.</p><p>대칭행렬은 정방행렬인 $(n, n)$-행렬에서만 가능하며, 역행렬을 가지며, 역행렬은 $A^{T}$입니다.</p><p>$(A^{-1})^{T} = (A^{T})^{-1} =: A^{-T}$</p><p>​    </p><p><strong>Remark</strong> (Sum and Product of Symmetric Matrices)</p><blockquote><p>임의의 두 대칭행렬의 합은 항상 대칭행렬이 됩니다. $A, B \in R^{n \times n}$</p><p>대칭행렬의 곱은 항상 정의되지만, 결과는 일반적으로 대칭행렬이 아닙니다.</p><p> $\begin{bmatrix}<br>1&amp;0 \<br>0&amp;0\<br>\end{bmatrix}<br>\begin{bmatrix}<br>1&amp;1 \<br>1&amp;1\<br>\end{bmatrix} =<br>\begin{bmatrix}<br>1&amp;1 \<br>0&amp;0\<br>\end{bmatrix}$</p></blockquote><p>​    </p><h3 id="스칼라에-의한-곱셈"><a href="#스칼라에-의한-곱셈" class="headerlink" title="스칼라에 의한 곱셈"></a>스칼라에 의한 곱셈</h3><p>행렬이 스칼라에 의해 곱해질 때를 고려해보겠습니다.</p><p>행렬 $A \in R^{m \times n}$과 스칼라 $\lambda \in R$가 있을 때, $\lambda A = K$입니다.</p><p>이때, <script type="math/tex">K_{ij} = \lambda a_{ij}</script>가 됩니다.</p><p>이때, $\lambda$는 $A$의 원소를 스케일링한다고 볼 수 있습니다.</p><p>스칼라가 $\lambda, \psi \in R$일 때, 행렬과 스칼라 곱의 성질은 아래와 같습니다.</p><ul><li><p>Associativity (결합법칙)</p><script type="math/tex; mode=display">(\lambda \psi)C = \lambda(\psi C), \ \ \  C \in R^{m \times n}</script><script type="math/tex; mode=display">\lambda(BC) = (\lambda B)C = B(\lambda C) = (BC)\lambda,\ \ B \in R^{m \times n}, C \in R^{n \times k}</script><script type="math/tex; mode=display">(\lambda C)^{T} = C^{T}\lambda^{T}  = C^{T}\lambda = \lambda C^{T}\ \ since\ \lambda=\lambda^{T}\ \ for\ all\ \lambda \in R</script></li><li><p>Distributivity  (분배법칙)</p><script type="math/tex; mode=display">(\lambda+\psi)C = \lambda C + \psi C,\ \ C \in R \\\lambda(B + C) = \lambda B + \lambda C,\ \ B, C \in R</script></li></ul><p>​    </p><h3 id="선형-시스템을-간단하게-표현하는-방법"><a href="#선형-시스템을-간단하게-표현하는-방법" class="headerlink" title="선형 시스템을 간단하게 표현하는 방법"></a>선형 시스템을 간단하게 표현하는 방법</h3><script type="math/tex; mode=display">\begin{matrix}  2x_{1} + 3x_{2} + 5x_{3} = 1\\   4x_{1} - 2x_{2} - 7x_{3} = 8\\ 9x_{1} + 5x_{2} - 3x_{3} = 2 \\\end{matrix}</script><p>위와 같은 선형 시스템이 있을 때, 선형 시스템을 하나하나 표기하는 것이 아닌, 계수(coefficient $a_{ij}$)들의 집합과의 관계로 표기하게 되면, 행렬곱으로 간소화하여 표현할 수 있습니다.</p><script type="math/tex; mode=display">\begin{bmatrix}  2&3&5\\   4&-2&-7\\  9&5&-3 \end{bmatrix}\begin{bmatrix}  x_{1}\\   x_{2}\\  x_{3} \end{bmatrix} = \begin{bmatrix}  1\\   8\\  2 \end{bmatrix}</script><p>이때, <script type="math/tex">x_{1}</script>은 첫 번째 column을, <script type="math/tex">x_{2}</script>는 두 번째 column을, <script type="math/tex">x_{3}</script>은 세 번째 column을 스케일링한다고 볼 수 있습니다.</p><p>일반적으로 선형 시스템은 행렬 형태로(<script type="math/tex">Ax = b</script> ) 간소화하여 표현할 수 있습니다.</p><p>프로덕트 $Ax$는 $A$의 columns의 선형 조합입니다. 우리는 Section 2.5에서 선형 조합에 대해서 논의해볼 것입니다.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;MML book 스터디를 진행하고있습니다. 이번 포스팅은 MML book Chapter 2 ~ 2.2까지 정리한 내용입니다.&lt;/p&gt;
&lt;p&gt;선형대수가 어떤 학문인지, 벡터, 선형시스템, 매트릭스의 정의는 무엇이고, 어떤 속성을 갖는지에 대해서 살펴봅니다.&lt;/p&gt;</summary>
    
    
    
    <category term="Math" scheme="http://ssaru.github.io/categories/Math/"/>
    
    
    <category term="Math" scheme="http://ssaru.github.io/tags/Math/"/>
    
    <category term="Linear algebra" scheme="http://ssaru.github.io/tags/Linear-algebra/"/>
    
    <category term="Vector" scheme="http://ssaru.github.io/tags/Vector/"/>
    
    <category term="Linear equation" scheme="http://ssaru.github.io/tags/Linear-equation/"/>
    
    <category term="Matrix" scheme="http://ssaru.github.io/tags/Matrix/"/>
    
  </entry>
  
  <entry>
    <title>(번역) Modern Parallel and Distributed Python-A Quick Tutorial on Ray</title>
    <link href="http://ssaru.github.io/2020/08/27/20200827-A_Quick_Tutorial_on_Ray/"/>
    <id>http://ssaru.github.io/2020/08/27/20200827-A_Quick_Tutorial_on_Ray/</id>
    <published>2020-08-27T02:31:30.000Z</published>
    <updated>2021-11-26T12:49:39.723Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><p><a href="https://github.com/robertnishihara">Robert Nishihara</a>의 허락을 받아, <a href="https://towardsdatascience.com/modern-parallel-and-distributed-python-a-quick-tutorial-on-ray-99f8d70369b8">Modern Parallel and Distributed Python: A Quick Tutorial on Ray</a>을 번역한 글입니다.</p><h2 id="What-is-Ray"><a href="#What-is-Ray" class="headerlink" title="What is Ray?"></a>What is <a href="https://github.com/ray-project/ray">Ray</a>?</h2><p><a href="https://github.com/ray-project/ray">Ray</a>는 파이썬에서 병렬, 분산 프로그래밍을 위한 오픈소스 프로젝트입니다.</p><p>병렬, 분산 컴퓨팅은 현대 애플리케이션을 구성하는 요소 중 하나로 자리잡았습니다. 우리는 필요에 따라 멀티코어나 여러 대의 머신의 리소스를 최대한 활용해서 애플리케이션을 가속해야할 필요가 있습니다. </p><blockquote><p>웹 사이트를 크롤링하거나 사용자 질의에 응답하는 소프트웨어들은 누군가의 노트북에서 돌아가는 single thread기반의 프로그램이 아니고, 서로 통신하고 상호작용하는 서비스 집합이라고 볼 수 있습니다.</p></blockquote><p><img src="cloud.jpeg" alt="cloud"></p><center>(클라우드 컴퓨팅은 메모리, 연산, 스토리지 등 다방면으로 끊임없는 확장성을 제공하고있습니다. 클라우드가 제공하는 이러한 이점에 적절하게 대응하기 위해서는 분산 어플리케이션을 만들 수 있는 새로운 도구가 필요합니다)</center><p>이번 포스팅은 Ray를 사용해서 병렬,분산 어플리케이션을 만드는 방법에 대해서 설명합니다.</p><h2 id="Why-Ray"><a href="#Why-Ray" class="headerlink" title="Why Ray?"></a>Why Ray?</h2><p>많은 튜토리얼들이 <a href="https://docs.python.org/3/library/multiprocessing.html#:~:text=multiprocessing is a package that,using subprocesses instead of threads">Python의 multiprocessing 모듈</a>을 어떻게 사용하는지 설명합니다. </p><p>하지만 Python의 multiprocessing 모듈은 한계점을 가지고 있어 현대 애플리케이션이 요구하는 분산, 병렬에 대한 필수사항을 충족하지 못합니다.</p><p>현대 애플리케이션이 요구하는 분산, 병렬처리에 대한 필수사항은 다음과 같습니다.</p><ul><li>같은 코드를 한대 이상의 머신(machine)에서 작동시켜야함</li><li>state를 가지고, 통신이 가능한 <a href="https://en.wikipedia.org/wiki/Actor_model">actor</a>와 <a href="https://en.wikipedia.org/wiki/Microservices">microservice</a>를 만들 수 있어야함</li><li>machine failures를 깔끔하게 다룰 수 있어야함</li><li>대규모 객체와 수치 데이터를 효율적으로 다룰 수 있어야함</li></ul><p><a href="https://github.com/ray-project/ray">Ray</a>는 위에서 언급한 요구사항을 모두 충족합니다. 또한 간단한 작업을 단순하게 만들며, 복잡한 동작을 하게끔 프로그래밍하는 것 또한 가능합니다.</p><p><img src="ray.png" alt="ray"></p><p>다른 회사들이 자신들의 Python 프로덕션을 확장하기 위해서 Ray를 어떻게 활용하고있는지 배우고싶다면, <a href="https://events.linuxfoundation.org/ray-summit/?utm_source=robert&amp;utm_medium=blog&amp;utm_campaign=ray_summit#featuredspeakers">Ray Summit</a>에 등록하세요!</p><p><img src="ray_summit.png" alt="ray-summit"></p><h2 id="Necessary-Concepts"><a href="#Necessary-Concepts" class="headerlink" title="Necessary Concepts"></a>Necessary Concepts</h2><p>전통적으로 프로그래밍은 <strong>1). 함수(Functions)</strong>, <strong>2) 클래스(Classes)</strong>라는 핵심 개념에 의존합니다. 생각해보면 우리는 함수와 클래스만으로 많은 애플리케이션들을 만들어왔습니다.</p><p>하지만, 함수와 클래스로 구성된 애플리케이션을 분산 환경으로 마이그레이션하려고하면 함수, 클래스라는 개념을 사용할 수 없게됩니다. </p><p>따라서 현재까지 알려진 병렬, 분산 도구를 활용해서 싱글 스레드 애플리케이션을 병렬, 분산 애플리케이션으로 마이그레이션을 하기 위해서는 애플리케이션 코드를 처음부터 다시 작성해야합니다.</p><p>현재까지 알려진 병렬, 분산도구는 저수준에서 고수준까지 다양한 도구들이 있습니다.</p><p>먼저 저수준 도구로는 메세지의 송수신을 저수준의 프리미티브로 제공하는 <a href="https://www.open-mpi.org/">OpenMPI</a>, <a href="https://docs.python.org/3/library/multiprocessing.html">Python Multiprocessing</a>, <a href="https://zeromq.org/">ZeroMQ</a>이 있습니다. 이 도구들은 분산, 병렬 환경을 위한 강력한 기능들을 제공합니다. 하지만, 전통적인 프로그래밍과는 다른 추상화 개념을 사용합니다. 이로 인해 위 도구들을 활용해서 기존의 싱글 스레드 애플리케이션을 분산, 병렬 어플리케이션으로 마이그레이션하기 위해서는 코드 전체를 재작성해야합니다.</p><p>또 다른 예로 도메인에 특화되어 고수준의 추상화를 제공하는 도구들이 있습니다. 딥러닝 모델을 학습하기 위한 <a href="https://www.tensorflow.org/">TensorFlow</a>, 데이터와 SQL 처리를 위한 <a href="https://spark.apache.org/">Spark</a>, 스트림 처리를 위한 <a href="https://flink.apache.org/">Flink</a>가 대표적입니다. 이 도구들은 neural network나 데이터셋, 스트림에 대한 고수준의 추상화 API를 제공합니다. 하지만, 고수준 추상화를 제공하는 도구들 역시 <strong>직렬화된 프로그래밍(serial programming)</strong>에서 사용하는 추상화와 다르기 때문에, 애플리케이션 코드 전체를 그에 맞게 재작성해줘야하는 단점이 있습니다.</p><p><img src="distributed_computing_tools.jpeg" alt="ray-summit"></p><center>(분산 컴퓨팅을 위한 도구들. 왼쪽은 저수준의 추상화 API를 지원하는 도구, 오른쪽은 고수준의 추상화 API를 제공하는 도구)</center><p>Ray는 위에서 설명한 도구들과 같은 고수준, 저수준이 아닌 중간수준에 위치합니다. Ray는 함수와 클래스를 task, actor라고 불리는 분산환경에 적합한 형태로 변환하며, 이를 통해 병렬, 분산 컴퓨팅을 지원하는 메커니즘을 가지고 있습니다. 따라서 사용자들은 이전과 다르게 코드를 재작성 없이 기존의 함수와 클래스 구조를 유지하면서 분산, 병렬 프로그래밍을 할 수 있습니다.</p><h2 id="Starting-Ray"><a href="#Starting-Ray" class="headerlink" title="Starting Ray"></a>Starting Ray</h2><p>Ray의 <code>ray.init()</code>명령어는 Ray에서 사용하는 프로세스들을 모두 구동합니다. </p><p>만약 클러스터 환경을 이용해서 분산 컴퓨팅을 하고자 한다면, 클러스터의 주소(address)를 입력하는 코드 라인 하나만 변경하면 됩니다.</p><p><code>ray.init()</code>명령어로 구동되는 Ray의 프로세스들은 아래와 같습니다.</p><ul><li><strong>Worker</strong> : 파이썬의 함수를 병렬적으로 실행할 프로세스(대략 하나의 worker는 하나의 CPU 코어를 의미합니다).</li><li><strong>Scheduler</strong> : task들을 worker 혹은 다른 머신에 할당하기 위한 스켸쥴러(task란 Ray에 사용되는 파이썬 함수 혹은 메소드로, Ray에 의해 스켸쥴링되는 단위).</li><li><strong>Shared memory object store</strong> : 워커(worker)들간 객체를 효율적으로 공유하기 위한 공유메모리(copy 발생이 없는)</li><li><strong>Inmemory database</strong> : 머신 실패(machine failure)와 같은 이벤트 상황에서 task들을 반환하기 위해 메타 데이터를 저장하는 데이터베이스</li></ul><blockquote><p>Ray worker는 thread가 아니며, thread와는 다른 개념의 process입니다.</p><p>Python은 GIL(Global Interpreter Lock)으로 인해 multi-threding 지원에 한계가 있습니다.</p></blockquote><h2 id="Parallelism-with-Tasks"><a href="#Parallelism-with-Tasks" class="headerlink" title="Parallelism with Tasks"></a>Parallelism with Tasks</h2><p><code>@ray.remote</code>라는 데코레이터를 함수 위에 선언해주는 것만으로 파이썬 함수를 Ray에서 실행 가능한 <em>remote function</em>으로 변경할 수 있습니다. </p><blockquote><p><em>remote function</em>은 Ray의 프로세스에 의해 비동기적으로 실행됩니다.</p></blockquote><p>아래 예제와 같이 함수 <code>f</code>를 <code>@ray.remote</code> 데코레이터를 통해서 <em>remote function</em>으로 변경했다면, <code>f.remote()</code>를 호출해서 함수를 실행할 수 있습니다. 이때, 호출된 <code>f.remote()</code>는 즉각적으로 future를 반환하고 실제 함수의 실행은 백그라운드에서 진행됩니다.</p><blockquote><p><a href="https://en.wikipedia.org/wiki/Futures_and_promises">future</a>는 나중에 반환될 함수의 출력값에 대한 참조입니다.</p></blockquote><p>아래 예제에서  <code>f.remote()</code>에 대한 호출이 즉시 반환되고 다음 <em>remote function</em>이 실행되기 때문에, 백그라운드에서 실행되는 <code>f</code>에 대한 4개의 복사본(task)은 단순히 해당 라인을 4번 실행하는 것으로 분산, 병렬로 실행할 수 있습니다.</p><p>파이썬 함수 <code>f</code>를 “remote function”으로 바꾸기 위해서는 함수에 <code>@ray.remote</code>라는 데코레이터를 선언해줘야합니다. 그리고 함수를 <code>f.remote()</code>로 호출하면 즉시 future를 리턴합니다. 그리고 실제 함수의 실행은 백그라운드에서 실행됩니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ray</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start Ray.</span></span><br><span class="line">ray.init()</span><br><span class="line"></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x</span>):</span></span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start 4 tasks in parallel.</span></span><br><span class="line">result_ids = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    result_ids.append(f.remote(i))</span><br><span class="line">    </span><br><span class="line"><span class="comment"># Wait for the tasks to complete and retrieve the results.</span></span><br><span class="line"><span class="comment"># With at least 4 cores, this will take 1 second.</span></span><br><span class="line">results = ray.get(result_ids)  <span class="comment"># [0, 1, 2, 3]</span></span><br></pre></td></tr></table></figure><h3 id="Task-Dependencies"><a href="#Task-Dependencies" class="headerlink" title="Task Dependencies"></a>Task Dependencies</h3><p>task는 또 다른 task에 의존할 수 있습니다. </p><p>아래 예제에서 <code>multiply_matrices</code> task는 두개의 <code>create_matrix</code> task의 결과를 사용합니다. 따라서 첫번째 두 task의 출력은 자동으로 세번째 task의 인자로 입력됩니다.</p><p>결론적으로, 아래 예제를 실행해보면, <code>multiply_matrices</code>는 첫번째 두 task의 출력의 값이 반환되기 전까지는 실행되지 않습니다. </p><p>이러한 방식으로 task들을 arbitrary DAG dependencies로 구성할 수 있습니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_matrix</span>(<span class="params">size</span>):</span></span><br><span class="line">    <span class="keyword">return</span> np.random.normal(size=size)</span><br><span class="line"></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multiply_matrices</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    <span class="keyword">return</span> np.dot(x, y)</span><br><span class="line"></span><br><span class="line">x_id = create_matrix.remote([<span class="number">1000</span>, <span class="number">1000</span>])</span><br><span class="line">y_id = create_matrix.remote([<span class="number">1000</span>, <span class="number">1000</span>])</span><br><span class="line">z_id = multiply_matrices.remote(x_id, y_id)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the results.</span></span><br><span class="line">z = ray.get(z_id)</span><br></pre></td></tr></table></figure><h3 id="Aggregating-Values-Efficiently"><a href="#Aggregating-Values-Efficiently" class="headerlink" title="Aggregating Values Efficiently"></a>Aggregating Values Efficiently</h3><p>task 의존성을 잘 설계하면 효율적인 방식으로 작업을 수행할 수 있습니다.</p><p>예를 들어 아래의 그림처럼 8개의 정수를 더한다고 생각해봅시다. </p><p>매우 간단한 예제이지만, 실제로 이러한 형태로 큰 벡터를 통합하는 것은 애플리케이션에 큰 병목이 되기도 합니다. 이런 병목 지점에서 task 의존성을 잘 설계한다면, 단 한줄의 코드 변경으로 시간 복잡도를 선형 시간에서 로그메틱 시간으로 변경할 수 있습니다.</p><p><img src="aggregation.jpeg" alt="aggregation.jpeg"></p><center>(두 연산 그래프는 같은 결과를 반환하지만, 좌측 그림은 의존성 그래프의 깊이가 7이며, 우측 그림은 의존성 그래프의 깊이가 3입니다. 이 경우 우측 연산 그래프의 연산이 더 빠릅니다)</center><p>위에서 설명한데로 하나의 task에서 생성된 output을 다른 task의 입력으로 사용하기 위해서는 첫번째 task로부터 반환받은 future를 두번째 task의 입력으로 넣으면 됩니다. </p><p>이때, 두번째 task가 첫번째 task의 출력을 의존하고있으면 두번째 task는 첫번째 task가 끝나기 전에는 실행되지 않습니다.</p><p>task 의존성은 자동으로 ray의 스켸쥴러가 추적하고 관리하므로, 만약 분산환경일 경우, 첫번째 task의 출력은 자동으로 두번째 task가 있는 머신으로 보내져 실행되게됩니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span>(<span class="params">x, y</span>):</span></span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> x + y</span><br><span class="line"></span><br><span class="line"><span class="comment"># Aggregate the values slowly. This approach takes O(n) where n is the</span></span><br><span class="line"><span class="comment"># number of values being aggregated. In this case, 7 seconds.</span></span><br><span class="line">id1 = add.remote(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">id2 = add.remote(id1, <span class="number">3</span>)</span><br><span class="line">id3 = add.remote(id2, <span class="number">4</span>)</span><br><span class="line">id4 = add.remote(id3, <span class="number">5</span>)</span><br><span class="line">id5 = add.remote(id4, <span class="number">6</span>)</span><br><span class="line">id6 = add.remote(id5, <span class="number">7</span>)</span><br><span class="line">id7 = add.remote(id6, <span class="number">8</span>)</span><br><span class="line">result = ray.get(id7)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Aggregate the values in a tree-structured pattern. This approach</span></span><br><span class="line"><span class="comment"># takes O(log(n)). In this case, 3 seconds.</span></span><br><span class="line">id1 = add.remote(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">id2 = add.remote(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">id3 = add.remote(<span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line">id4 = add.remote(<span class="number">7</span>, <span class="number">8</span>)</span><br><span class="line">id5 = add.remote(id1, id2)</span><br><span class="line">id6 = add.remote(id3, id4)</span><br><span class="line">id7 = add.remote(id5, id6)</span><br><span class="line">result = ray.get(id7)</span><br></pre></td></tr></table></figure><p>위의 코드는 명확합니다. 하지만, 이를 <code>while</code> loop를 통해 구현한다면 더 간결하게 구현할 수 있습니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Slow approach.</span></span><br><span class="line">values = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line"><span class="keyword">while</span> <span class="built_in">len</span>(values) &gt; <span class="number">1</span>:</span><br><span class="line">    values = [add.remote(values[<span class="number">0</span>], values[<span class="number">1</span>])] + values[<span class="number">2</span>:]</span><br><span class="line">result = ray.get(values[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fast approach.</span></span><br><span class="line">values = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line"><span class="keyword">while</span> <span class="built_in">len</span>(values) &gt; <span class="number">1</span>:</span><br><span class="line">    values = values[<span class="number">2</span>:] + [add.remote(values[<span class="number">0</span>], values[<span class="number">1</span>])]</span><br><span class="line">result = ray.get(values[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><h2 id="From-Classes-to-Actors"><a href="#From-Classes-to-Actors" class="headerlink" title="From Classes to Actors"></a>From Classes to Actors</h2><p>클래스없이 좋은 애플리케이션을 만드는 것은 어려운 일입니다. 그리고 이는 분산환경에서도 마찬가지로 어렵습니다.</p><p>클래스 데코레이터 <code>@ray.remote</code>를 사용하면 Ray에서 파이썬 클래스를 사용할 수 있습니다. 클래스를 인스턴스화하면 Ray는 새로운 액터(Actor)를 생성합니다. 액터는 분산환경 어딘가에서 실행되지만 객체의 복제본(object copy)을 유지하는 프로세스입니다. </p><p>액터의 메소드를 실행하면 Ray는 해당 메소드를 액터 프로세스 위에서 작동하는 task로 변환합니다. 액터 프로세스 위에서 작동하는 task는 액터의 상태(state)에 접근이 가능하고 상태를 변경할 수 있습니다. 이러한 방법으로 액터는 액터의 상태값을 여러 task간 공유합니다.</p><p>개별적인 액터는 메소드를 직렬로 실행하며(블럭킹), 액터의 메소드는 atomic 속성을 갖습니다. 따라서 race condition이 발생하지 않게됩니다. 액터를 이용한 병렬성은 다수의 액터를 생성하는 방식으로 구현합니다.</p><p>아래 예제는 액터를 사용하는 간단한 예제입니다. <code>Counter.remote()</code>는 새로운 액터 프로세스를 생성합니다. </p><p>액터 프로세스는 <code>Counter</code> 객체의 복사본을 갖으며,  <code>c.get_value.remote()</code>와  <code>c.inc.remote()</code>는 원격 액터 프로세스(remote actor process)에서 task를 실행하고 액터의 상태를 변경합니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Counter</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.x = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inc</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.x += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_value</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.x</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an actor process.</span></span><br><span class="line">c = Counter.remote()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Check the actor&#x27;s counter value.</span></span><br><span class="line"><span class="built_in">print</span>(ray.get(c.get_value.remote()))  <span class="comment"># 0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Increment the counter twice and check the value again.</span></span><br><span class="line">c.inc.remote()</span><br><span class="line">c.inc.remote()</span><br><span class="line"><span class="built_in">print</span>(ray.get(c.get_value.remote()))  <span class="comment"># 2</span></span><br></pre></td></tr></table></figure><h3 id="Actor-Handles"><a href="#Actor-Handles" class="headerlink" title="Actor Handles"></a>Actor Handles</h3><p>위에서 우리는 파이썬의 메인 스크립트에서 액터의 메소드를 실행하는 예제를 살펴봤습니다. </p><p>액터의 강력한 장점은 핸들(handle)을 액터에 전달할 수 있는 것입니다. 이는 다른 액터나 다른 task가 동일한 액터의 메소드를 호출할 수 있게 해줍니다.</p><p>아래 예제는 메세지를 저장하는 액터를 생성합니다. 몇몇의 worker task는 반복적으로 messages를 액터로 푸쉬합니다. 그리고 파이썬 메인 스크립트는 주기적으로 이 메세지를 읽습니다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MessageActor</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.messages = []</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_message</span>(<span class="params">self, message</span>):</span></span><br><span class="line">        self.messages.append(message)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_and_clear_messages</span>(<span class="params">self</span>):</span></span><br><span class="line">        messages = self.messages</span><br><span class="line">        self.messages = []</span><br><span class="line">        <span class="keyword">return</span> messages</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a remote function which loops around and pushes</span></span><br><span class="line"><span class="comment"># messages to the actor.</span></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">worker</span>(<span class="params">message_actor, j</span>):</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        message_actor.add_message.remote(</span><br><span class="line">            <span class="string">&quot;Message &#123;&#125; from worker &#123;&#125;.&quot;</span>.<span class="built_in">format</span>(i, j))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a message actor.</span></span><br><span class="line">message_actor = MessageActor.remote()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Start 3 tasks that push messages to the actor.</span></span><br><span class="line">[worker.remote(message_actor, j) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Periodically get the messages and print them.</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    new_messages = ray.get(message_actor.get_and_clear_messages.remote())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;New messages:&quot;</span>, new_messages)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># This script prints something like the following:</span></span><br><span class="line"><span class="comment"># New messages: []</span></span><br><span class="line"><span class="comment"># New messages: [&#x27;Message 0 from worker 1.&#x27;, &#x27;Message 0 from worker 0.&#x27;]</span></span><br><span class="line"><span class="comment"># New messages: [&#x27;Message 0 from worker 2.&#x27;, &#x27;Message 1 from worker 1.&#x27;, &#x27;Message 1 from worker 0.&#x27;, &#x27;Message 1 from worker 2.&#x27;]</span></span><br><span class="line"><span class="comment"># New messages: [&#x27;Message 2 from worker 1.&#x27;, &#x27;Message 2 from worker 0.&#x27;, &#x27;Message 2 from worker 2.&#x27;]</span></span><br><span class="line"><span class="comment"># New messages: [&#x27;Message 3 from worker 2.&#x27;, &#x27;Message 3 from worker 1.&#x27;, &#x27;Message 3 from worker 0.&#x27;]</span></span><br><span class="line"><span class="comment"># New messages: [&#x27;Message 4 from worker 2.&#x27;, &#x27;Message 4 from worker 0.&#x27;, &#x27;Message 4 from worker 1.&#x27;]</span></span><br><span class="line"><span class="comment"># New messages: [&#x27;Message 5 from worker 2.&#x27;, &#x27;Message 5 from worker 0.&#x27;, &#x27;Message 5 from worker 1.&#x27;]</span></span><br></pre></td></tr></table></figure><p>Ray의 액터는 매우 강력합니다. 액터는 파이썬의 클래스를 가져와서 다른 액터와의 작업 혹은 다른 애플리케이션에 질의할 수 있는 마이크로 서비스로 인스턴스화할 수 있습니다.</p><p>task와 액터는 Ray가 제공하는 핵심적인 추상입니다. 이 두 가지 개념은 매우 일반적이면서 정교한 애플리케이션 구현에 사용할 수 있습니다.</p><p>Ray는 딥러닝에 사용되는 정교한 애플리케이션 중 하나인 <a href="https://docs.ray.io/en/latest/rllib.html">분산 강화학습</a>, <a href="https://docs.ray.io/en/latest/tune/index.html">하이퍼파라미터 튜닝 도구</a>, <a href="https://docs.ray.io/en/latest/pandas_on_ray.html">가속화된 판다스</a>를 제공하니 한번 살펴보시기 바랍니다.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://towardsdatascience.com/modern-parallel-and-distributed-python-a-quick-tutorial-on-ray-99f8d70369b8">Modern Parallel and Distributed Python: A Quick Tutorial on Ray</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;이번 포스팅은 Ray에 대해서 소개합니다.&lt;/p&gt;</summary>
    
    
    
    <category term="Software" scheme="http://ssaru.github.io/categories/Software/"/>
    
    <category term="Disbritubed Computing" scheme="http://ssaru.github.io/categories/Software/Disbritubed-Computing/"/>
    
    
    <category term="Python" scheme="http://ssaru.github.io/tags/Python/"/>
    
    <category term="Distributed" scheme="http://ssaru.github.io/tags/Distributed/"/>
    
    <category term="Parallel" scheme="http://ssaru.github.io/tags/Parallel/"/>
    
    <category term="Ray" scheme="http://ssaru.github.io/tags/Ray/"/>
    
  </entry>
  
  <entry>
    <title>2019년 회고</title>
    <link href="http://ssaru.github.io/2020/01/05/20200105-2019_retrospective/"/>
    <id>http://ssaru.github.io/2020/01/05/20200105-2019_retrospective/</id>
    <published>2020-01-05T14:45:55.000Z</published>
    <updated>2021-11-26T12:08:48.955Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!--toc--><h1 id="들어가며"><a href="#들어가며" class="headerlink" title="들어가며"></a>들어가며</h1><p>이제 2019년이 가고 2020년이 되었다.</p><p>지난 2019년 초에 많은 계획들을 세웠던 것 같은데, 예상치 못한 일들로 다사다난했던 해였다.</p><p>2020년을 맞이하여 2019년 회고하고 2020년 계획을 다짐하는 포스팅을 작성한다.</p><h1 id="2019년-계획했던-일들"><a href="#2019년-계획했던-일들" class="headerlink" title="2019년 계획했던 일들"></a>2019년 계획했던 일들</h1><p>2019년을 시작하면서 그때의 상황에 맞춰 여러 계획들을 많이 세웠다.</p><p>큰 카테고리로 나누어보자면 아래와 같이 나눌 수 있다.</p><ol><li><strong>건강</strong></li><li><strong>경제적 자립</strong></li><li><strong>업무와 연관된 학습</strong></li><li><strong>업무와 연관되지 않은 비-기술적인 학습</strong></li></ol><h2 id="1-건강-👎"><a href="#1-건강-👎" class="headerlink" title="1. 건강 👎"></a>1. 건강 👎</h2><p>일을 오래 잘하려면 체력이 좋아야하고 건강한 것이 필수이다. 2019년엔 그에 맞춰 아래와 같은 계획을 세웠었다.</p><ul><li>삼시세끼 잘 먹을 것 👎</li><li>근력, 근지구력 열심히 키울 것 👎</li><li>규칙적인 수면 습관을 들일 것 👎</li></ul><p>성향상 아침 잠이 많은 편이고 점심, 저녁은 회사 업무를 하다보면 잘 챙겨먹는 편이었던 나는 세 가지를 한꺼번에 잡기 위해서 규칙적인 생활 아래에서 이른 기상으로 아침 식사와 운동을 잘 잡으려 노력했다. 운동은 원래 즐겨하던 비보이 연습과 회사에서 헬스를 병행하는 방식으로 했다. 2월 달을 기점으로 살짝 흔들렸던 것 같고 본격적으로 9월부터는 전혀 해당 목표에 대해서 관리하지 못했다.</p><h2 id="2-경제적-자립-👌"><a href="#2-경제적-자립-👌" class="headerlink" title="2. 경제적 자립 👌"></a>2. 경제적 자립 👌</h2><p>이제는 나이도 나이인지라 미래의 나를 위해 경제적인 부분에서 자립할 수 있을 정도로 스스로 지출 설계 및 소비 패턴 제어가 필요했다. 이를 위해 아래와 같은 작업을 했다.</p><ul><li>고정 지출 분석 👍</li><li>데일리 로그에서 데일리 지출 기록 👍</li><li>매달 말 지출 내역 분석 및 회고 👎</li></ul><p>이 또한 9월까지는 순조롭게 잘 관리했고 년초에 목표했던 금액에 80%를 달성할 정도로 근사한 달성률을 보였다. 9월 이후에는…. 👀</p><h2 id="3-업무와-연관된-연관되지-않은-학습-😭"><a href="#3-업무와-연관된-연관되지-않은-학습-😭" class="headerlink" title="3. 업무와 연관된, 연관되지 않은 학습 😭"></a>3. 업무와 연관된, 연관되지 않은 학습 😭</h2><p>항상 언제든지 도태될 수 있다는 생각을 달고 살았던지라 자기계발을 놓고 살지는 않았다. 2019년에는 아래와 같은 내용으로 자기계발 내용을 조금 더 구조화하고 체계적으로 바꿀까했다.</p><ul><li>1주일 1개 paper 리딩 후 TIL 👍</li><li>한달에 한권씩 책읽고 후기 남기기 👎</li><li>Object Detection 구현 모임 👎</li><li>경량화 네트워크 프로젝트 진행 👍</li><li>공인인증 영어성적 획득 👎</li></ul><h3 id="1주-1일-Paper"><a href="#1주-1일-Paper" class="headerlink" title="1주 1일 Paper"></a>1주 1일 Paper</h3><p>현실감각이 없었던 계획이었지만, 연구직이라는 업무 특성과 대학원 수업에서 강제적인 논문 발표 수업으로 인하여 논문을 꽤나 읽게되어 나름 만족으럽게 80%의 달성률을 보였다. 읽은 논문 리스트는 아래와 같다.</p><p>SqueezeNet / BinaryConnect / Binarized Neural Network / XNOR Net / EfficientNet / EfficientDet / Trained CNNs are biased towards texture / rafiqi  / TFX / TrIMS / Clipper / 기타 헬스케어 관련 논문 20편 내외</p><h3 id="경량화-네트워크-프로젝트"><a href="#경량화-네트워크-프로젝트" class="headerlink" title="경량화 네트워크 프로젝트"></a>경량화 네트워크 프로젝트</h3><p>9월달 대학원에 입학하자마자 석사 1기생들과 팀을 꾸려 인공지능 수업에서 BinaryConnect와 Binarized Neural Network를 구현하는 프로젝트를 진행하였다. Binarized Neural Network까지 구현을 하지는 못하였지만 BinaryConnect까지는 진행 완료하게 되었다.</p><h1 id="2019년-계획하지-않았던-일들"><a href="#2019년-계획하지-않았던-일들" class="headerlink" title="2019년 계획하지 않았던 일들.."></a>2019년 계획하지 않았던 일들..</h1><p>2019년 초에 세웠던 계획과 다르게 삶에 터닝 포인트가 되거나 여러 사건들이 많이 생기게 되었다. 년초에 세웠던 계획들이 크게 틀어지게된 계기는 <strong>대학원 입학</strong>과 <strong>여러 새로운 업무들</strong>이 제일 컸다.</p><ul><li>성남시 빅데이터 이노베이션 해커톤 부분 최우수상 수상</li><li>EO-Detection 대회 준비</li><li>시흥 시청 빅데이터 분석 주강사, 보조강사</li><li>대학원 입학</li><li>하이퍼커넥트 CS기초 스터디</li><li>MML-Book 스터디</li><li>여러 새로운 업무들</li></ul><h1 id="2019년을-보내며"><a href="#2019년을-보내며" class="headerlink" title="2019년을 보내며.."></a>2019년을 보내며..</h1><p>2019년에 여러 일들을 겪으며 내가 얻게된 화두의 키워드는 아래와 같다.</p><ul><li>함께 자라기</li><li>의연하게 대처하기</li><li>잘 예측하고 책임감 있게 수행하기</li><li>감사하기</li><li>꾸준하기</li></ul><h2 id="함께-자라기"><a href="#함께-자라기" class="headerlink" title="함께 자라기"></a>함께 자라기</h2><p>지금까지는 호흡이 맞는 사람들과 프로젝트를 했다면 2019년에는 회사 업무와 학교 프로젝트에서 호흡을 맞춰 보지 않았던 사람들과 호흡을 맞췄다. 호흡을 맞추던 과정에서 당연히 알 것이라고 생각했던 것들을 사람들이 모를 수 있다는 것을 깨달았다. 덕분에 예상하지 못했던 부분에서 많은 시간을 투입하게 되었고 스스로가 병목이 되는 경험을 해볼 수 있었다. 다음번부터는 팀원들의 능력에 따른 예상시간을 추정해보고 그에 따라서 업무를 진행해보려고 한다. 또한 스스로 병목이 되는 구간에 대해서는 어디까지 병목을 허용하고 허용하지 않을지에 대한 지점을 찾아볼까 한다.</p><h2 id="의연하게-대처하기"><a href="#의연하게-대처하기" class="headerlink" title="의연하게 대처하기"></a>의연하게 대처하기</h2><p>2019년 9월부터 대학원과 회사 업무를 병행하게 되었다. 대학원은 SoC연구실로 입학하게 되었고 회사에서는 인공지능 모델 서빙을 위한 클라우드 연구에서 마이크로 아키텍쳐 서비스 시스템에 GPU를 연동하기 위한 설정과 마이크로 아키텍쳐 서비스에 사용되는 컨테이너 변경하는 작업, 마이크로 아키텍쳐 시스템을 시연하는 여러 데모 프로그램을 작성하게 되었다. 그 과정에서 개인적으로 힘듦을 느껴 주변에 스스로의 상태에 대해 많이 토로했던 것 같다. 새해가 지나고 천천히 돌아보니 나뿐만 아니라 모두가 그런 일상을 보내고 있었다라는 것을 깨닫고 부끄러웠다. 계속 경험하다보면은 자연스러워지겠지만 당분간은 의식적으로 마음의 여유를 잘 찾아서 의연함을 잃지 않게 노력해보려고 한다.</p><h2 id="잘-예측하고-책임감-있게-수행하기"><a href="#잘-예측하고-책임감-있게-수행하기" class="headerlink" title="잘 예측하고 책임감 있게 수행하기"></a>잘 예측하고 책임감 있게 수행하기</h2><p>2019년도 과제를 마무리하기 위해서 회사에서 9월부터 12월까지 여러 작업을 진행하면서 순간순간 예측을 벗어나는 일들이 많았던 것 같다. 예측을 크게 벗어나 몇번 할당된 업무를 제때 수행하지 못할 뻔한 위기상황을 많이 겪었는데, 프로젝트를 관리하는 측면에서 나의 이러한 상황은 굉장히 불안정해보일 수 있다는 점을 깨달았다. 이는 년초에 추정했던 업무량을 상회해서 발생했다라고 판단하고 있고, 2019년도에 크게 한번 겪어봤으니 2020년에는 추가적인 업무량과 예상되는 업무량 그리고 내가 수용가능한 업무량을 잘 조율하여 업무를 매끄럽게 수행해볼 수 있게 노력해보고자 한다.</p><h2 id="감사하기"><a href="#감사하기" class="headerlink" title="감사하기"></a>감사하기</h2><p>2019년에 자율차 플랫폼 연구부서에서 현재 부서로 이동하고나서 정말 다양한 경험을 하게되었다. 대학원을 병행하면서 갈증이 있던 지식을 수업을 통해서 해소했고 해보고싶었던 연구도 즐겁게 했다. 더 중요한 것은 <strong>할당된 업무를 혼자 독립적으로 충분히 업무를 진행할 수 있다는 자신감</strong>이다. 이런 유의미한 경험들이 다 주변 사람들이 믿어주고 기회와 충분한 시간을 주었던 덕분이 아닐까 싶다. 이런 좋은 환경에서도 상황이 급박해져서 불만을 종종 토로하곤 했는데 이런 행동은 스스로에게 그렇게 도움이되는 태도는 아니라고 생각한다. 2020년에는 조금 더 감사히 내게 주어진 환경에서 즐겁고 열심히 최선을 다하는 한해가 되었으면 한다.</p><h2 id="꾸준하기"><a href="#꾸준하기" class="headerlink" title="꾸준하기"></a>꾸준하기</h2><p>비록 년초에 새웠던 공부 일정은 달성하지 못했지만 몇가지 꾸준히 진행했던 프로젝트 및 스터디는 유의미한 결과를 얻어 내년에도 지속할 수 있는 결과들을 얻었다. 1~2년을 꾸준히 진행했던 덕분이 아닐까 싶다. 생각 외로 스터디에서 진행했던 공부들이 업무에 직접적으로 또는 간접적으로 크게 영향을 많이 준다는 것을 깨달았는데, 2020년에는 더 깔끔하게 정제되게 꾸준히 하는 스터디를 진행해보았으면 하는 바람이다.</p><h1 id="2020년을-맞이하며"><a href="#2020년을-맞이하며" class="headerlink" title="2020년을 맞이하며.."></a>2020년을 맞이하며..</h1><p>2020년에도 2019년과 다를게 없이 관심사는 아래와 같이 같은 카테고리로 나뉘어질 듯 하다.</p><ul><li>건강</li><li>경제적 자립</li><li>업무 관련 학습</li><li>기타 학습</li></ul><h2 id="건강"><a href="#건강" class="headerlink" title="건강"></a>건강</h2><p>9월~12월 동안 급격하게 흘러갔던 업무 상황으로 운동도 내팽겨친채 밤새 일했던 시간이 많았다. 그 결과로 12월 말에 몸이 2~3주 동안 계속 아팠는데 체력적으로 많이 부족하다는 생각이 들었다.</p><ul><li>오전에 할 수 있는 운동 진행(크로스핏, 수영, 등등)</li></ul><h2 id="경제적-자립"><a href="#경제적-자립" class="headerlink" title="경제적 자립"></a>경제적 자립</h2><p>분당으로 이사오고 나서 초기에 세웠던 경제적 목표가 크게 틀어졌다. 2020년에는 더 긴장하고 경제적 목표를 채워볼까 한다.</p><ul><li>고정 지출, 고정 수입 확인</li><li>가계부 작성</li><li>매달 가계부 분석 및 회고</li></ul><h2 id="업무-관련-학습"><a href="#업무-관련-학습" class="headerlink" title="업무 관련 학습"></a>업무 관련 학습</h2><p>2020년은 인공지능 모델 서빙관련 프로젝트가 종료되는 해이다. 이번년도는 더 탄탄해진 업무 프로세스와 함께 내가 접근해야하는 기술 스택이 더 많아졌는데 시간이 된다면 아래와 같은 학습을 더 해볼까 한다. 추가적으로 대학원 졸업을 위해서 하드웨어관련 지식을 더 학습할 예정이다.</p><ul><li>Golnag</li><li>쿠버네티스</li><li>gRPC</li><li>Verilog</li><li>FPGA</li><li>TDD</li></ul><h2 id="기타-학습"><a href="#기타-학습" class="headerlink" title="기타 학습"></a>기타 학습</h2><p>이번년도는 대학원 졸업 및 미래의 이직을 위한 여러가지 학습을 진행하려고 한다. 따라서 협업을 위한 스킬이라던가 면접을 위한 공부와 코딩 테스트를 위한 공부를 추가적으로 진행할 예정이다.</p><ul><li>자료구조/알고리즘</li><li>OS</li><li>디자인패턴</li><li>개발자 교양도서 독서 모임</li><li>EO-Detection 대회</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;이번 포스팅은 2019년의 나를 돌아보고 2020년을 계획하는 회고를 적어볼까 한다.&lt;/p&gt;</summary>
    
    
    
    <category term="Retrospective" scheme="http://ssaru.github.io/categories/Retrospective/"/>
    
    
    <category term="Retrospective" scheme="http://ssaru.github.io/tags/Retrospective/"/>
    
  </entry>
  
  <entry>
    <title>How the Eye of A.I Sees</title>
    <link href="http://ssaru.github.io/2019/08/06/20190806-How_the_Eye_of_AI_Sees/"/>
    <id>http://ssaru.github.io/2019/08/06/20190806-How_the_Eye_of_AI_Sees/</id>
    <published>2019-08-06T07:23:55.000Z</published>
    <updated>2021-11-26T12:08:48.907Z</updated>
    
    <content type="html"><![CDATA[<!--toc--><p>이번 포스팅은 논문 <a href="https://openreview.net/pdf?id=Bygh9j09KX">ImageNet - Train CNNs are biased towards texture; increasing shape bias improves accuracy and robustness</a>을 읽고 읽은 내용을 포스팅한다.<br><span id="more"></span></p><h1 id="무엇이-맞는-말일까"><a href="#무엇이-맞는-말일까" class="headerlink" title="무엇이 맞는 말일까??"></a>무엇이 맞는 말일까??</h1><h2 id="컨볼루션-뉴럴-네트워크-Convolutional-Neural-Network-가-무엇에-편향되는지-바라보는-두-가지-관점"><a href="#컨볼루션-뉴럴-네트워크-Convolutional-Neural-Network-가-무엇에-편향되는지-바라보는-두-가지-관점" class="headerlink" title="컨볼루션 뉴럴 네트워크(Convolutional Neural Network)가 무엇에 편향되는지 바라보는 두 가지 관점"></a>컨볼루션 뉴럴 네트워크(Convolutional Neural Network)가 무엇에 편향되는지 바라보는 두 가지 관점</h2><p>형상 정보 가설과 질감 정보 가설(Shape Hypothesis vs Texture Hypothesis)</p><h3 id="형상정보-가설-Shape-Hypothesis"><a href="#형상정보-가설-Shape-Hypothesis" class="headerlink" title="형상정보 가설(Shape Hypothesis)"></a>형상정보 가설(Shape Hypothesis)</h3><p>많은 사람들은 컨볼루션 뉴럴 네트워크(Convolutional Neural Network; 이하 CNN)가 <em>“레이어가 깊어질 수록 저-레벨(low level)의 특징(feature)을 조합해서 고-레벨(high level) 특징(feature)을 만들고, 이 특징들을 이용하여 객체인식을 한다.”</em> 이라는 직관에 동의할 것이다.</p><p><img src="layer12-de7c9aef-a43f-4314-9c83-0034c314fa4a.png" alt=""></p><p><img src="layer3-78e973d7-5554-4638-a0b5-51f93ad0df7f.png" alt=""></p><p>[그림 1] ZF-Net으로 시각화한 layer들의 특징</p><p>CNN이 객체 분류를 어떻게 하는지에 대한 공통된 해석은 여러 문헌에서도 나타나는데 Kriegeskorte과 LeCun은 그들이 저술한 <a href="https://pdfs.semanticscholar.org/fd88/2a24391a05bf4cf92e8259101f7944d88a56.pdf">논문</a> 혹은 <a href="https://www.researchgate.net/profile/Y_Bengio/publication/277411157_Deep_Learning/links/55e0cdf908ae2fac471ccf0f/Deep-Learning.pdf">아티클</a>에서 아래와 같이 언급했다.</p><blockquote><p>CNN은 각 카테고리(강아지, 고양이)가 가지고있는 고유한 패턴과 같은 지식을 얻는다.  … (중략) … 고-레벨(high level)의 특징들은 실제 영상(생성되거나 조작되지 않은 영상)에서 나타나는 형상(shape; 이하 형상) 정보를 배우는 것 처럼 보인다.</p><p>CNN의 중간 레이어들은 같은 카테고리의 객체들에게서 유사한 부분을 인식한다. …(중략) … 객체를 검출하는 것은 이러한 부분들의 조합이다.</p></blockquote><p>이렇게 CNN이 형상 정보를 학습한다는 주장을 <strong>형상 정보 가설 (Shape Hypothesis)</strong>부른다.</p><p>형상 가설은 수많은 실험을 통해서 지지를 받는데, 대표적으로 <a href="https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf">ZF-Net</a>이 있다. <a href="https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf">ZF-Net</a>은 모델의 레이어로부터 특징들을 추출한다. 그 후 역-컨볼루션(De-Convolution)이라는 연산을 통해서 추출한 특징을 시각화한다. [그림 1]은 ZF-Net에서 추출한 특징을 시각적으로 보여준다.</p><p>Kubilius라는 연구자는 CNN을 사람의 <a href="https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1004896&amp;type=printable">시각 인지 모델로써 제안</a>했으며 Ritter는 <a href="https://arxiv.org/pdf/1706.08606.pdf">CNN이 아이들과 유사하게 형상 정보를 개발해나간다</a>는 것을 밝혀냈다. Ritter가 이야기하는 형상 정보를 개발한다는 것의 의미는 색감(Colour) 정보 보다는 형상 정보가 객체 분류를 하는데 더 중요한 역할을 한다는 것을 의미한다. </p><p>실제로 형상 정보 가설은 사람의 인지 체계와 매우 비슷하기도 하다. 사람은 모양이 바뀌면 다른 카테고리로 분류하지만 질감 및 크기가 변화하더라도 같은 모양이면 같은 객체 카테고리로 인식한다. 이는 <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.331.3386&amp;rep=rep1&amp;type=pdf">해당 연구 결과</a>를 통해서 확인되었다.</p><p><img src="Experimental-Stimuli-A-Examples-of-stimuli-used-in-Experiment-1-Scenes-and-objects-4291356f-3c4c-46d0-8e7d-987059291c32.png.jpeg" alt=""></p><p>[그림 2] 사람은 질감과는 관계없이 모양에 따라 같은/다른 물체로 인식한다.</p><p><strong>Summary</strong></p><ul><li>형상정보 가설(Shape Hypothesis)는 CNN이 객체의 거시적인 형상을 보고 인식을 한다는 가설이다.</li><li><p>가설을 지지하는 실험들이 여러 논문들을 통해서 확인되었다.</p><p>  ZF-Net, A Shape Bias Case Study, </p></li><li><p>이러한 형상정보 가설은 사람의 인지체계와도 제일 유사한 측면을 갖는다.</p></li></ul><h3 id="질감-정보-가설-Texture-Hypothesis"><a href="#질감-정보-가설-Texture-Hypothesis" class="headerlink" title="질감 정보 가설(Texture Hypothesis)"></a>질감 정보 가설(Texture Hypothesis)</h3><p>몇몇 연구 결과들은 형상 정보 가설과 상반되는 결과를 얻기도 했다. 대표적으로 연결이 부분적으로 끊어진 네트워크에서 학습된 모델은 질감 정보(Texture; 이하 질감)가 더 중요한 역할을 한다는 연구가 있다. <a href="https://www.researchgate.net/profile/Alexander_Ecker/publication/319940454_Texture_and_art_with_deep_neural_networks/links/59d814150f7e9b12b3612c60/Texture-and-art-with-deep-neural-networks.pdf">해당 연구</a>에서는 CNN이 전반적인 형상 정보가 없어도 질감 정보를 이용해서 영상을 잘 분류할 수 있다는 것을 증명한다. 오히려 질감 정보가 없는 형상 정보(스케치 그림)만으로 학습한 CNN은 나쁜 인식 성능을 갖는다.</p><p><img src="Screenshot_from_2019-07-26_15-42-51-76e6b3c4-a54d-49d0-ad13-bd29cd6e7614.png" alt=""></p><p>[그림 3] CNN의 질감 정보만을 이용한 분류 예시</p><p><img src="Screenshot_from_2019-07-26_15-52-57-28ac9b25-f52b-47bf-9d2d-de62245dc131.png" alt=""></p><p><img src="Screenshot_from_2019-07-26_15-54-14-9bc52e1c-cf20-4470-9476-1ddee077e191.png" alt=""></p><p>[그림 4] 질감 정보가 없는 스케치 데이터로만 학습했을 때, 새(bird) 데이터를 얼마나 많이, 자주 틀리는지에 대한 예시</p><p>두 가지 결과는 질감 정보와 같은 지역적인 정보(Local feature)만을 이용해서 객체 인식 문제를 충분히 해결할 수 있다는 것을 시사한다. 이를 증명한 연구결과는 <a href="https://papers.nips.cc/paper/5633-texture-synthesis-using-convolutional-neural-networks.pdf">여기</a>에서 확인할 수 있다. </p><p>질감 정보의 중요성을 이야기하는 또 다른 연구에서는 질감 정보를 학습하고 특정 질감 정보를 생성하는 네트워크를 만들었다. 이렇게 질감 정보를 종류별로 학습하고 생성한다는 것은 모델이 세 가지의 기능을 수행한다는 의미를 갖는다.</p><ol><li>종류별 질감 정보를 분류한다.</li><li>종류별 질감 정보의 분포를 학습한다.</li><li>특정 질감 정보의 분포를 생성 한다.</li></ol><p><em>해당 네트워크는 분류(Classification)를 하는 네트워크가 아니다. 하지만 질감 정보를 종류별로 생성한다는 것은 “질감 정보의 분포가 서로 다르기 때문에 질감 별로 분리해서 학습할 수 있다”는 것을 내포한다. 이런 맥락에서 논문의 저자는 질감 정보만으로 객체 분류 문제를 풀 수 있다고 이야기하는 듯 하다.</em></p><p><img src="Screenshot_from_2019-07-26_16-04-33-a8313feb-2a86-42ed-b50c-be0dc81d9680.png" alt=""></p><p>[그림 5] 질감정보를 생성하는 네트워크</p><p>그 외에도 <a href="https://openreview.net/pdf?id=SkfMWhAqYQ">다른 연구</a>에서는 최대 리셉티브 필드의 크기에 제한을 둔 BagNet을 설계했다. BagNet은 최대 리셉티브 필드 크기의 제한으로 CNN이 국부적인 정보만 볼수 있게끔 시야가 제한이 되었다. 그럼에도 불구하고 ImageNet 데이터에서 놀라울 정도로 높은 정확도를 갖는 결과를 얻었다. 이러한 결과들을 보았을 때 국부적인 질감 정보는 객체 분류를 하는데 충분한 정보를 가지고 있음을 알 수 있다. CNN은 이런 질감 정보을 추론하는데 이를 <strong>질감 정보 가설(Texture Hypothesis)</strong>라고 부른다.</p><p><img src="Screenshot_from_2019-07-26_17-17-05-c8099ac0-ddd8-4d8f-a93f-e75eaddb5ffc.png" alt=""></p><p>[그림 6] 최대 리셉티브 필드의 크기가 제한된 Bag Net의 최종 Layer에서 확인된 Feature들</p><p><strong>Summary</strong></p><ul><li>질감정보 가설(Texture Hypothesis)는 CNN이 객체의 국부적인 질감정보를 보고 인식을 한다는 가설이다.</li><li>가설을 지지하는 실험들이 여러 논문을 통해서 확인되었다.</li></ul><hr><p>지금까지 형상 정보 가설(Shape Hypothesis)와 질감 정보 가설(Texture Hypothesis)를 살펴보았다. 이렇게 상반되는 두 가지 가설을 해결하는 것은 인공지능 커뮤니티와 뇌 과학자 커뮤니티 모두에게 중요하다. </p><p>해당 논문에서는 <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf">StyleGAN</a>을 이용하여 질감-형상 정보가 모순된 이미지(Cue Conflict)를 만들었다. 이를 이용하면 CNN과 사람의 시각 능력에 대해서 정량적으로 측정할 수 있게 된다. 이렇게 만든 질감-형상 정보가 모순된  이미지(Cue Conflict)를 이용해서 총 97명의 실험 참가자와 함께 9종류의 정신 물리학 실험(Psychophysical Experiments) 을 진행하였다. 총 실험의 횟수는 48,560번이었다.</p><p>본 논문의 기여는 아래와 같다.</p><ul><li>CNN과 사람의 인지 차이를 확인함</li><li>CNN의 편향의 변경할 수 있음을 확인함</li><li>편향의 변경으로 생기는 효과를 확인함</li></ul><h1 id="실험"><a href="#실험" class="headerlink" title="실험"></a>실험</h1><p>CNN과 사람의 시각 시스템의 차이를 확실하게 확인하기 위해서 해당 논문에서는 여러가지 실험을 진행했다.<br><br/></p><ol><li>CNN과 사람의 시각 시스템은 서로 어떻게 다를까?(Psychophysical Experiments)</li><li>데이터셋</li><li>모순된 영상을 보여준다면? (Cue Conflict)</li><li>실험 결과</li><li>CNN이 사람과 비슷하게 보게 하려면? 비슷하게 보게 된다면?</li></ol><h2 id="CNN과-사람의-시각-시스템은-서로-어떻게-다를까-Psychophysical-Experiments"><a href="#CNN과-사람의-시각-시스템은-서로-어떻게-다를까-Psychophysical-Experiments" class="headerlink" title="CNN과 사람의 시각 시스템은 서로 어떻게 다를까? (Psychophysical Experiments)"></a>CNN과 사람의 시각 시스템은 서로 어떻게 다를까? (Psychophysical Experiments)</h2><p>CNN과 사람이 어떻게 물체를 인식하느냐(질감 정보를 기반으로 인식하느냐? vs 형상 정보를 기반으로 인식하느냐?)를 확인하기 위해서 정신 물리학(Psychophysical Experiments; 이하 정신 물리학) 실험을 진행하였다.</p><p>실험 내용은 16-Class-ImageNet이라는 데이터 셋을 사람과 CNN에게 똑같이 보여주고 이미지 분류 작업 결과를 확인하였다. 실험 참가자는 총 97명이었으며 16-Class-ImageNet의 데이터수는 49K(49,000)였다.</p><p>사람과 CNN이 본질적으로 큰 차이가 있기 때문에 실험은 굉장히 신중하게 설계 되었어야 했다. CNN은 단일의 영상 정보를 한번만 네트워크에 입력하지만 사람의 시각 시스템은 연속된 정보(동영상)을 획득하고 뇌에서는 이를 기반으로 각 신경끼리 피드백을 주고받는다. 따라서 단순하게 영상을 보여주고 분류하는 실험은 CNN과 사람에게 <strong>단 한장의 영상만 보고 분류를 한다</strong>라는 실험 조건에서 <em>단 한장</em>이 서로 다를 수 있다.</p><p>실험을 최대한 공평하게 진행하기 위해서는 사람과 CNN의 실험 조건을 같게 설정 해야했다. 사람의 시각 시스템에서 발생하는 피드백은 영상을 제공하는 순서와 타이밍을 조절하여 최소화하였다. 이러한 방법은 이미 정신 물리학적 실험에서는 잘 알려진 사실이라고 논문에서는 언급한다. 하지만 <em>의학적인 참고자료가 제시되어있지 않아서 더 자세한 근거는 확인하지 못했다.</em></p><ol><li>200ms 동안 분류작업을 할 영상을 보여준다.</li><li>300ms 동안 고정된 사각형 이미지를 보여준다.</li><li>1/f 스펙트럼을 가진 노이즈 마스크를 200ms동안 보여준다.</li></ol><p><img src="screenshot-from-2018-05-17-20-24-45-00c8ba94-f94d-422b-aa73-cc123fe604e4.png" alt=""></p><p><a href="https://neurdiness.wordpress.com/2018/05/17/deep-convolutional-neural-networks-as-models-of-the-visual-system-qa/">[그림 7]</a> CNN과 사람의 시각 시스템의 비교</p><h2 id="데이터-셋"><a href="#데이터-셋" class="headerlink" title="데이터 셋"></a>데이터 셋</h2><p>해당 연구의 실험에서는 사람과 CNN이 서로 어떤 가설을 기반으로 인지를 하는지 확인하는 것이 목적이므로 16-Class ImageNet 데이터를 왜곡하여서 진행하였다. </p><ul><li>Original</li><li>GreyScale</li><li>Silhouette</li><li>Edges</li><li>Texture</li><li>Cue Conflict (모순된 영상)</li></ul><p><img src="Screen_Shot_2019-08-05_at_12-5e21295c-52d8-4807-8d6e-87b8800647cf.44.50_AM.png" alt=""></p><p>[그림 8] 16-Class ImageNet 예시</p><h2 id="모순된-영상-Cue-Conflict"><a href="#모순된-영상-Cue-Conflict" class="headerlink" title="모순된 영상(Cue Conflict)"></a>모순된 영상(Cue Conflict)</h2><p>기본적인 이미지 왜곡 외에도 서로 다른 형상 정보와 질감 정보가 섞여 있어 모순을 일으키는 Cue Conflict 영상으로도 실험을 진행하였다.</p><p><img src="Screen_Shot_2019-08-05_at_12-f4524e3d-8c7d-469a-8bd1-2d246a21a446.50.32_AM.png" alt=""></p><p>[그림 9] Silhouettes를 이용한 Cue Conflict 영상(위에서 3번째)과 Style transfer를 이용한 Cue Conflict 영상(위에서 네 번째)</p><p>Cue Conflict 영상을 만들기 위해서 두 가지 방법을 적용하였다.</p><ol><li>세그멘테이션 맵을 이용해 다른 영상 정보를 혼합하는 방법(filled silhouettes)</li><li>Style GAN을 이용하여 영상 정보를 혼합하는 방법(style transfer)</li></ol><p>연구자들이 막상 이러한 영상을 만들고 나니까 문득 든 생각이 <strong>해당 영상들이 실제 형상 정보와 질감 정보가 완전히 모순 되어 있다는 것을 어떻게 증명할 수 있을까?</strong> 였다. 이를 증명하기 위해서 연구자들은 앞서 언급했던 Bag Net를 사용하였다.</p><p>Bag Net는 최대 리셉티브 필드의 크기를 제한하여 CNN이 이미지의 전체 형상을 보지 못하게 만든 모델이다. 국부적인 특징(local feature)들만 이용했음에도 불구하고 BagNet은 굉장히 좋은 성능을 나타내었는데 만약 국부적인 특징(Texture)이 전체적인 특징(Shape)과 모순되어있다면(Cue conflict) Bag Net의 성능이 급격히 하락할 것이다.</p><p>실제로 Bag Net을 이용하여 Cue conflict 영상을 추론해본 결과 기존 ImageNet 데이터에서 성능이 잘 나오던 모델이 약 85% 정도의 성능 하락 발생한 것을 할 수 있었다.(ImageNet, 70.0% top-5 accuracy → Cue conflict, 10.0% top-5 accuracy)</p><p>이를 토대로 생성된 Cue conflict 영상이 형상 정보와 질감 정보가 모순되어 있다는 것을 확인할 수 있었다.</p><h2 id="실험-결과"><a href="#실험-결과" class="headerlink" title="실험 결과"></a>실험 결과</h2><p>실험 결과 사람과 CNN이 물체를 분류하는 작업에서 큰 차이를 볼 수 있었다. 사람은 굉장히 형상 정보에 편향되어 있고, CNN은 질감 정보에 편향되어 있음을 확인할 수 있었다.</p><p>이는 고양이 형상에 코끼리 가죽 질감 정보가 섞여있는 Cue conflict 영상을 사람과 CNN에게 보여주었을 때, CNN은 이를 <strong>“코끼리”</strong>로 사람은 이를 <strong>“고양이”</strong>로 인식한다는 이야기가 된다.</p><p><img src="Screen_Shot_2019-07-24_at_2-3f1bbca5-9002-432e-a761-3e9cf949f3dc.56.43_PM.png" alt=""></p><p>[그림 10] CNN과 사람의 시각 시스템의 차이. 왼쪽은 형상 정보 편향을 의미하고 오른쪽으로 질감 정보 편향을 의미한다. 해당 그림에서 사람은 형상 정보에 편향 되어있음을 CNN은 질감 정보에 편향 되어있음을 확인할 수 있다.</p><h2 id="CNN이-사람과-비슷하게-보게-하려면-비슷하게-보게-된다면"><a href="#CNN이-사람과-비슷하게-보게-하려면-비슷하게-보게-된다면" class="headerlink" title="CNN이 사람과 비슷하게 보게 하려면? 비슷하게 보게 된다면?"></a>CNN이 사람과 비슷하게 보게 하려면? 비슷하게 보게 된다면?</h2><p>연구자들은 이제 <strong>CNN이 사람과 비슷하게 형상 정보에 편향되면 어떻게 될까?</strong>가 궁금해졌다. 그래서 기존의 <strong>IN</strong>(ImageNet) 데이터와 <strong>SIN</strong>(Sytle transfered ImageNet)데이터를 이용하여 학습을 진행하였다.</p><p>학습 방법에 대해서는 다양한 실험을 진행했다</p><ol><li>IN 학습 → IN으로 평가</li><li>IN 학습 → SIN으로 평가</li><li>SIN 학습 → IN으로 평가</li><li>SIN 학습 → SIN으로 평가</li><li>IN과 SIN을 혼합해서 학습 → IN으로 평가</li><li>IN과 SIN을 혼합하여 학습 후 IN으로 파인튠 → IN으로 평가</li></ol><p>학습 후에는 모델이 효과적으로 형상 정보 편향이 되었는지 확인하기 위해 16-Class-ImageNet 데이터를 이용하여 이를 확인하였다. 전부는 아니지만 많은 클래스에 대해서 CNN이 질감 정보 편향에서 형상 정보 편향으로 이동 하였음을 확인할 수 있었다.</p><p><img src="Screen_Shot_2019-07-24_at_3-922d85d2-ebec-4437-9ae7-773da82ff745.51.49_PM.png" alt=""></p><p>[그림 11] IN/SIN 데이터를 학습한 모델과 사람의 차이. 데이터를 혼합해서 학습한 모델이 그림 10. 과 비교했을 때 상대적으로 형상 정보 편향으로 이동되었음을 확인할 수 있다.</p><p>결론적으로 해당 실험에서 <strong>SIN 데이터</strong>(형상 정보 편향)만으로는 성능을 더 개선시킬 수는 없었다. 하지만 <strong>IN</strong> 데이터와 <strong>SIN</strong>데이터를 혼합해서 학습하는 경우에는 ImageNet 데이터 셋만 이용해서 학습한 것보다는 성능이 더 좋아진다는 것을 확인하였다. 또한 형상 정보 편향이 된 CNN을 이용해 객체 검출(Object Detection) 모델에 전이 학습(Transfer learning)했을 때, 기존의 객체 검출 모델보다 성능이 더 개선 되었음을 확인할 수 있었다. 이는 <strong>SIN</strong>데이터를 혼합해서 학습하는 것이 모델의 일반화(Generalization)에 더 기여한다고 해석할 수 있다.</p><p><img src="Screen_Shot_2019-07-24_at_3-7591f4fc-6465-4e77-a853-0821aa698abd.52.15_PM.png" alt=""></p><p>[그림 12] IN데이터와 SIN 데이터를 이용한 CNN 학습 결과</p><p>그 외에 노이즈를 이용한 영상 왜곡 실험을 추가로 진행했다. 이 경우에도 형상 정보에 편향된 CNN이 노이즈 왜곡에도 모델이 더 강인해짐을 확인할 수 있었다.</p><p><img src="Screen_Shot_2019-07-24_at_5-2d3778ca-9b7d-43a9-ac91-217353e79e1e.38.52_PM.png" alt=""></p><p>[그림 13] 추가 영상 왜곡 실험에서 사용한 노이즈 예시</p><p><img src="Screen_Shot_2019-07-24_at_5-edcf9de5-0d18-47aa-a2f0-abe4fcacb91a.34.05_PM.png" alt=""></p><p>[그림 14] 형상 정보, 질감 정보에 편향된 CNN이 노이즈 왜곡에 따라 나타내는 성능</p><h1 id="요약"><a href="#요약" class="headerlink" title="요약"></a>요약</h1><ul><li><p>기존의 CNN이 이미지 분류를 할 때, 형상 정보를 기반으로 인식을 한다는 <strong>형상 정보 가설(Shape Bias Hypothesis)</strong>와 질감 정보를 기반으로 인식한다는 <strong>질감 정보 가설(Texture Bias Hypothesis)</strong>가 존재했다.</p></li><li><p>사람과 CNN이 영상 데이터를 어떤 관점에서 분류하는지 확인하기 위해 정신 물리학 실험을 수행했다. 해당 실험을 통해서 사람은 형상 정보에 편향 되어있고, CNN은 질감 정보에 편향 되어  있음을 확인할 수 있었다.</p></li><li><p>모델을 SIN/IN 데이터를 혼합하여 학습하면 모델을 형상 정보로 편향시킬 수 있다. 형상 정보로 편향된 모델이 기존 IN 데이터로만 학습된 모델보다 더 좋은 성능을 나타냄과 동시에 전이 학습(Transfer learning)에서도 성능 개선이 유효함을 확인할 수 있었다. 따라서 본 논문에서 제안한 SIN/IN 데이터 학습이 인공지능 모델을 일반화(Generalization) 시키는데 기여한다라고 이야기할 수 있다.</p></li></ul><h1 id="참고자료"><a href="#참고자료" class="headerlink" title="참고자료"></a>참고자료</h1><ol><li><a href="https://arxiv.org/pdf/1811.12231.pdf">IMAGENET-TRAINED CNNS ARE BIASED TOWARDS TEXTURE; INCREASING SHAPE BIAS IMPROVES ACCURACY AND ROBUSTNESS</a></li></ol><h1 id="Thanks-to"><a href="#Thanks-to" class="headerlink" title="Thanks to"></a>Thanks to</h1><ul><li><a href="https://lovablebaby1015.wordpress.com/">정미연</a></li><li><a href="https://www.facebook.com/profile.php?id=100024472417238">김형섭</a></li><li><a href="https://gogyzzz.blogspot.com/">권해용</a></li><li><a href="https://github.com/kch8909">김철환</a>(<a href="mailto:markkch@naver.com">markkch@naver.com</a>)</li><li><a href="https://aisolab.github.io/">김보섭</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;!--toc--&gt;
&lt;p&gt;이번 포스팅은 논문 &lt;a href=&quot;https://openreview.net/pdf?id=Bygh9j09KX&quot;&gt;ImageNet - Train CNNs are biased towards texture; increasing shape bias improves accuracy and robustness&lt;/a&gt;을 읽고 읽은 내용을 포스팅한다.&lt;br&gt;</summary>
    
    
    
    <category term="Ai" scheme="http://ssaru.github.io/categories/Ai/"/>
    
    <category term="Paper review" scheme="http://ssaru.github.io/categories/Ai/Paper-review/"/>
    
    
    <category term="CNN" scheme="http://ssaru.github.io/tags/CNN/"/>
    
    <category term="Convolutional Neural Network" scheme="http://ssaru.github.io/tags/Convolutional-Neural-Network/"/>
    
    <category term="Shape Bias" scheme="http://ssaru.github.io/tags/Shape-Bias/"/>
    
    <category term="Texture Bias" scheme="http://ssaru.github.io/tags/Texture-Bias/"/>
    
  </entry>
  
  <entry>
    <title>Connect GPU to Minikube</title>
    <link href="http://ssaru.github.io/2019/07/25/20190725-Connect_GPU_to_Minikube/"/>
    <id>http://ssaru.github.io/2019/07/25/20190725-Connect_GPU_to_Minikube/</id>
    <published>2019-07-25T12:56:53.000Z</published>
    <updated>2021-11-26T12:48:45.482Z</updated>
    
    <content type="html"><![CDATA[<!-- excerpt --><!-- toc --><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>현재 쿠버네티스(Kubernetes, 이하 쿠버네티스)를 이용하여 <em>딥러닝을 지원하는 마이크로 아키텍쳐(Micro Architecture, 이하 마이크로 아키텍쳐) 프레임워크 개발 및 연구</em>를 진행 중이다.</p><p>일반적으로 개발 및 연구 프로젝트의 원활한 진행을 위해서는 개발한 기능을 테스트하기 위한 개발 환경 구축이 필요하게 된다. 필자는 이전에 개발한 기능을 테스트하기 위해서 쿠버네티스 기반으로 작성되어있던 프레임워크를 미니쿠베(minikube, 이하 미니쿠베)에서 구동시키고 테스트하는 작업을 수행했었다.</p><p>이번에는 GPU관련 기능을 테스트하기 위해서 <strong>GPU 컨테이너 사용이 가능하게끔 미니쿠베를 설정하는 작업</strong>을 했으나 정확하지 않은 공식 문서와 인터넷 상에 알파, 베타 버전등 파편화된 가이드 문서로 인해 미니쿠베에서 GPU 인식이 안되어 어려움을 겪었다.</p><p>본 포스팅은 아래 세 가지를 전달하기 위해 작성되었다.</p><ol><li>GPU 컨테이너 사용을 지원하는 미니쿠베 설정 방법 소개</li><li>순서 별로 작업 시 해당 작업이 잘 되었는지 테스트하는 방법</li><li>몇 가지 에러와 해결 방법</li></ol><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>필자는 쿠버네티스를 이용하여 <em>딥러닝을 지원하는 마이크로 아키텍쳐 프레임워크 개발을</em> 하고있으며 사내에서는 서비스 혹은 테스트용으로 GPU 컨테이너 사용을 지원하는 마이크로 아키텍쳐 프레임워크가 구축되어있다.</p><p>여러 명의 개발자와 협업하여 프로젝트를 진행 하다보면 일반적으로 따르는 프로세스가 있다.</p><ol><li>개발자가 기능 개발 수행</li><li>개발 환경에서 개발된 기능을 테스트하고 이상이 없음을 확인한다</li><li>기능 작동 및 테스트가 완료 되면 해당 기능은 프로젝트에 병합한다</li></ol><p>이 때, 개발자의 개발 환경 혹은 테스트 환경은 서비스 배포 환경과 유사하게끔 설정되어야한다. 필자의 프로젝트가 딥러닝을 지원하는 마이크로 아키텍쳐 프레임워크 개발이기 때문에 필자의 개발 환경은 <strong>GPU 컨테이너를 지원하는 미니쿠베 환경</strong>을 갖춰야 했다.</p><h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><p>미니쿠베의 GPU 지원 문서$^{[1]}$를 확인해보면 미니쿠베가 GPU를 지원하는 방법은 크게 두 가지로 나뉘어진다.</p><ol><li>kmv2 가상환경을 이용해서 지원 (<code>--vm-driver=kvm2</code>)</li><li>호스트의 운영체제 환경을 이용해서 지원 (<code>--vm-driver=none</code>)</li></ol><h2 id="kvm2-가상환경-vm-driver-kvm2"><a href="#kvm2-가상환경-vm-driver-kvm2" class="headerlink" title="kvm2 가상환경(--vm-driver=kvm2)"></a>kvm2 가상환경(<code>--vm-driver=kvm2</code>)</h2><p>kvm2환경에서 GPU사용이 가능한 미니쿠베 설정 방법을 소개한다. 이 과정은 기존에 운영체제에 연결되었던 GPU 장치를 kvm2 가상환경에 직접적으로 연결(GPU Passthrough)하는 작업들을 포함$^{[2-9]}$하고 있기 때문에 과정이 복잡하다.</p><p>필자의 경우 해당 방법이 두 가지 사항을 요구했기 때문에 선택하지 않았다.</p><ol><li>기존 nvidia 드라이버에 연결되어있던 GPU 연결 해제</li><li>nvidia 그래픽 드라이버 삭제 필요</li></ol><p>필자의 업무는 마이크로아키텍쳐 프레임워크 개발 외에도 인공지능 모델 개발도 있다. kvm2 환경에서 요구하는 두 가지 사항은 cuda와 cudnn 등 인공지능 모델 개발을 위한 환경설정을 작동하지 않도록 만든다.</p><p>필자가 kvm2환경을 사용하게 되면 업무 별로 nvidia 그래픽 드라이버 및 의존 패키지를 설치하고 삭제하는 작업을 반복적으로 수행해야한다. 이런 이유로 필자는 kvm2 환경을 선택하지 않았다.</p><h2 id="호스트-운영체제-환경-vm-driver-none"><a href="#호스트-운영체제-환경-vm-driver-none" class="headerlink" title="호스트 운영체제 환경(--vm-driver=none)"></a>호스트 운영체제 환경(<code>--vm-driver=none</code>)</h2><p>필자는 공식 문서를 믿고 이를 따라서 미니쿠베 설정을 진행하였다. 적용 결과 기존에 작성된 마이크로 아키텍쳐  프레임워크에서 <strong>GPU를 사용하는 파드(Pods)가 무한 대기(pending)에 빠지는 현상</strong>이 발생했다.</p><p>확인 결과 미니쿠베에서 <strong>GPU 디바이스를 인식하지 못했거나 GPU 디바이스는 인식했으나 관련 드라이버 및 패키지가 존재하지 않아서</strong> 일어난 일이였다.</p><p>미니쿠베, 엔비디아-도커의 세부사항을 몰랐던 필자는 방대한 구글을 헤엄칠 수 밖에 없었다$^{[10-17]}$.</p><h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><h2 id="Prerequisite"><a href="#Prerequisite" class="headerlink" title="Prerequisite"></a>Prerequisite</h2><p>본 포스팅에서는 몇가지 준비 되어야하는 컴퓨터 환경과 작업이 있다. 필자는 아래의 패키지와 Ubuntu 18.04 환경에서 작업하였다.</p><ul><li><p>Docker-CE ( ≥ 18.09)</p></li><li><p>Nvidia-Docker( ≥ 2.03)</p></li><li><p>Nvidia GPU를 장작한 컴퓨터</p></li><li><p>Nvidia 그래픽 드라이버 설치</p></li><li><p>Minikube(≥ 1.2.0)</p></li></ul><p><br/></p><ul><li><p>Nvidia-Graphics-Driver</p><pre><code>  $ nvidia-smi  Fri Jul 19 21:53:48 2019         +-----------------------------------------------------------------------------+  | NVIDIA-SMI 390.116                Driver Version: 390.116                   |  |-------------------------------+----------------------+----------------------+  | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |  | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |  |===============================+======================+======================|  |   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |  | 33%   30C    P8    24W / 250W |    599MiB / 11175MiB |      1%      Default |  +-------------------------------+----------------------+----------------------+  |   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |  | 33%   31C    P8    16W / 250W |      2MiB / 11178MiB |      0%      Default |  +-------------------------------+----------------------+----------------------+  +-----------------------------------------------------------------------------+  | Processes:                                                       GPU Memory |  |  GPU       PID   Type   Process name                             Usage      |  |=============================================================================|  |    0      2117      G   /usr/lib/xorg/Xorg                            40MiB |  |    0      2183      G   /usr/bin/gnome-shell                          50MiB |  |    0      2975      G   /usr/lib/xorg/Xorg                           334MiB |  |    0      3116      G   /usr/bin/gnome-shell                         170MiB |  +-----------------------------------------------------------------------------+</code></pre></li><li><p>Docker</p><pre><code>  $ docker version  &gt;&gt;&gt;  Client:   Version:           18.09.4   API version:       1.39   Go version:        go1.10.8   Git commit:        d14af54266   Built:             Wed Mar 27 18:35:44 2019   OS/Arch:           linux/amd64   Experimental:      false  Server: Docker Engine - Community   Engine:    Version:          18.09.4    API version:      1.39 (minimum version 1.12)    Go version:       go1.10.8    Git commit:       d14af54    Built:            Wed Mar 27 18:01:48 2019    OS/Arch:          linux/amd64    Experimental:     false</code></pre></li><li><p>Nvidia-docker</p><pre><code>  $ nvidia-docker version  &gt;&gt;&gt;  NVIDIA Docker: 2.0.3  ...</code></pre></li></ul><h2 id="Set-docker-default-runtime"><a href="#Set-docker-default-runtime" class="headerlink" title="Set docker default-runtime"></a>Set docker default-runtime</h2><p>미니쿠베에서는 기본 런타임을 Nvidia-Docker가 아닌 Docker-CE로 인식한다. GPU 사용을 위해서 도커의 기본 런타임을 Nvidia-Docker로 변경해준다.</p><p><code>/etc/docker/daemon.json</code> 파일에서 <code>default-runtime</code>을 <code>nvidia</code>로 변경한다.</p><pre><code>&#123;    &quot;default-runtime&quot;: &quot;nvidia&quot;,    &quot;runtimes&quot;: &#123;        &quot;nvidia&quot;: &#123;            &quot;path&quot;: &quot;nvidia-container-runtime&quot;,            &quot;runtimeArgs&quot;: []        &#125;    &#125;&#125;</code></pre><p>변경이 다 되었다면,  도커를 재시작한다.</p><pre><code>$ sudo service docker restart</code></pre><h2 id="Minikube-start"><a href="#Minikube-start" class="headerlink" title="Minikube start"></a>Minikube start</h2><p>미니쿠베를 실행한다. 필요한 옵션에 대해서는 표에 설명해 두었다.</p><pre><code>$ sudo -E minikube start --vm-driver=none --apiserver-ips 127.0.0.1 --apiserver-name localhost --docker-opt default-runtime=nvidia --feature-gates=DevicePlugins=true --kubernetes-version v1.15.0&gt;&gt;&gt;🟟  minikube v1.2.0 on linux (amd64)🟟  Creating none VM (CPUs=2, Memory=2048MB, Disk=20000MB) ...🟟  Configuring environment for Kubernetes v1.15.0 on Docker 18.09.4    ▪ opt default-runtime=nvidia    ▪ kubelet.resolv-conf=/run/systemd/resolve/resolv.conf🟟  Downloading kubeadm v1.15.0🟟  Downloading kubelet v1.15.0🟟  Pulling images ...🟟  Launching Kubernetes ... 🟟  Configuring local host environment ...⚠️  The &#39;none&#39; driver provides limited isolation and may reduce system security and reliability.⚠️  For more information, see:🟟  https://github.com/kubernetes/minikube/blob/master/docs/vmdriver-none.md⌛  Verifying: apiserver proxy etcd scheduler controller dns🟟  Done! kubectl is now configured to use &quot;minikube&quot;</code></pre><div class="table-container"><table><thead><tr><th>name</th><th>description</th></tr></thead><tbody><tr><td>—docker-opt default-runtime=nvidia</td><td>미니쿠베의 기본 도커를 엔비디아 도커로 설정한다</td></tr><tr><td>—feature-gates=DevicePlugins=true</td><td>GPU 지원은 쿠버네티스에서 알바/베타 단계에 속한다. 따라서 이를 사용하기 위해서는 feature-gates 옵션을 이용해서 GPU 사용 옵션을 변경해줘야한다</td></tr><tr><td>—kubernetes-version v1.15.0</td><td>NVIDIA 드라이버를 쿠버네티스와 연결해주는 k8s-device-plugin$^{[18]}$은 1.10이상의 쿠버네티스 버전을 요구한다</td></tr></tbody></table></div><p>미니쿠베 작동을 확인한다.</p><pre><code>$ kubectl get pods --all-namespacesNAMESPACE     NAME                                   READY   STATUS    RESTARTS   AGEkube-system   coredns-5c98db65d4-nks96               1/1     Running   0          149mkube-system   coredns-5c98db65d4-ns9dr               1/1     Running   0          149mkube-system   etcd-minikube                          1/1     Running   0          148mkube-system   kube-addon-manager-minikube            1/1     Running   0          148mkube-system   kube-apiserver-minikube                1/1     Running   0          148mkube-system   kube-controller-manager-minikube       1/1     Running   0          148mkube-system   kube-proxy-wdhfd                       1/1     Running   0          149mkube-system   kube-scheduler-minikube                1/1     Running   0          148mkube-system   storage-provisioner                    1/1     Running   0          149m</code></pre><p><br></p><p><strong>CrashLoopBackOff Error</strong></p><p>만약 kube-system의 coredns에서 CrashLoopBackOff Error가 발생한다면, coredns 설정에서 Corefile안의 loop를 삭제한다.</p><pre><code>$ kubectl -n kube-system edit configmap coredns&gt;&gt;&gt;# Please edit the object below. Lines beginning with a &#39;#&#39; will be ignored,# and an empty file will abort the edit. If an error occurs while saving this file will be# reopened with the relevant failures.#apiVersion: v1data:  Corefile: |    .:53 &#123;        errors        health        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;           pods insecure           upstream           fallthrough in-addr.arpa ip6.arpa           ttl 30        &#125;        prometheus :9153        forward . /etc/resolv.conf        cache 30        loop -&gt; remove this line        reload        loadbalance    &#125;kind: ConfigMapmetadata:  creationTimestamp: &quot;2019-07-19T10:34:27Z&quot;  name: coredns  namespace: kube-system  resourceVersion: &quot;189&quot;  selfLink: /api/v1/namespaces/kube-system/configmaps/coredns  uid: 8aa1d75a-0986-457f-81d6-d0339308a98a</code></pre><p>이제 기존의 포드(Pods)를 삭제하고 새로운 설정이 적용된 파드를 생성한다.</p><pre><code>$ kubectl -n kube-system delete pod -l k8s-app=kube-dns</code></pre><p><br></p><p><strong>Check GPU status</strong></p><p>미니쿠베의 GPU 마운트 상태를 확인한다. 지금은 GPU가 <code>&lt;none&gt;</code>인 것을 확인할 수가 있다.</p><pre><code>$ kubectl get nodes &quot;-o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\.com/gpu&quot;&gt;&gt;&gt;NAME       GPUminikube   &lt;none&gt;</code></pre><h2 id="k8s-device-plugin"><a href="#k8s-device-plugin" class="headerlink" title="k8s-device-plugin"></a>k8s-device-plugin</h2><p>k8s-device-plugin$^{[18]}$을 미니쿠베에 적용한다. k8s-device-plugin은 미니쿠베에서 GPU 디바이스를 인식할 수 있게 해준다.</p><pre><code>$ kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/1.0.0-beta/nvidia-device-plugin.yml$ kubectl get pods --all-namespaces&gt;&gt;&gt;NAMESPACE     NAME                                   READY   STATUS    RESTARTS   AGE...kube-system   nvidia-device-plugin-daemonset-4xlfc   1/1     Running   0          146m...</code></pre><p>k8s-device-plugin이 Running상태로 바뀌였다면, GPU 상태를 다시 한번 확인해본다. GPU의 개수가 2개로 변경되었음을 확인할 수 있다.</p><pre><code>$ kubectl get nodes &quot;-o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\.com/gpu&quot;&gt;&gt;&gt;NAME       GPUminikube   2</code></pre><h2 id="GPU-demo-yaml"><a href="#GPU-demo-yaml" class="headerlink" title="GPU-demo.yaml"></a>GPU-demo.yaml</h2><p>GPU 컨테이너를 생성할 yaml파일을 생성한다. 이는 실제로 컨테이너가 미니쿠베에서 실행되었을 때, 제대로 작동하는지 확인하기 위함이다.</p><p><strong>GPU-demo.yaml</strong></p><pre><code>apiVersion: v1kind: Podmetadata:  name: gpuspec:  containers:  - name: gpu-container    image: nvidia/cuda:9.0-runtime    command:      - &quot;/bin/sh&quot;      - &quot;-c&quot;    args:      - nvidia-smi &amp;&amp; tail -f /dev/null    resources:      requests:        nvidia.com/gpu: 2      limits:        nvidia.com/gpu: 2</code></pre><p> 미니쿠베에 컨테이너를 띄워보자.</p><pre><code>$ kubectl apply -f GPU-demo.yaml&gt;&gt;&gt;pod/gpu created$ kubectl get pods -n default&gt;&gt;&gt;NAME   READY   STATUS    RESTARTS   AGEgpu    1/1     Running   0          157m$ kubectl logs gpu&gt;&gt;&gt;+-----------------------------------------------------------------------------+| NVIDIA-SMI 390.116                Driver Version: 390.116                   ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||===============================+======================+======================||   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A || 33%   30C    P8    24W / 250W |    599MiB / 11175MiB |      1%      Default |+-------------------------------+----------------------+----------------------+|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A || 33%   31C    P8    16W / 250W |      2MiB / 11178MiB |      0%      Default |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes:                                                       GPU Memory ||  GPU       PID   Type   Process name                             Usage      ||=============================================================================||    0      2117      G   /usr/lib/xorg/Xorg                            40MiB ||    0      2183      G   /usr/bin/gnome-shell                          50MiB ||    0      2975      G   /usr/lib/xorg/Xorg                           334MiB ||    0      3116      G   /usr/bin/gnome-shell                         170MiB |+-----------------------------------------------------------------------------+</code></pre><h3 id="Access-container"><a href="#Access-container" class="headerlink" title="Access container"></a>Access container</h3><p>조금 더 확실하게 하기 위해서 미니쿠베에 배포한 컨테이너에 접속해보자. 접속 한 후에는 <code>nvidia-smi</code>와 <code>nvcc -V</code>명령어로 GPU가 잘 연결되어있는지 확인한다.</p><pre><code>$ kubectl exec gpu -it g -- /bin/bash&gt;&gt;&gt;    root@gpu:/# nvcc -V    &gt;&gt;&gt;    nvcc: NVIDIA (R) Cuda compiler driver    Copyright (c) 2005-2017 NVIDIA Corporation    Built on Fri_Sep__1_21:08:03_CDT_2017    Cuda compilation tools, release 9.0, V9.0.176    root@gpu:/# nvidia-smi    +-----------------------------------------------------------------------------+    | NVIDIA-SMI 390.116                Driver Version: 390.116                   |    |-------------------------------+----------------------+----------------------+    | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |    | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |    |===============================+======================+======================|    |   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |    | 33%   30C    P8    24W / 250W |    599MiB / 11175MiB |      1%      Default |    +-------------------------------+----------------------+----------------------+    |   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |    | 33%   31C    P8    16W / 250W |      2MiB / 11178MiB |      0%      Default |    +-------------------------------+----------------------+----------------------+    +-----------------------------------------------------------------------------+    | Processes:                                                       GPU Memory |    |  GPU       PID   Type   Process name                             Usage      |    |=============================================================================|    |    0      2117      G   /usr/lib/xorg/Xorg                            40MiB |    |    0      2183      G   /usr/bin/gnome-shell                          50MiB |    |    0      2975      G   /usr/lib/xorg/Xorg                           334MiB |    |    0      3116      G   /usr/bin/gnome-shell                         170MiB |    +-----------------------------------------------------------------------------+</code></pre><h2 id="Tip-of-Testing-amp-Debugging"><a href="#Tip-of-Testing-amp-Debugging" class="headerlink" title="Tip of Testing &amp; Debugging"></a>Tip of Testing &amp; Debugging</h2><h3 id="Helpful-command"><a href="#Helpful-command" class="headerlink" title="Helpful command"></a>Helpful command</h3><p>필자는 쿠버네티스와 도커환경이 익숙하지 않아서 생각보다 많이 헤맸는데, 매 스텝 스텝 작업할 때마다 에러가 발생하면 <code>kubectl describe</code>, <code>kubectl logs</code>, <code>minikube logs</code> <code>lspci -nn | grep -i nvidia</code> 를 열심히 사용해서 디버깅을 진행하였다.</p><ul><li><code>kubectl describe</code>, <code>kubectl logs</code>는 미니쿠베의 파드(Pods)의 상태 및 로그 메세지를 확인할 수 있다</li><li><code>minikube logs</code>는 미니쿠베 자체의 로그 정보를 확인할 수 있다</li><li><code>lspci -nn | grep -i nvidia</code>는 연결되어있는 디바이스 정보를 확인할 수 있다. 컨테이너에서 이를 확인하기 위해서는 별도의 Dockerfile을 작성해서 lspci util을 설치해야 컨테이너 내부에서 사용이 가능하다</li></ul><h3 id="Configuration-file-clearning"><a href="#Configuration-file-clearning" class="headerlink" title="Configuration file clearning"></a>Configuration file clearning</h3><p>미니쿠베로 작업을 하다가 잘못되어서 혹은 재현을 위해서 재설치를 하는 경우가 종종 있다. 이 때 기존의 설정 파일 삭제를 해줘야한다. 그렇지 않으면 이전에 설정들이 같이 따라와서 이전 작업에서 발생한 에러가 그대로 발생하는 경우가 있다. 대표적으로 아래 파일들을 삭제했는지 꼭 확인하자.</p><ul><li><code>~/.kube</code></li><li><code>~/.minikube</code></li><li><code>/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</code></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://github.com/kubernetes/minikube/blob/master/docs/gpu.md">(Experimental) NVIDIA GPU support in minikube</a></li><li><a href="https://www.reddit.com/r/linuxquestions/comments/bgbpim/how_to_enable_iommu_on_ubuntu_1804/">How to enable IOMMU on Ubuntu 18.04</a></li><li><a href="https://blog.zerosector.io/2018/07/28/kvm-qemu-windows-10-gpu-passthrough/">Ubuntu 18.04 - KVM/QEMU Windows 10 GPU Passthrough</a></li><li><a href="https://linustechtips.com/main/topic/978579-guide-linux-pci-gpu-vfio-passthrough/">[GUIDE] Linux PCI GPU VFIO Passthrough</a></li><li><a href="https://github.com/intel/nemu/wiki/Testing-VFIO-with-GPU">Testing VFIO with GPU</a></li><li><a href="https://www.server-world.info/en/note?os=Ubuntu_18.04&amp;p=kvm&amp;f=11">KVM: GPU Passthrough</a></li><li><a href="https://www.nepirity.com/blog/kvm-gpu-passthrough/">KVM 기반의 GPU Passthrough 환경</a></li><li><a href="https://smallake.kr/?p=9712">USERSPACE I/O와 VFIO</a></li><li><a href="http://iusethis.keizie.net/collection/virtualization/passthrough">Passthrough</a></li><li><a href="https://github.com/NVIDIA/k8s-device-plugin/issues/33">0/1 nodes are available: 1 Insufficient nvidia.com/gpu</a></li><li><a href="https://github.com/kubernetes/minikube/issues/2115https://github.com/kubernetes/minikube/issues/2115">minikube - GPU support</a></li><li><a href="https://www.kubeflow.org/docs/other-guides/troubleshooting/">Kubeflow - Troubleshooting</a></li><li><a href="https://medium.com/jim-fleming/running-tensorflow-on-kubernetes-ca00d0e67539">Running TensorFlow Kubernetes</a></li><li><a href="https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/">Kubernetes - Schedule GPUs</a></li><li><a href="https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/">Kubernetes - Feature Gates</a></li><li><a href="https://nvaitc.github.io/workstation-setup-guide/kubeflow-setup.html">Kubeflow Setup</a></li><li><a href="https://likefree.tistory.com/15">Kubernetes에서 gpu pod 생성</a></li><li><a href="https://github.com/NVIDIA/k8s-device-plugin">NVIDIA device plugin for Kubernetes</a></li></ol><h1 id="Thanks-to"><a href="#Thanks-to" class="headerlink" title="Thanks to"></a>Thanks to</h1><h2 id="검수자"><a href="#검수자" class="headerlink" title="검수자"></a>검수자</h2><ul><li><a href="https://evan-moon.github.io/">문동욱</a></li><li><a href="https://lovablebaby1015.wordpress.com/">정미연</a></li><li><a href="https://github.com/soodevv">김수정</a></li><li><a href="https://aisolab.github.io/">김보섭</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;이번 포스팅에는 Minikube에서 GPU 컨테이너 사용이 가능하도록 설정하는 방법에 대해서 포스팅한다.&lt;/p&gt;</summary>
    
    
    
    <category term="Software" scheme="http://ssaru.github.io/categories/Software/"/>
    
    <category term="Cloud" scheme="http://ssaru.github.io/categories/Software/Cloud/"/>
    
    
    <category term="Minikube" scheme="http://ssaru.github.io/tags/Minikube/"/>
    
    <category term="GPU" scheme="http://ssaru.github.io/tags/GPU/"/>
    
    <category term="Kubernetes" scheme="http://ssaru.github.io/tags/Kubernetes/"/>
    
  </entry>
  
</feed>
